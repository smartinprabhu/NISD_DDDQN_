<!DOCTYPE HTML>
<!-- saved from url=(0016)http://localhost -->
<!-- This file was generated by Snap2HTML 2.14 at 2023-11-22 11:58 AM. See http://www.rlvision.com for more information -->
<html>
<head>

	<meta http-equiv="content-type" content="text/html; charset=utf-8">
	<meta http-equiv="X-UA-Compatible" content="IE=10,IE=9,IE=8">

	<title>Literature</title>
	
	<style type="text/css">

		html, body {
			height:100%;
			margin: 0;
			padding: 0;
		}

		html > body {
			font-size: 16px; 
			font-size: 68.75%;
		} /* Reset Base Font Size */

		body {
			font-family: Verdana, helvetica, arial, sans-serif;
			font-size: 68.75%;
			background: #0072AF;
			color: #333;

			background-image: rgb(201,222,150);
			background-image: -moz-linear-gradient(top, rgb(201,222,150) 0%, rgb(138,182,107) 44%, rgb(57,130,53) 100%);
			background-image: -webkit-gradient(linear, left top, left bottom, color-stop(0%,rgb(201,222,150)), color-stop(44%,rgb(138,182,107)), color-stop(100%,rgb(57,130,53)));
			background-image: -webkit-linear-gradient(top, rgb(201,222,150) 0%,rgb(138,182,107) 44%,rgb(57,130,53) 100%);
			background-image: -o-linear-gradient(top, rgb(201,222,150) 0%,rgb(138,182,107) 44%,rgb(57,130,53) 100%);
			background-image: -ms-linear-gradient(top, rgb(201,222,150) 0%,rgb(138,182,107) 44%,rgb(57,130,53) 100%);
			filter: progid:DXImageTransform.Microsoft.gradient( startColorstr='#c9de96', endColorstr='#398235',GradientType=0 );
			background-image: linear-gradient(top, rgb(201,222,150) 0%,rgb(138,182,107) 44%,rgb(57,130,53) 100%);
		}

		h1 {
			font-family: 'trebuchet ms', verdana, arial;
			padding: 10px;
			padding-top:12px;
			padding-bottom:0px;
			margin: 0;
		}

		a img {
			border: none;
		}


		.loading {
			background:#fff;
			border: 1px solid #aaa;
			margin-left: auto;
			margin-right: auto;
			width: 90%;
			height:90%;
			padding-top:30px;
			text-align:center;
			font-size:120%;
		}
		.loading_info {
			font-size:80%;
			font-style: italic;
		}

		/* --- Top header --- */

		.app_header {
			height:80px;
			max-width: 1440px;
			background-color:#eee;
			margin-left: auto;
			margin-right: auto;

			border-left: 1px solid #aaa;
			border-right: 1px solid #aaa;

			background-image: rgb(246,248,249);
			background-image: -moz-linear-gradient(top, rgb(246,248,249) 0%, rgb(215,222,227) 99%);
			background-image: -webkit-gradient(linear, left top, left bottom, color-stop(0%,rgb(246,248,249)), color-stop(99%,rgb(215,222,227)));
			background-image: -webkit-linear-gradient(top, rgb(246,248,249) 0%,rgb(215,222,227) 99%);
			background-image: -o-linear-gradient(top, rgb(246,248,249) 0%,rgb(215,222,227) 99%);
			background-image: -ms-linear-gradient(top, rgb(246,248,249) 0%,rgb(215,222,227) 99%);
			filter: progid:DXImageTransform.Microsoft.gradient( startColorstr='#f6f8f9', endColorstr='#d7dee3',GradientType=0 );
			background-image: linear-gradient(top, rgb(246,248,249) 0%,rgb(215,222,227) 99%);
		}
		@media screen and (min-width : 1024px) {
			.app_header {
				width: 90%;
			}
		}

		.app_header a {
			color: #900;
		}
		.app_header_icon {
			/* Icon from https://commons.wikimedia.org/wiki/File:Gnome-emblem-documents.svg (GPL) */
			background: url(data:image/png;base64,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)
			no-repeat;

			margin:10px;
			margin-left:16px;
			float:left;
			width:48px;
			height:48px;
		}
		.app_header_search {
			float:right;
			padding:10px;
		}
		.app_header_search_help {
			display: inline-block;
			background-color: #bbb;
			color: white;
			width: 14px;
			height: 14px;
			border-radius: 50%;
			text-align: center;
			font-weight: bold;
			position: relative;
			top: -1px;
			cursor: pointer;
		}
		.app_header_stats {
			padding: 10px;
			padding-top:0px;
			font-style: italic;
		}

		/* --- Main areas --- */

		.content {
			max-width: 1440px;
			display:none;
			padding:0px;
			margin-left: auto;
			margin-right: auto;
			background: white;
			border: none;
			border-left: 1px solid #aaa;
			border-right: 1px solid #aaa;
			border-bottom: 1px solid #aaa;
		}
		@media screen and (min-width : 1024px) {
			.content {
				width: 90%;
			}
		}

		.treeview {
			position:relative;
			height: 100%;
			width:29%;
			float:left;
			overflow:auto;
			border-top: 1px solid #aaa;
		}
		.treeview_bold {
			font-weight: bold;
		}

		.list_container {
			position:relative;
			height: 100%;
			overflow: auto;
			border-top: 1px solid #aaa;
		}

		.list_files {
			overflow: auto;
			position: relative;
		}

		.search_indicator {
			position: absolute;
			left: 0px;
			right: 0px;
			top: 0px;
			bottom: 0px;
			background-color: white;
			opacity: 0.7;
			text-align: center;
			padding-top: 100px;
			font-size: 18px;
			display: none;
			z-index: 99;
		}

		/* --- Splitter --- */

		.vsplitbar {
			width: 4px;
			background: #d7dee3;
			border-right: 1px solid #bbb;
		}

		/* --- File Table --- */

		#files.tablesorter {
			font-family:arial;
			background-color: #cdcdcd;
			font-size: 8pt;
			line-height: 1.25em;
			width: 100%;
			text-align: left;
			border-spacing: 0px;
			border-bottom: 1px solid #ccc;
		}
		#files.tablesorter thead tr th, #files.tablesorter tfoot tr th {
			background: #ffefcc;
			border-left: 1px solid #ccc;
			border-right: 1px solid #ccc;
			padding: 4px;
			border-left: 0px;
		}
		#files.tablesorter thead tr .header {
			background-image: url(data:image/gif;base64,R0lGODlhFQAJAIAAACMtMP///yH5BAEAAAEALAAAAAAVAAkAAAIXjI+AywnaYnhUMoqt3gZXPmVg94yJVQAAOw==);
			background-repeat: no-repeat;
			background-position: center right;
			cursor: pointer;
			text-align: center;
		}
		#files.tablesorter tbody td {
			vertical-align: top;
			background-color: #fff;
			border-bottom: none;
			border-left: none;
			border-right: 1px solid #ccc;
			border-top: 1px solid #e0e0e0;
			padding: 3px 4px 3px 4px;
		}

		#files.tablesorter:not(.has-parent-folder) tbody tr:nth-child(even) td {
			background-color: #f8f8f8;
		}
		#files.tablesorter.has-parent-folder tbody tr:nth-child(odd) td {
			background-color: #f8f8f8;
		}
		
		#files.tablesorter tbody tr:hover td,
		#files.tablesorter tbody tr:nth-child(even):hover td {
			background-color: #E4F0F9;
		}
		
		#files.tablesorter thead tr .headerSortUp {
			background-image: url(data:image/gif;base64,R0lGODlhFQAEAIAAACMtMP///yH5BAEAAAEALAAAAAAVAAQAAAINjB+gC+jP2ptn0WskLQA7);
		}
		#files.tablesorter thead tr .headerSortDown {
			/*background-image: url(tree_tablesorter_desc.gif);*/
			background-image: url(data:image/gif;base64,R0lGODlhFQAEAIAAACMtMP///yH5BAEAAAEALAAAAAAVAAQAAAINjI8Bya2wnINUMopZAQA7);
		}
		#files.tablesorter thead tr .headerSortDown, #files.tablesorter thead tr .headerSortUp {
			background-color: #FFD283;
		}

		#files.tablesorter th:last-of-type,
		#files.tablesorter td:last-of-type {
			border-right:0px;
		}

		span.file, span.file_folder {
			background: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAwAAAAOCAYAAAAbvf3sAAAAYUlEQVR4nGNkYGBgqKmp+c+AB7S0tDCiCNTU1PzHBdavX/8f2UAmfCbDgLGxMdwVRGlA1sRCSGFAQACcffbsWeJtgAE6afj+/TtRir9//z5o/UAKYGRgYGAoLi7Gm/iQAQC+qjWGF5ecJwAAAABJRU5ErkJggg==)
						no-repeat
						left center;
			padding-left:16px;
			padding-bottom:1px;
			padding-top:1px;
		}

		span.file_folder {
			background: url(data:image/gif;base64,R0lGODlhEAAOALMIAOC6eJdaH61zLZ9oJMOHNP/Sg//inv///////wAAAAAAAAAAAAAAAAAAAAAAAAAAACH5BAEAAAgALAAAAAAQAA4AAAQ9EMlJq72XaIKnOOAhdIRhFgCwaRQRviE3lWZtB5Rg78bo8TafZFAoGo8DSuDILOAmAUHT+JwMrthsZ4uIAAA7)
						no-repeat
						left center;
		}

		span.file a, span.file_folder a {
			text-decoration: none;
			color: #333;
		}

		span.file a:hover, span.file_folder a:hover {
			text-decoration: underline;
			color: #900;
		}

		td.size {
			text-align: right;
			white-space: nowrap;
		}
		
		td.date {
			white-space: nowrap;
		}


		/* make room for [..] */
		#files.tablesorter.has-parent-folder th {
			border-bottom: 1px solid #ccc;
		}

		#files.tablesorter.has-parent-folder tbody tr:first-child td {
			border-top: 20px solid white;
		}
		#parent_folder {
			position: absolute;
			top: 24px;
			left: 4px;
		}
		#parent_folder_border {
			background-color: #e0e0e0;
			height: 1px;
			position: absolute;
			width: 100%;
			top: 42px;
		}


		/* --- Breadcrumb --- */

		.list_header {
			background: #fff;
			font-family: arial;
			font-size: 8pt;
			border: 0px;
			border-bottom: 1px solid #CCC;
			padding:3px;
			padding-left: 6px;
		}

		.list_header span {
			background-color: white;
		}

		.list_header a {
			text-decoration: none;
			color: #333;
		}
		.list_header a:hover {
			text-decoration: underline;
			color: #900;
		}
		
		.path_divider {
			display:inline-block;
			margin-left: 3px;
			margin-right: 2px;
			margin-bottom: 1px;
			width: 0px;
			height: 0px;
			border-style: solid;
			border-width: 3px 0 3px 5px;
			border-color: transparent transparent transparent #222;
		}

		/* --- Listview footer --- */

		.list_footer {
			padding: 10px;
			border-top: 1px solid #ccc;
		}
		
		.list_footer_open_export {
			float: right;
		}
		.list_footer_open_export:hover {
			text-decoration: underline;
			color: #900;
			cursor: pointer;
		}
		
		/* --- CSV LightBox --- */
		
		.export_lightbox {
			z-index: 1000;
			background-color: rgba(0,0,0,0.75);
			position: absolute;
			top: 0;
			left: 0;
			right: 0;
			bottom: 0;
			text-align: center;
			font-size: 13px;
			display: none;
		}
		.export_content {
			text-align: left;
			background-color: white;
			padding: 20px;
			padding-top: 5px;
			width: calc(100% - 40px);
			max-width: 800px;
			height: 240px;
			margin-left: auto;
			margin-right: auto;
			position: relative;
		}
		.export_options {
			line-height: 2em;
		}
		.export_options input {
			position: relative;
			top: 2px;
			left: 2px;
		}
		.export_options label {
			margin-right: 0.5em;
			padding-left: 0.5em;
		}
		.export_text {
			width: 100%;
			height: calc(100% - 5.25em);	/* two .export_options => 4em + save link*/
		}
		.export_close:link, .export_close:visited {
			float: right;
			text-decoration: none;
			color: black;
		}
		.export_close:hover, .export_close:active {
			text-decoration: underline;
		}	

		#export_checkbox_csv + label {
			margin-right: 1em;
		}


		.export_save {
			text-align: center;
			margin-top: 0.25em;
		}
		.export_save a:link, .export_save a:visited {
			color: black;
			text-decoration: none;
		}
		.export_save a:hover {
			text-decoration: underline;
		}

		.export_chevron {
			box-sizing: border-box;
			position: relative;
			display: inline-block;
			width: 18px;
			height: 16px
		}
		.export_chevron::after,
		.export_chevron::before {
			content: "";
			display: block;
			box-sizing: border-box;
			position: absolute;
			width: 8px;
			height: 8px;
			border-bottom: 2px solid;
			border-right: 2px solid;
			transform: rotate(45deg);
			left: 7px;
			top: 3px
		}
		.export_chevron::after {
			top: 8px
		}

		#export_tip {
			color: #eee;
			position: absolute;
			bottom: 13px;
			right: 20px;
			font-size: 11px;
		}



		/* --- DynaTree --- */
		
		ul.dynatree-container
		{
			white-space: nowrap;
			padding: 0px;
			margin: 0; /* issue 201 */
			background-color: white;
			border: 0px dotted gray;
			overflow: auto;
			height: 100%; /* issue 263 */
		}

		ul.dynatree-container ul
		{
			padding: 0 0 0 16px;
			margin: 0;
		}

		ul.dynatree-container li
		{
			list-style-image: none;
			list-style-position: outside;
			list-style-type: none;
			-moz-background-clip:border;
			-moz-background-inline-policy: continuous;
			-moz-background-origin: padding;
			background-attachment: scroll;
			background-color: transparent;
			background-repeat: repeat-y;
			/* vline.gif */
			background-image:url(data:image/gif;base64,R0lGODlhEAAQAPcAAAAAAIAAAACAAICAAAAAgIAAgACAgMDAwMDcwKbK8P///6Wlpf/////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////78KCgpICAgP8AAAD/AP//AAAA//8A/wD//////yH5BAEAAP4ALAAAAAAQABAAAAgpAP0JFHhvoMGDCBMiLKiwocOBDB9KXDixosGIFidizPhwI8eGHj8KDAgAOw==);
			background-position: 0 0;
			margin: 0;
			padding: 1px 0 0 0;
		}
		ul.dynatree-container li.dynatree-lastsib
		{
			background-image: none;
		}
		ul.dynatree-no-connector > li
		{
			background-image: none;
		}
		.ui-dynatree-disabled ul.dynatree-container
		{
			opacity: 0.5;
			background-color: silver;
		}
		span.dynatree-empty,
		span.dynatree-vline,
		span.dynatree-connector,
		span.dynatree-expander,
		span.dynatree-icon,
		span.dynatree-checkbox,
		span.dynatree-radio,
		span.dynatree-drag-helper-img,
		#dynatree-drop-marker
		{
			width: 16px;
			height: 16px;
			display: inline-block; /* Required to make a span sizeable */
			vertical-align: top;
			background-repeat: no-repeat;
			background-position: left;
			/* icons.gif */
			background-image:url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAEAAAABwCAYAAACuE3ZzAAAA+UlEQVR4nO3YYY6CMBAG0HazJ9QjrMfSI+AV9YepwQ0IWVgmOO8lxIL5jOmMQlsKAAAAAAAAAAAAAAAAAAAAwCfquvMtMk80HZCdDsiuVXDu69p5oqlMdjogOx2QnQ7ILnotEJ1PpZYyb8aOx1Mde2/P+e82OBx+RsPX62Xq83eb/xq6WOvoZM+yNL+lwQnI5GUCaq3P6vXHzdR6fq18/9gk33XnW18p5eV86k9m7fxv/5n3Exi6+Cji3y3Nb+l5G5xzq3ln73n6op/Fo/NEVyA6T3QFovOp2A9og72u55fm7QdEf4Fo9gPawH5AUvYD2iB6PR6dB3K6A7CRDkvQMF4HAAAAAElFTkSuQmCC);
			background-position: 0 0;
		}
		ul.dynatree-container img
		{
			width: 16px;
			height: 16px;
			margin-left: 3px;
			vertical-align: top;
			border-style: none;
		}
		span.dynatree-connector
		{
			background-position: -16px -64px;
		}
		span.dynatree-expander
		{
			background-position: 0px -80px;
			cursor: pointer;
		}
		.dynatree-exp-cl span.dynatree-expander /* Collapsed, not delayed, last sibling */
		{
			background-position: 0px -96px;
		}
		.dynatree-exp-cd span.dynatree-expander /* Collapsed, delayed, not last sibling */
		{
			background-position: -64px -80px;
		}
		.dynatree-exp-cdl span.dynatree-expander /* Collapsed, delayed, last sibling */
		{
			background-position: -64px -96px;
		}
		.dynatree-exp-e span.dynatree-expander,  /* Expanded, not delayed, not last sibling */
		.dynatree-exp-ed span.dynatree-expander  /* Expanded, delayed, not last sibling */
		{
			background-position: -32px -80px;
		}
		.dynatree-exp-el span.dynatree-expander,  /* Expanded, not delayed, last sibling */
		.dynatree-exp-edl span.dynatree-expander  /* Expanded, delayed, last sibling */
		{
			background-position: -32px -96px;
		}
		.dynatree-loading span.dynatree-expander  /* 'Loading' status overrides all others */
		{
			background-position: 0 0;
			/*background-image: url("loading.gif");*/
		}
		span.dynatree-icon /* Default icon */
		{
			margin-left: 3px;
			background-position: 0px 0px;
		}
		.dynatree-ico-cf span.dynatree-icon  /* Collapsed Folder */
		{
			/*background-position: 0px -16px;*/
			background: url(data:image/gif;base64,R0lGODlhEAAOALMIAOC6eJdaH61zLZ9oJMOHNP/Sg//inv///////wAAAAAAAAAAAAAAAAAAAAAAAAAAACH5BAEAAAgALAAAAAAQAA4AAAQ9EMlJq72XaIKnOOAhdIRhFgCwaRQRviE3lWZtB5Rg78bo8TafZFAoGo8DSuDILOAmAUHT+JwMrthsZ4uIAAA7)
		}
		.dynatree-ico-ef span.dynatree-icon  /* Expanded Folder */
		{
			/*background-position: -64px -16px;*/
			background:url(data:image/gif;base64,R0lGODlhEAAOALMIAJdaH+C6eJ9oJMOHNK1zLf/inv/Sg////////wAAAAAAAAAAAAAAAAAAAAAAAAAAACH5BAEAAAgALAAAAAAQAA4AAARAEMlJq7136IEnOeBBdENhGkGwadQQviE3lWZtAxRhE3zvIzpT0HYaCQwGAnLJHCEASabU+VRKl1SJYMvtdr6ICAA7);
		}
		span.dynatree-node
		{
			/*	display: -moz-inline-box; /* issue 133, 165, 172, 192. removed for issue 221*/
			/*	-moz-box-align: start; /* issue 221 */
			/*  display: inline-block; /* Required to make a span sizeable */
		}
		ul.dynatree-container a
		{
			color: black; /* inherit doesn't work on IE */
			text-decoration: none;
			vertical-align: top;
			margin: 0px;
			/*margin-left: 3px;*/
			border: 1px solid transparent;
			/*	outline: 0; /* @ Firefox, prevent dotted border after click */
		}
		ul.dynatree-container a:hover
		{
			/*	text-decoration: underline; */
			background-color: #E9EDEF;
			border: 1px solid #aaa;
		}
		span.dynatree-node a
		{
			/*font-size: 10pt; /* required for IE, quirks mode */
			display: inline-block; /* Better alignment, when title contains <br> */
			padding-left: 2px;
			padding-right: 3px; /* Otherwise italic font will be outside bounds */
		}
		span.dynatree-folder a
		{
		}
		ul.dynatree-container a:focus,
		span.dynatree-focused a:link  /* @IE */
		{
		}
		span.dynatree-has-children a
		{
		}
		span.dynatree-expanded a
		{
		}
		span.dynatree-selected a
		{
		}
		span.dynatree-active a
		{
			font-weight: bold;
			/*background-color: #3169C6 !important;
			color: white !important; /* @ IE6 */
		}

	</style>
		
	<script type="text/javascript">
		/* --- jQuery 1.6.2: http://jquery.com/ --- */
		(function(a,b){function cv(a){return f.isWindow(a)?a:a.nodeType===9?a.defaultView||a.parentWindow:!1}function cs(a){if(!cg[a]){var b=c.body,d=f("<"+a+">").appendTo(b),e=d.css("display");d.remove();if(e==="none"||e===""){ch||(ch=c.createElement("iframe"),ch.frameBorder=ch.width=ch.height=0),b.appendChild(ch);if(!ci||!ch.createElement)ci=(ch.contentWindow||ch.contentDocument).document,ci.write((c.compatMode==="CSS1Compat"?"<!doctype html>":"")+"<html><body>"),ci.close();d=ci.createElement(a),ci.body.appendChild(d),e=f.css(d,"display"),b.removeChild(ch)}cg[a]=e}return cg[a]}function cr(a,b){var c={};f.each(cm.concat.apply([],cm.slice(0,b)),function(){c[this]=a});return c}function cq(){cn=b}function cp(){setTimeout(cq,0);return cn=f.now()}function cf(){try{return new a.ActiveXObject("Microsoft.XMLHTTP")}catch(b){}}function ce(){try{return new a.XMLHttpRequest}catch(b){}}function b$(a,c){a.dataFilter&&(c=a.dataFilter(c,a.dataType));var d=a.dataTypes,e={},g,h,i=d.length,j,k=d[0],l,m,n,o,p;for(g=1;g<i;g++){if(g===1)for(h in a.converters)typeof h=="string"&&(e[h.toLowerCase()]=a.converters[h]);l=k,k=d[g];if(k==="*")k=l;else if(l!=="*"&&l!==k){m=l+" "+k,n=e[m]||e["* "+k];if(!n){p=b;for(o in e){j=o.split(" ");if(j[0]===l||j[0]==="*"){p=e[j[1]+" "+k];if(p){o=e[o],o===!0?n=p:p===!0&&(n=o);break}}}}!n&&!p&&f.error("No conversion from "+m.replace(" "," to ")),n!==!0&&(c=n?n(c):p(o(c)))}}return c}function bZ(a,c,d){var e=a.contents,f=a.dataTypes,g=a.responseFields,h,i,j,k;for(i in g)i in d&&(c[g[i]]=d[i]);while(f[0]==="*")f.shift(),h===b&&(h=a.mimeType||c.getResponseHeader("content-type"));if(h)for(i in e)if(e[i]&&e[i].test(h)){f.unshift(i);break}if(f[0]in d)j=f[0];else{for(i in d){if(!f[0]||a.converters[i+" "+f[0]]){j=i;break}k||(k=i)}j=j||k}if(j){j!==f[0]&&f.unshift(j);return d[j]}}function bY(a,b,c,d){if(f.isArray(b))f.each(b,function(b,e){c||bC.test(a)?d(a,e):bY(a+"["+(typeof e=="object"||f.isArray(e)?b:"")+"]",e,c,d)});else if(!c&&b!=null&&typeof b=="object")for(var e in b)bY(a+"["+e+"]",b[e],c,d);else d(a,b)}function bX(a,c,d,e,f,g){f=f||c.dataTypes[0],g=g||{},g[f]=!0;var h=a[f],i=0,j=h?h.length:0,k=a===bR,l;for(;i<j&&(k||!l);i++)l=h[i](c,d,e),typeof l=="string"&&(!k||g[l]?l=b:(c.dataTypes.unshift(l),l=bX(a,c,d,e,l,g)));(k||!l)&&!g["*"]&&(l=bX(a,c,d,e,"*",g));return l}function bW(a){return function(b,c){typeof b!="string"&&(c=b,b="*");if(f.isFunction(c)){var d=b.toLowerCase().split(bN),e=0,g=d.length,h,i,j;for(;e<g;e++)h=d[e],j=/^\+/.test(h),j&&(h=h.substr(1)||"*"),i=a[h]=a[h]||[],i[j?"unshift":"push"](c)}}}function bA(a,b,c){var d=b==="width"?a.offsetWidth:a.offsetHeight,e=b==="width"?bv:bw;if(d>0){c!=="border"&&f.each(e,function(){c||(d-=parseFloat(f.css(a,"padding"+this))||0),c==="margin"?d+=parseFloat(f.css(a,c+this))||0:d-=parseFloat(f.css(a,"border"+this+"Width"))||0});return d+"px"}d=bx(a,b,b);if(d<0||d==null)d=a.style[b]||0;d=parseFloat(d)||0,c&&f.each(e,function(){d+=parseFloat(f.css(a,"padding"+this))||0,c!=="padding"&&(d+=parseFloat(f.css(a,"border"+this+"Width"))||0),c==="margin"&&(d+=parseFloat(f.css(a,c+this))||0)});return d+"px"}function bm(a,b){b.src?f.ajax({url:b.src,async:!1,dataType:"script"}):f.globalEval((b.text||b.textContent||b.innerHTML||"").replace(be,"/*$0*/")),b.parentNode&&b.parentNode.removeChild(b)}function bl(a){f.nodeName(a,"input")?bk(a):"getElementsByTagName"in a&&f.grep(a.getElementsByTagName("input"),bk)}function bk(a){if(a.type==="checkbox"||a.type==="radio")a.defaultChecked=a.checked}function bj(a){return"getElementsByTagName"in a?a.getElementsByTagName("*"):"querySelectorAll"in a?a.querySelectorAll("*"):[]}function bi(a,b){var c;if(b.nodeType===1){b.clearAttributes&&b.clearAttributes(),b.mergeAttributes&&b.mergeAttributes(a),c=b.nodeName.toLowerCase();if(c==="object")b.outerHTML=a.outerHTML;else if(c!=="input"||a.type!=="checkbox"&&a.type!=="radio"){if(c==="option")b.selected=a.defaultSelected;else if(c==="input"||c==="textarea")b.defaultValue=a.defaultValue}else a.checked&&(b.defaultChecked=b.checked=a.checked),b.value!==a.value&&(b.value=a.value);b.removeAttribute(f.expando)}}function bh(a,b){if(b.nodeType===1&&!!f.hasData(a)){var c=f.expando,d=f.data(a),e=f.data(b,d);if(d=d[c]){var g=d.events;e=e[c]=f.extend({},d);if(g){delete e.handle,e.events={};for(var h in g)for(var i=0,j=g[h].length;i<j;i++)f.event.add(b,h+(g[h][i].namespace?".":"")+g[h][i].namespace,g[h][i],g[h][i].data)}}}}function bg(a,b){return f.nodeName(a,"table")?a.getElementsByTagName("tbody")[0]||a.appendChild(a.ownerDocument.createElement("tbody")):a}function W(a,b,c){b=b||0;if(f.isFunction(b))return f.grep(a,function(a,d){var e=!!b.call(a,d,a);return e===c});if(b.nodeType)return f.grep(a,function(a,d){return a===b===c});if(typeof b=="string"){var d=f.grep(a,function(a){return a.nodeType===1});if(R.test(b))return f.filter(b,d,!c);b=f.filter(b,d)}return f.grep(a,function(a,d){return f.inArray(a,b)>=0===c})}function V(a){return!a||!a.parentNode||a.parentNode.nodeType===11}function N(a,b){return(a&&a!=="*"?a+".":"")+b.replace(z,"`").replace(A,"&")}function M(a){var b,c,d,e,g,h,i,j,k,l,m,n,o,p=[],q=[],r=f._data(this,"events");if(!(a.liveFired===this||!r||!r.live||a.target.disabled||a.button&&a.type==="click")){a.namespace&&(n=new RegExp("(^|\\.)"+a.namespace.split(".").join("\\.(?:.*\\.)?")+"(\\.|$)")),a.liveFired=this;var s=r.live.slice(0);for(i=0;i<s.length;i++)g=s[i],g.origType.replace(x,"")===a.type?q.push(g.selector):s.splice(i--,1);e=f(a.target).closest(q,a.currentTarget);for(j=0,k=e.length;j<k;j++){m=e[j];for(i=0;i<s.length;i++){g=s[i];if(m.selector===g.selector&&(!n||n.test(g.namespace))&&!m.elem.disabled){h=m.elem,d=null;if(g.preType==="mouseenter"||g.preType==="mouseleave")a.type=g.preType,d=f(a.relatedTarget).closest(g.selector)[0],d&&f.contains(h,d)&&(d=h);(!d||d!==h)&&p.push({elem:h,handleObj:g,level:m.level})}}}for(j=0,k=p.length;j<k;j++){e=p[j];if(c&&e.level>c)break;a.currentTarget=e.elem,a.data=e.handleObj.data,a.handleObj=e.handleObj,o=e.handleObj.origHandler.apply(e.elem,arguments);if(o===!1||a.isPropagationStopped()){c=e.level,o===!1&&(b=!1);if(a.isImmediatePropagationStopped())break}}return b}}function K(a,c,d){var e=f.extend({},d[0]);e.type=a,e.originalEvent={},e.liveFired=b,f.event.handle.call(c,e),e.isDefaultPrevented()&&d[0].preventDefault()}function E(){return!0}function D(){return!1}function m(a,c,d){var e=c+"defer",g=c+"queue",h=c+"mark",i=f.data(a,e,b,!0);i&&(d==="queue"||!f.data(a,g,b,!0))&&(d==="mark"||!f.data(a,h,b,!0))&&setTimeout(function(){!f.data(a,g,b,!0)&&!f.data(a,h,b,!0)&&(f.removeData(a,e,!0),i.resolve())},0)}function l(a){for(var b in a)if(b!=="toJSON")return!1;return!0}function k(a,c,d){if(d===b&&a.nodeType===1){var e="data-"+c.replace(j,"$1-$2").toLowerCase();d=a.getAttribute(e);if(typeof d=="string"){try{d=d==="true"?!0:d==="false"?!1:d==="null"?null:f.isNaN(d)?i.test(d)?f.parseJSON(d):d:parseFloat(d)}catch(g){}f.data(a,c,d)}else d=b}return d}var c=a.document,d=a.navigator,e=a.location,f=function(){function J(){if(!e.isReady){try{c.documentElement.doScroll("left")}catch(a){setTimeout(J,1);return}e.ready()}}var e=function(a,b){return new e.fn.init(a,b,h)},f=a.jQuery,g=a.$,h,i=/^(?:[^<]*(<[\w\W]+>)[^>]*$|#([\w\-]*)$)/,j=/\S/,k=/^\s+/,l=/\s+$/,m=/\d/,n=/^<(\w+)\s*\/?>(?:<\/\1>)?$/,o=/^[\],:{}\s]*$/,p=/\\(?:["\\\/bfnrt]|u[0-9a-fA-F]{4})/g,q=/"[^"\\\n\r]*"|true|false|null|-?\d+(?:\.\d*)?(?:[eE][+\-]?\d+)?/g,r=/(?:^|:|,)(?:\s*\[)+/g,s=/(webkit)[ \/]([\w.]+)/,t=/(opera)(?:.*version)?[ \/]([\w.]+)/,u=/(msie) ([\w.]+)/,v=/(mozilla)(?:.*? rv:([\w.]+))?/,w=/-([a-z])/ig,x=function(a,b){return b.toUpperCase()},y=d.userAgent,z,A,B,C=Object.prototype.toString,D=Object.prototype.hasOwnProperty,E=Array.prototype.push,F=Array.prototype.slice,G=String.prototype.trim,H=Array.prototype.indexOf,I={};e.fn=e.prototype={constructor:e,init:function(a,d,f){var g,h,j,k;if(!a)return this;if(a.nodeType){this.context=this[0]=a,this.length=1;return this}if(a==="body"&&!d&&c.body){this.context=c,this[0]=c.body,this.selector=a,this.length=1;return this}if(typeof a=="string"){a.charAt(0)!=="<"||a.charAt(a.length-1)!==">"||a.length<3?g=i.exec(a):g=[null,a,null];if(g&&(g[1]||!d)){if(g[1]){d=d instanceof e?d[0]:d,k=d?d.ownerDocument||d:c,j=n.exec(a),j?e.isPlainObject(d)?(a=[c.createElement(j[1])],e.fn.attr.call(a,d,!0)):a=[k.createElement(j[1])]:(j=e.buildFragment([g[1]],[k]),a=(j.cacheable?e.clone(j.fragment):j.fragment).childNodes);return e.merge(this,a)}h=c.getElementById(g[2]);if(h&&h.parentNode){if(h.id!==g[2])return f.find(a);this.length=1,this[0]=h}this.context=c,this.selector=a;return this}return!d||d.jquery?(d||f).find(a):this.constructor(d).find(a)}if(e.isFunction(a))return f.ready(a);a.selector!==b&&(this.selector=a.selector,this.context=a.context);return e.makeArray(a,this)},selector:"",jquery:"1.6.2",length:0,size:function(){return this.length},toArray:function(){return F.call(this,0)},get:function(a){return a==null?this.toArray():a<0?this[this.length+a]:this[a]},pushStack:function(a,b,c){var d=this.constructor();e.isArray(a)?E.apply(d,a):e.merge(d,a),d.prevObject=this,d.context=this.context,b==="find"?d.selector=this.selector+(this.selector?" ":"")+c:b&&(d.selector=this.selector+"."+b+"("+c+")");return d},each:function(a,b){return e.each(this,a,b)},ready:function(a){e.bindReady(),A.done(a);return this},eq:function(a){return a===-1?this.slice(a):this.slice(a,+a+1)},first:function(){return this.eq(0)},last:function(){return this.eq(-1)},slice:function(){return this.pushStack(F.apply(this,arguments),"slice",F.call(arguments).join(","))},map:function(a){return this.pushStack(e.map(this,function(b,c){return a.call(b,c,b)}))},end:function(){return this.prevObject||this.constructor(null)},push:E,sort:[].sort,splice:[].splice},e.fn.init.prototype=e.fn,e.extend=e.fn.extend=function(){var a,c,d,f,g,h,i=arguments[0]||{},j=1,k=arguments.length,l=!1;typeof i=="boolean"&&(l=i,i=arguments[1]||{},j=2),typeof i!="object"&&!e.isFunction(i)&&(i={}),k===j&&(i=this,--j);for(;j<k;j++)if((a=arguments[j])!=null)for(c in a){d=i[c],f=a[c];if(i===f)continue;l&&f&&(e.isPlainObject(f)||(g=e.isArray(f)))?(g?(g=!1,h=d&&e.isArray(d)?d:[]):h=d&&e.isPlainObject(d)?d:{},i[c]=e.extend(l,h,f)):f!==b&&(i[c]=f)}return i},e.extend({noConflict:function(b){a.$===e&&(a.$=g),b&&a.jQuery===e&&(a.jQuery=f);return e},isReady:!1,readyWait:1,holdReady:function(a){a?e.readyWait++:e.ready(!0)},ready:function(a){if(a===!0&&!--e.readyWait||a!==!0&&!e.isReady){if(!c.body)return setTimeout(e.ready,1);e.isReady=!0;if(a!==!0&&--e.readyWait>0)return;A.resolveWith(c,[e]),e.fn.trigger&&e(c).trigger("ready").unbind("ready")}},bindReady:function(){if(!A){A=e._Deferred();if(c.readyState==="complete")return setTimeout(e.ready,1);if(c.addEventListener)c.addEventListener("DOMContentLoaded",B,!1),a.addEventListener("load",e.ready,!1);else if(c.attachEvent){c.attachEvent("onreadystatechange",B),a.attachEvent("onload",e.ready);var b=!1;try{b=a.frameElement==null}catch(d){}c.documentElement.doScroll&&b&&J()}}},isFunction:function(a){return e.type(a)==="function"},isArray:Array.isArray||function(a){return e.type(a)==="array"},isWindow:function(a){return a&&typeof a=="object"&&"setInterval"in a},isNaN:function(a){return a==null||!m.test(a)||isNaN(a)},type:function(a){return a==null?String(a):I[C.call(a)]||"object"},isPlainObject:function(a){if(!a||e.type(a)!=="object"||a.nodeType||e.isWindow(a))return!1;if(a.constructor&&!D.call(a,"constructor")&&!D.call(a.constructor.prototype,"isPrototypeOf"))return!1;var c;for(c in a);return c===b||D.call(a,c)},isEmptyObject:function(a){for(var b in a)return!1;return!0},error:function(a){throw a},parseJSON:function(b){if(typeof b!="string"||!b)return null;b=e.trim(b);if(a.JSON&&a.JSON.parse)return a.JSON.parse(b);if(o.test(b.replace(p,"@").replace(q,"]").replace(r,"")))return(new Function("return "+b))();e.error("Invalid JSON: "+b)},parseXML:function(b,c,d){a.DOMParser?(d=new DOMParser,c=d.parseFromString(b,"text/xml")):(c=new ActiveXObject("Microsoft.XMLDOM"),c.async="false",c.loadXML(b)),d=c.documentElement,(!d||!d.nodeName||d.nodeName==="parsererror")&&e.error("Invalid XML: "+b);return c},noop:function(){},globalEval:function(b){b&&j.test(b)&&(a.execScript||function(b){a.eval.call(a,b)})(b)},camelCase:function(a){return a.replace(w,x)},nodeName:function(a,b){return a.nodeName&&a.nodeName.toUpperCase()===b.toUpperCase()},each:function(a,c,d){var f,g=0,h=a.length,i=h===b||e.isFunction(a);if(d){if(i){for(f in a)if(c.apply(a[f],d)===!1)break}else for(;g<h;)if(c.apply(a[g++],d)===!1)break}else if(i){for(f in a)if(c.call(a[f],f,a[f])===!1)break}else for(;g<h;)if(c.call(a[g],g,a[g++])===!1)break;return a},trim:G?function(a){return a==null?"":G.call(a)}:function(a){return a==null?"":(a+"").replace(k,"").replace(l,"")},makeArray:function(a,b){var c=b||[];if(a!=null){var d=e.type(a);a.length==null||d==="string"||d==="function"||d==="regexp"||e.isWindow(a)?E.call(c,a):e.merge(c,a)}return c},inArray:function(a,b){if(H)return H.call(b,a);for(var c=0,d=b.length;c<d;c++)if(b[c]===a)return c;return-1},merge:function(a,c){var d=a.length,e=0;if(typeof c.length=="number")for(var f=c.length;e<f;e++)a[d++]=c[e];else while(c[e]!==b)a[d++]=c[e++];a.length=d;return a},grep:function(a,b,c){var d=[],e;c=!!c;for(var f=0,g=a.length;f<g;f++)e=!!b(a[f],f),c!==e&&d.push(a[f]);return d},map:function(a,c,d){var f,g,h=[],i=0,j=a.length,k=a instanceof e||j!==b&&typeof j=="number"&&(j>0&&a[0]&&a[j-1]||j===0||e.isArray(a));if(k)for(;i<j;i++)f=c(a[i],i,d),f!=null&&(h[h.length]=f);else for(g in a)f=c(a[g],g,d),f!=null&&(h[h.length]=f);return h.concat.apply([],h)},guid:1,proxy:function(a,c){if(typeof c=="string"){var d=a[c];c=a,a=d}if(!e.isFunction(a))return b;var f=F.call(arguments,2),g=function(){return a.apply(c,f.concat(F.call(arguments)))};g.guid=a.guid=a.guid||g.guid||e.guid++;return g},access:function(a,c,d,f,g,h){var i=a.length;if(typeof c=="object"){for(var j in c)e.access(a,j,c[j],f,g,d);return a}if(d!==b){f=!h&&f&&e.isFunction(d);for(var k=0;k<i;k++)g(a[k],c,f?d.call(a[k],k,g(a[k],c)):d,h);return a}return i?g(a[0],c):b},now:function(){return(new Date).getTime()},uaMatch:function(a){a=a.toLowerCase();var b=s.exec(a)||t.exec(a)||u.exec(a)||a.indexOf("compatible")<0&&v.exec(a)||[];return{browser:b[1]||"",version:b[2]||"0"}},sub:function(){function a(b,c){return new a.fn.init(b,c)}e.extend(!0,a,this),a.superclass=this,a.fn=a.prototype=this(),a.fn.constructor=a,a.sub=this.sub,a.fn.init=function(d,f){f&&f instanceof e&&!(f instanceof a)&&(f=a(f));return e.fn.init.call(this,d,f,b)},a.fn.init.prototype=a.fn;var b=a(c);return a},browser:{}}),e.each("Boolean Number String Function Array Date RegExp Object".split(" "),function(a,b){I["[object "+b+"]"]=b.toLowerCase()}),z=e.uaMatch(y),z.browser&&(e.browser[z.browser]=!0,e.browser.version=z.version),e.browser.webkit&&(e.browser.safari=!0),j.test(" ")&&(k=/^[\s\xA0]+/,l=/[\s\xA0]+$/),h=e(c),c.addEventListener?B=function(){c.removeEventListener("DOMContentLoaded",B,!1),e.ready()}:c.attachEvent&&(B=function(){c.readyState==="complete"&&(c.detachEvent("onreadystatechange",B),e.ready())});return e}(),g="done fail isResolved isRejected promise then always pipe".split(" "),h=[].slice;f.extend({_Deferred:function(){var a=[],b,c,d,e={done:function(){if(!d){var c=arguments,g,h,i,j,k;b&&(k=b,b=0);for(g=0,h=c.length;g<h;g++)i=c[g],j=f.type(i),j==="array"?e.done.apply(e,i):j==="function"&&a.push(i);k&&e.resolveWith(k[0],k[1])}return this},resolveWith:function(e,f){if(!d&&!b&&!c){f=f||[],c=1;try{while(a[0])a.shift().apply(e,f)}finally{b=[e,f],c=0}}return this},resolve:function(){e.resolveWith(this,arguments);return this},isResolved:function(){return!!c||!!b},cancel:function(){d=1,a=[];return this}};return e},Deferred:function(a){var b=f._Deferred(),c=f._Deferred(),d;f.extend(b,{then:function(a,c){b.done(a).fail(c);return this},always:function(){return b.done.apply(b,arguments).fail.apply(this,arguments)},fail:c.done,rejectWith:c.resolveWith,reject:c.resolve,isRejected:c.isResolved,pipe:function(a,c){return f.Deferred(function(d){f.each({done:[a,"resolve"],fail:[c,"reject"]},function(a,c){var e=c[0],g=c[1],h;f.isFunction(e)?b[a](function(){h=e.apply(this,arguments),h&&f.isFunction(h.promise)?h.promise().then(d.resolve,d.reject):d[g](h)}):b[a](d[g])})}).promise()},promise:function(a){if(a==null){if(d)return d;d=a={}}var c=g.length;while(c--)a[g[c]]=b[g[c]];return a}}),b.done(c.cancel).fail(b.cancel),delete b.cancel,a&&a.call(b,b);return b},when:function(a){function i(a){return function(c){b[a]=arguments.length>1?h.call(arguments,0):c,--e||g.resolveWith(g,h.call(b,0))}}var b=arguments,c=0,d=b.length,e=d,g=d<=1&&a&&f.isFunction(a.promise)?a:f.Deferred();if(d>1){for(;c<d;c++)b[c]&&f.isFunction(b[c].promise)?b[c].promise().then(i(c),g.reject):--e;e||g.resolveWith(g,b)}else g!==a&&g.resolveWith(g,d?[a]:[]);return g.promise()}}),f.support=function(){var a=c.createElement("div"),b=c.documentElement,d,e,g,h,i,j,k,l,m,n,o,p,q,r,s,t,u;a.setAttribute("className","t"),a.innerHTML="   <link/><table></table><a href='/a' style='top:1px;float:left;opacity:.55;'>a</a><input type='checkbox'/>",d=a.getElementsByTagName("*"),e=a.getElementsByTagName("a")[0];if(!d||!d.length||!e)return{};g=c.createElement("select"),h=g.appendChild(c.createElement("option")),i=a.getElementsByTagName("input")[0],k={leadingWhitespace:a.firstChild.nodeType===3,tbody:!a.getElementsByTagName("tbody").length,htmlSerialize:!!a.getElementsByTagName("link").length,style:/top/.test(e.getAttribute("style")),hrefNormalized:e.getAttribute("href")==="/a",opacity:/^0.55$/.test(e.style.opacity),cssFloat:!!e.style.cssFloat,checkOn:i.value==="on",optSelected:h.selected,getSetAttribute:a.className!=="t",submitBubbles:!0,changeBubbles:!0,focusinBubbles:!1,deleteExpando:!0,noCloneEvent:!0,inlineBlockNeedsLayout:!1,shrinkWrapBlocks:!1,reliableMarginRight:!0},i.checked=!0,k.noCloneChecked=i.cloneNode(!0).checked,g.disabled=!0,k.optDisabled=!h.disabled;try{delete a.test}catch(v){k.deleteExpando=!1}!a.addEventListener&&a.attachEvent&&a.fireEvent&&(a.attachEvent("onclick",function(){k.noCloneEvent=!1}),a.cloneNode(!0).fireEvent("onclick")),i=c.createElement("input"),i.value="t",i.setAttribute("type","radio"),k.radioValue=i.value==="t",i.setAttribute("checked","checked"),a.appendChild(i),l=c.createDocumentFragment(),l.appendChild(a.firstChild),k.checkClone=l.cloneNode(!0).cloneNode(!0).lastChild.checked,a.innerHTML="",a.style.width=a.style.paddingLeft="1px",m=c.getElementsByTagName("body")[0],o=c.createElement(m?"div":"body"),p={visibility:"hidden",width:0,height:0,border:0,margin:0},m&&f.extend(p,{position:"absolute",left:-1e3,top:-1e3});for(t in p)o.style[t]=p[t];o.appendChild(a),n=m||b,n.insertBefore(o,n.firstChild),k.appendChecked=i.checked,k.boxModel=a.offsetWidth===2,"zoom"in a.style&&(a.style.display="inline",a.style.zoom=1,k.inlineBlockNeedsLayout=a.offsetWidth===2,a.style.display="",a.innerHTML="<div style='width:4px;'></div>",k.shrinkWrapBlocks=a.offsetWidth!==2),a.innerHTML="<table><tr><td style='padding:0;border:0;display:none'></td><td>t</td></tr></table>",q=a.getElementsByTagName("td"),u=q[0].offsetHeight===0,q[0].style.display="",q[1].style.display="none",k.reliableHiddenOffsets=u&&q[0].offsetHeight===0,a.innerHTML="",c.defaultView&&c.defaultView.getComputedStyle&&(j=c.createElement("div"),j.style.width="0",j.style.marginRight="0",a.appendChild(j),k.reliableMarginRight=(parseInt((c.defaultView.getComputedStyle(j,null)||{marginRight:0}).marginRight,10)||0)===0),o.innerHTML="",n.removeChild(o);if(a.attachEvent)for(t in{submit:1,change:1,focusin:1})s="on"+t,u=s in a,u||(a.setAttribute(s,"return;"),u=typeof a[s]=="function"),k[t+"Bubbles"]=u;o=l=g=h=m=j=a=i=null;return k}(),f.boxModel=f.support.boxModel;var i=/^(?:\{.*\}|\[.*\])$/,j=/([a-z])([A-Z])/g;f.extend({cache:{},uuid:0,expando:"jQuery"+(f.fn.jquery+Math.random()).replace(/\D/g,""),noData:{embed:!0,object:"clsid:D27CDB6E-AE6D-11cf-96B8-444553540000",applet:!0},hasData:function(a){a=a.nodeType?f.cache[a[f.expando]]:a[f.expando];return!!a&&!l(a)},data:function(a,c,d,e){if(!!f.acceptData(a)){var g=f.expando,h=typeof c=="string",i,j=a.nodeType,k=j?f.cache:a,l=j?a[f.expando]:a[f.expando]&&f.expando;if((!l||e&&l&&!k[l][g])&&h&&d===b)return;l||(j?a[f.expando]=l=++f.uuid:l=f.expando),k[l]||(k[l]={},j||(k[l].toJSON=f.noop));if(typeof c=="object"||typeof c=="function")e?k[l][g]=f.extend(k[l][g],c):k[l]=f.extend(k[l],c);i=k[l],e&&(i[g]||(i[g]={}),i=i[g]),d!==b&&(i[f.camelCase(c)]=d);if(c==="events"&&!i[c])return i[g]&&i[g].events;return h?i[f.camelCase(c)]||i[c]:i}},removeData:function(b,c,d){if(!!f.acceptData(b)){var e=f.expando,g=b.nodeType,h=g?f.cache:b,i=g?b[f.expando]:f.expando;if(!h[i])return;if(c){var j=d?h[i][e]:h[i];if(j){delete j[c];if(!l(j))return}}if(d){delete h[i][e];if(!l(h[i]))return}var k=h[i][e];f.support.deleteExpando||h!=a?delete h[i]:h[i]=null,k?(h[i]={},g||(h[i].toJSON=f.noop),h[i][e]=k):g&&(f.support.deleteExpando?delete b[f.expando]:b.removeAttribute?b.removeAttribute(f.expando):b[f.expando]=null)}},_data:function(a,b,c){return f.data(a,b,c,!0)},acceptData:function(a){if(a.nodeName){var b=f.noData[a.nodeName.toLowerCase()];if(b)return b!==!0&&a.getAttribute("classid")===b}return!0}}),f.fn.extend({data:function(a,c){var d=null;if(typeof a=="undefined"){if(this.length){d=f.data(this[0]);if(this[0].nodeType===1){var e=this[0].attributes,g;for(var h=0,i=e.length;h<i;h++)g=e[h].name,g.indexOf("data-")===0&&(g=f.camelCase(g.substring(5)),k(this[0],g,d[g]))}}return d}if(typeof a=="object")return this.each(function(){f.data(this,a)});var j=a.split(".");j[1]=j[1]?"."+j[1]:"";if(c===b){d=this.triggerHandler("getData"+j[1]+"!",[j[0]]),d===b&&this.length&&(d=f.data(this[0],a),d=k(this[0],a,d));return d===b&&j[1]?this.data(j[0]):d}return this.each(function(){var b=f(this),d=[j[0],c];b.triggerHandler("setData"+j[1]+"!",d),f.data(this,a,c),b.triggerHandler("changeData"+j[1]+"!",d)})},removeData:function(a){return this.each(function(){f.removeData(this,a)})}}),f.extend({_mark:function(a,c){a&&(c=(c||"fx")+"mark",f.data(a,c,(f.data(a,c,b,!0)||0)+1,!0))},_unmark:function(a,c,d){a!==!0&&(d=c,c=a,a=!1);if(c){d=d||"fx";var e=d+"mark",g=a?0:(f.data(c,e,b,!0)||1)-1;g?f.data(c,e,g,!0):(f.removeData(c,e,!0),m(c,d,"mark"))}},queue:function(a,c,d){if(a){c=(c||"fx")+"queue";var e=f.data(a,c,b,!0);d&&(!e||f.isArray(d)?e=f.data(a,c,f.makeArray(d),!0):e.push(d));return e||[]}},dequeue:function(a,b){b=b||"fx";var c=f.queue(a,b),d=c.shift(),e;d==="inprogress"&&(d=c.shift()),d&&(b==="fx"&&c.unshift("inprogress"),d.call(a,function(){f.dequeue(a,b)})),c.length||(f.removeData(a,b+"queue",!0),m(a,b,"queue"))}}),f.fn.extend({queue:function(a,c){typeof a!="string"&&(c=a,a="fx");if(c===b)return f.queue(this[0],a);return this.each(function(){var b=f.queue(this,a,c);a==="fx"&&b[0]!=="inprogress"&&f.dequeue(this,a)})},dequeue:function(a){return this.each(function(){f.dequeue(this,a)})},delay:function(a,b){a=f.fx?f.fx.speeds[a]||a:a,b=b||"fx";return this.queue(b,function(){var c=this;setTimeout(function(){f.dequeue(c,b)},a)})},clearQueue:function(a){return this.queue(a||"fx",[])},promise:function(a,c){function m(){--h||d.resolveWith(e,[e])}typeof a!="string"&&(c=a,a=b),a=a||"fx";var d=f.Deferred(),e=this,g=e.length,h=1,i=a+"defer",j=a+"queue",k=a+"mark",l;while(g--)if(l=f.data(e[g],i,b,!0)||(f.data(e[g],j,b,!0)||f.data(e[g],k,b,!0))&&f.data(e[g],i,f._Deferred(),!0))h++,l.done(m);m();return d.promise()}});var n=/[\n\t\r]/g,o=/\s+/,p=/\r/g,q=/^(?:button|input)$/i,r=/^(?:button|input|object|select|textarea)$/i,s=/^a(?:rea)?$/i,t=/^(?:autofocus|autoplay|async|checked|controls|defer|disabled|hidden|loop|multiple|open|readonly|required|scoped|selected)$/i,u=/\:|^on/,v,w;f.fn.extend({attr:function(a,b){return f.access(this,a,b,!0,f.attr)},removeAttr:function(a){return this.each(function(){f.removeAttr(this,a)})},prop:function(a,b){return f.access(this,a,b,!0,f.prop)},removeProp:function(a){a=f.propFix[a]||a;return this.each(function(){try{this[a]=b,delete this[a]}catch(c){}})},addClass:function(a){var b,c,d,e,g,h,i;if(f.isFunction(a))return this.each(function(b){f(this).addClass(a.call(this,b,this.className))});if(a&&typeof a=="string"){b=a.split(o);for(c=0,d=this.length;c<d;c++){e=this[c];if(e.nodeType===1)if(!e.className&&b.length===1)e.className=a;else{g=" "+e.className+" ";for(h=0,i=b.length;h<i;h++)~g.indexOf(" "+b[h]+" ")||(g+=b[h]+" ");e.className=f.trim(g)}}}return this},removeClass:function(a){var c,d,e,g,h,i,j;if(f.isFunction(a))return this.each(function(b){f(this).removeClass(a.call(this,b,this.className))});if(a&&typeof a=="string"||a===b){c=(a||"").split(o);for(d=0,e=this.length;d<e;d++){g=this[d];if(g.nodeType===1&&g.className)if(a){h=(" "+g.className+" ").replace(n," ");for(i=0,j=c.length;i<j;i++)h=h.replace(" "+c[i]+" "," ");g.className=f.trim(h)}else g.className=""}}return this},toggleClass:function(a,b){var c=typeof a,d=typeof b=="boolean";if(f.isFunction(a))return this.each(function(c){f(this).toggleClass(a.call(this,c,this.className,b),b)});return this.each(function(){if(c==="string"){var e,g=0,h=f(this),i=b,j=a.split(o);while(e=j[g++])i=d?i:!h.hasClass(e),h[i?"addClass":"removeClass"](e)}else if(c==="undefined"||c==="boolean")this.className&&f._data(this,"__className__",this.className),this.className=this.className||a===!1?"":f._data(this,"__className__")||""})},hasClass:function(a){var b=" "+a+" ";for(var c=0,d=this.length;c<d;c++)if((" "+this[c].className+" ").replace(n," ").indexOf(b)>-1)return!0;return!1},val:function(a){var c,d,e=this[0];if(!arguments.length){if(e){c=f.valHooks[e.nodeName.toLowerCase()]||f.valHooks[e.type];if(c&&"get"in c&&(d=c.get(e,"value"))!==b)return d;d=e.value;return typeof d=="string"?d.replace(p,""):d==null?"":d}return b}var g=f.isFunction(a);return this.each(function(d){var e=f(this),h;if(this.nodeType===1){g?h=a.call(this,d,e.val()):h=a,h==null?h="":typeof h=="number"?h+="":f.isArray(h)&&(h=f.map(h,function(a){return a==null?"":a+""})),c=f.valHooks[this.nodeName.toLowerCase()]||f.valHooks[this.type];if(!c||!("set"in c)||c.set(this,h,"value")===b)this.value=h}})}}),f.extend({valHooks:{option:{get:function(a){var b=a.attributes.value;return!b||b.specified?a.value:a.text}},select:{get:function(a){var b,c=a.selectedIndex,d=[],e=a.options,g=a.type==="select-one";if(c<0)return null;for(var h=g?c:0,i=g?c+1:e.length;h<i;h++){var j=e[h];if(j.selected&&(f.support.optDisabled?!j.disabled:j.getAttribute("disabled")===null)&&(!j.parentNode.disabled||!f.nodeName(j.parentNode,"optgroup"))){b=f(j).val();if(g)return b;d.push(b)}}if(g&&!d.length&&e.length)return f(e[c]).val();return d},set:function(a,b){var c=f.makeArray(b);f(a).find("option").each(function(){this.selected=f.inArray(f(this).val(),c)>=0}),c.length||(a.selectedIndex=-1);return c}}},attrFn:{val:!0,css:!0,html:!0,text:!0,data:!0,width:!0,height:!0,offset:!0},attrFix:{tabindex:"tabIndex"},attr:function(a,c,d,e){var g=a.nodeType;if(!a||g===3||g===8||g===2)return b;if(e&&c in f.attrFn)return f(a)[c](d);if(!("getAttribute"in a))return f.prop(a,c,d);var h,i,j=g!==1||!f.isXMLDoc(a);j&&(c=f.attrFix[c]||c,i=f.attrHooks[c],i||(t.test(c)?i=w:v&&c!=="className"&&(f.nodeName(a,"form")||u.test(c))&&(i=v)));if(d!==b){if(d===null){f.removeAttr(a,c);return b}if(i&&"set"in i&&j&&(h=i.set(a,d,c))!==b)return h;a.setAttribute(c,""+d);return d}if(i&&"get"in i&&j&&(h=i.get(a,c))!==null)return h;h=a.getAttribute(c);return h===null?b:h},removeAttr:function(a,b){var c;a.nodeType===1&&(b=f.attrFix[b]||b,f.support.getSetAttribute?a.removeAttribute(b):(f.attr(a,b,""),a.removeAttributeNode(a.getAttributeNode(b))),t.test(b)&&(c=f.propFix[b]||b)in a&&(a[c]=!1))},attrHooks:{type:{set:function(a,b){if(q.test(a.nodeName)&&a.parentNode)f.error("type property can't be changed");else if(!f.support.radioValue&&b==="radio"&&f.nodeName(a,"input")){var c=a.value;a.setAttribute("type",b),c&&(a.value=c);return b}}},tabIndex:{get:function(a){var c=a.getAttributeNode("tabIndex");return c&&c.specified?parseInt(c.value,10):r.test(a.nodeName)||s.test(a.nodeName)&&a.href?0:b}},value:{get:function(a,b){if(v&&f.nodeName(a,"button"))return v.get(a,b);return b in a?a.value:null},set:function(a,b,c){if(v&&f.nodeName(a,"button"))return v.set(a,b,c);a.value=b}}},propFix:{tabindex:"tabIndex",readonly:"readOnly","for":"htmlFor","class":"className",maxlength:"maxLength",cellspacing:"cellSpacing",cellpadding:"cellPadding",rowspan:"rowSpan",colspan:"colSpan",usemap:"useMap",frameborder:"frameBorder",contenteditable:"contentEditable"},prop:function(a,c,d){var e=a.nodeType;if(!a||e===3||e===8||e===2)return b;var g,h,i=e!==1||!f.isXMLDoc(a);i&&(c=f.propFix[c]||c,h=f.propHooks[c]);return d!==b?h&&"set"in h&&(g=h.set(a,d,c))!==b?g:a[c]=d:h&&"get"in h&&(g=h.get(a,c))!==b?g:a[c]},propHooks:{}}),w={get:function(a,c){return f.prop(a,c)?c.toLowerCase():b},set:function(a,b,c){var d;b===!1?f.removeAttr(a,c):(d=f.propFix[c]||c,d in a&&(a[d]=!0),a.setAttribute(c,c.toLowerCase()));return c}},f.support.getSetAttribute||(f.attrFix=f.propFix,v=f.attrHooks.name=f.attrHooks.title=f.valHooks.button={get:function(a,c){var d;d=a.getAttributeNode(c);return d&&d.nodeValue!==""?d.nodeValue:b},set:function(a,b,c){var d=a.getAttributeNode(c);if(d){d.nodeValue=b;return b}}},f.each(["width","height"],function(a,b){f.attrHooks[b]=f.extend(f.attrHooks[b],{set:function(a,c){if(c===""){a.setAttribute(b,"auto");return c}}})})),f.support.hrefNormalized||f.each(["href","src","width","height"],function(a,c){f.attrHooks[c]=f.extend(f.attrHooks[c],{get:function(a){var d=a.getAttribute(c,2);return d===null?b:d}})}),f.support.style||(f.attrHooks.style={get:function(a){return a.style.cssText.toLowerCase()||b},set:function(a,b){return a.style.cssText=""+b}}),f.support.optSelected||(f.propHooks.selected=f.extend(f.propHooks.selected,{get:function(a){var b=a.parentNode;b&&(b.selectedIndex,b.parentNode&&b.parentNode.selectedIndex)}})),f.support.checkOn||f.each(["radio","checkbox"],function(){f.valHooks[this]={get:function(a){return a.getAttribute("value")===null?"on":a.value}}}),f.each(["radio","checkbox"],function(){f.valHooks[this]=f.extend(f.valHooks[this],{set:function(a,b){if(f.isArray(b))return a.checked=f.inArray(f(a).val(),b)>=0}})});var x=/\.(.*)$/,y=/^(?:textarea|input|select)$/i,z=/\./g,A=/ /g,B=/[^\w\s.|`]/g,C=function(a){return a.replace(B,"\\$&")};f.event={add:function(a,c,d,e){if(a.nodeType!==3&&a.nodeType!==8){if(d===!1)d=D;else if(!d)return;var g,h;d.handler&&(g=d,d=g.handler),d.guid||(d.guid=f.guid++);var i=f._data(a);if(!i)return;var j=i.events,k=i.handle;j||(i.events=j={}),k||(i.handle=k=function(a){return typeof f!="undefined"&&(!a||f.event.triggered!==a.type)?f.event.handle.apply(k.elem,arguments):b}),k.elem=a,c=c.split(" ");var l,m=0,n;while(l=c[m++]){h=g?f.extend({},g):{handler:d,data:e},l.indexOf(".")>-1?(n=l.split("."),l=n.shift(),h.namespace=n.slice(0).sort().join(".")):(n=[],h.namespace=""),h.type=l,h.guid||(h.guid=d.guid);var o=j[l],p=f.event.special[l]||{};if(!o){o=j[l]=[];if(!p.setup||p.setup.call(a,e,n,k)===!1)a.addEventListener?a.addEventListener(l,k,!1):a.attachEvent&&a.attachEvent("on"+l,k)}p.add&&(p.add.call(a,h),h.handler.guid||(h.handler.guid=d.guid)),o.push(h),f.event.global[l]=!0}a=null}},global:{},remove:function(a,c,d,e){if(a.nodeType!==3&&a.nodeType!==8){d===!1&&(d=D);var g,h,i,j,k=0,l,m,n,o,p,q,r,s=f.hasData(a)&&f._data(a),t=s&&s.events;if(!s||!t)return;c&&c.type&&(d=c.handler,c=c.type);if(!c||typeof c=="string"&&c.charAt(0)==="."){c=c||"";for(h in t)f.event.remove(a,h+c);return}c=c.split(" ");while(h=c[k++]){r=h,q=null,l=h.indexOf(".")<0,m=[],l||(m=h.split("."),h=m.shift(),n=new RegExp("(^|\\.)"+f.map(m.slice(0).sort(),C).join("\\.(?:.*\\.)?")+"(\\.|$)")),p=t[h];if(!p)continue;if(!d){for(j=0;j<p.length;j++){q=p[j];if(l||n.test(q.namespace))f.event.remove(a,r,q.handler,j),p.splice(j--,1)}continue}o=f.event.special[h]||{};for(j=e||0;j<p.length;j++){q=p[j];if(d.guid===q.guid){if(l||n.test(q.namespace))e==null&&p.splice(j--,1),o.remove&&o.remove.call(a,q);if(e!=null)break}}if(p.length===0||e!=null&&p.length===1)(!o.teardown||o.teardown.call(a,m)===!1)&&f.removeEvent(a,h,s.handle),g=null,delete t[h]}if(f.isEmptyObject(t)){var u=s.handle;u&&(u.elem=null),delete s.events,delete s.handle,f.isEmptyObject(s)&&f.removeData(a,b,!0)}}},customEvent:{getData:!0,setData:!0,changeData:!0},trigger:function(c,d,e,g){var h=c.type||c,i=[],j;h.indexOf("!")>=0&&(h=h.slice(0,-1),j=!0),h.indexOf(".")>=0&&(i=h.split("."),h=i.
		shift(),i.sort());if(!!e&&!f.event.customEvent[h]||!!f.event.global[h]){c=typeof c=="object"?c[f.expando]?c:new f.Event(h,c):new f.Event(h),c.type=h,c.exclusive=j,c.namespace=i.join("."),c.namespace_re=new RegExp("(^|\\.)"+i.join("\\.(?:.*\\.)?")+"(\\.|$)");if(g||!e)c.preventDefault(),c.stopPropagation();if(!e){f.each(f.cache,function(){var a=f.expando,b=this[a];b&&b.events&&b.events[h]&&f.event.trigger(c,d,b.handle.elem)});return}if(e.nodeType===3||e.nodeType===8)return;c.result=b,c.target=e,d=d!=null?f.makeArray(d):[],d.unshift(c);var k=e,l=h.indexOf(":")<0?"on"+h:"";do{var m=f._data(k,"handle");c.currentTarget=k,m&&m.apply(k,d),l&&f.acceptData(k)&&k[l]&&k[l].apply(k,d)===!1&&(c.result=!1,c.preventDefault()),k=k.parentNode||k.ownerDocument||k===c.target.ownerDocument&&a}while(k&&!c.isPropagationStopped());if(!c.isDefaultPrevented()){var n,o=f.event.special[h]||{};if((!o._default||o._default.call(e.ownerDocument,c)===!1)&&(h!=="click"||!f.nodeName(e,"a"))&&f.acceptData(e)){try{l&&e[h]&&(n=e[l],n&&(e[l]=null),f.event.triggered=h,e[h]())}catch(p){}n&&(e[l]=n),f.event.triggered=b}}return c.result}},handle:function(c){c=f.event.fix(c||a.event);var d=((f._data(this,"events")||{})[c.type]||[]).slice(0),e=!c.exclusive&&!c.namespace,g=Array.prototype.slice.call(arguments,0);g[0]=c,c.currentTarget=this;for(var h=0,i=d.length;h<i;h++){var j=d[h];if(e||c.namespace_re.test(j.namespace)){c.handler=j.handler,c.data=j.data,c.handleObj=j;var k=j.handler.apply(this,g);k!==b&&(c.result=k,k===!1&&(c.preventDefault(),c.stopPropagation()));if(c.isImmediatePropagationStopped())break}}return c.result},props:"altKey attrChange attrName bubbles button cancelable charCode clientX clientY ctrlKey currentTarget data detail eventPhase fromElement handler keyCode layerX layerY metaKey newValue offsetX offsetY pageX pageY prevValue relatedNode relatedTarget screenX screenY shiftKey srcElement target toElement view wheelDelta which".split(" "),fix:function(a){if(a[f.expando])return a;var d=a;a=f.Event(d);for(var e=this.props.length,g;e;)g=this.props[--e],a[g]=d[g];a.target||(a.target=a.srcElement||c),a.target.nodeType===3&&(a.target=a.target.parentNode),!a.relatedTarget&&a.fromElement&&(a.relatedTarget=a.fromElement===a.target?a.toElement:a.fromElement);if(a.pageX==null&&a.clientX!=null){var h=a.target.ownerDocument||c,i=h.documentElement,j=h.body;a.pageX=a.clientX+(i&&i.scrollLeft||j&&j.scrollLeft||0)-(i&&i.clientLeft||j&&j.clientLeft||0),a.pageY=a.clientY+(i&&i.scrollTop||j&&j.scrollTop||0)-(i&&i.clientTop||j&&j.clientTop||0)}a.which==null&&(a.charCode!=null||a.keyCode!=null)&&(a.which=a.charCode!=null?a.charCode:a.keyCode),!a.metaKey&&a.ctrlKey&&(a.metaKey=a.ctrlKey),!a.which&&a.button!==b&&(a.which=a.button&1?1:a.button&2?3:a.button&4?2:0);return a},guid:1e8,proxy:f.proxy,special:{ready:{setup:f.bindReady,teardown:f.noop},live:{add:function(a){f.event.add(this,N(a.origType,a.selector),f.extend({},a,{handler:M,guid:a.handler.guid}))},remove:function(a){f.event.remove(this,N(a.origType,a.selector),a)}},beforeunload:{setup:function(a,b,c){f.isWindow(this)&&(this.onbeforeunload=c)},teardown:function(a,b){this.onbeforeunload===b&&(this.onbeforeunload=null)}}}},f.removeEvent=c.removeEventListener?function(a,b,c){a.removeEventListener&&a.removeEventListener(b,c,!1)}:function(a,b,c){a.detachEvent&&a.detachEvent("on"+b,c)},f.Event=function(a,b){if(!this.preventDefault)return new f.Event(a,b);a&&a.type?(this.originalEvent=a,this.type=a.type,this.isDefaultPrevented=a.defaultPrevented||a.returnValue===!1||a.getPreventDefault&&a.getPreventDefault()?E:D):this.type=a,b&&f.extend(this,b),this.timeStamp=f.now(),this[f.expando]=!0},f.Event.prototype={preventDefault:function(){this.isDefaultPrevented=E;var a=this.originalEvent;!a||(a.preventDefault?a.preventDefault():a.returnValue=!1)},stopPropagation:function(){this.isPropagationStopped=E;var a=this.originalEvent;!a||(a.stopPropagation&&a.stopPropagation(),a.cancelBubble=!0)},stopImmediatePropagation:function(){this.isImmediatePropagationStopped=E,this.stopPropagation()},isDefaultPrevented:D,isPropagationStopped:D,isImmediatePropagationStopped:D};var F=function(a){var b=a.relatedTarget,c=!1,d=a.type;a.type=a.data,b!==this&&(b&&(c=f.contains(this,b)),c||(f.event.handle.apply(this,arguments),a.type=d))},G=function(a){a.type=a.data,f.event.handle.apply(this,arguments)};f.each({mouseenter:"mouseover",mouseleave:"mouseout"},function(a,b){f.event.special[a]={setup:function(c){f.event.add(this,b,c&&c.selector?G:F,a)},teardown:function(a){f.event.remove(this,b,a&&a.selector?G:F)}}}),f.support.submitBubbles||(f.event.special.submit={setup:function(a,b){if(!f.nodeName(this,"form"))f.event.add(this,"click.specialSubmit",function(a){var b=a.target,c=b.type;(c==="submit"||c==="image")&&f(b).closest("form").length&&K("submit",this,arguments)}),f.event.add(this,"keypress.specialSubmit",function(a){var b=a.target,c=b.type;(c==="text"||c==="password")&&f(b).closest("form").length&&a.keyCode===13&&K("submit",this,arguments)});else return!1},teardown:function(a){f.event.remove(this,".specialSubmit")}});if(!f.support.changeBubbles){var H,I=function(a){var b=a.type,c=a.value;b==="radio"||b==="checkbox"?c=a.checked:b==="select-multiple"?c=a.selectedIndex>-1?f.map(a.options,function(a){return a.selected}).join("-"):"":f.nodeName(a,"select")&&(c=a.selectedIndex);return c},J=function(c){var d=c.target,e,g;if(!!y.test(d.nodeName)&&!d.readOnly){e=f._data(d,"_change_data"),g=I(d),(c.type!=="focusout"||d.type!=="radio")&&f._data(d,"_change_data",g);if(e===b||g===e)return;if(e!=null||g)c.type="change",c.liveFired=b,f.event.trigger(c,arguments[1],d)}};f.event.special.change={filters:{focusout:J,beforedeactivate:J,click:function(a){var b=a.target,c=f.nodeName(b,"input")?b.type:"";(c==="radio"||c==="checkbox"||f.nodeName(b,"select"))&&J.call(this,a)},keydown:function(a){var b=a.target,c=f.nodeName(b,"input")?b.type:"";(a.keyCode===13&&!f.nodeName(b,"textarea")||a.keyCode===32&&(c==="checkbox"||c==="radio")||c==="select-multiple")&&J.call(this,a)},beforeactivate:function(a){var b=a.target;f._data(b,"_change_data",I(b))}},setup:function(a,b){if(this.type==="file")return!1;for(var c in H)f.event.add(this,c+".specialChange",H[c]);return y.test(this.nodeName)},teardown:function(a){f.event.remove(this,".specialChange");return y.test(this.nodeName)}},H=f.event.special.change.filters,H.focus=H.beforeactivate}f.support.focusinBubbles||f.each({focus:"focusin",blur:"focusout"},function(a,b){function e(a){var c=f.event.fix(a);c.type=b,c.originalEvent={},f.event.trigger(c,null,c.target),c.isDefaultPrevented()&&a.preventDefault()}var d=0;f.event.special[b]={setup:function(){d++===0&&c.addEventListener(a,e,!0)},teardown:function(){--d===0&&c.removeEventListener(a,e,!0)}}}),f.each(["bind","one"],function(a,c){f.fn[c]=function(a,d,e){var g;if(typeof a=="object"){for(var h in a)this[c](h,d,a[h],e);return this}if(arguments.length===2||d===!1)e=d,d=b;c==="one"?(g=function(a){f(this).unbind(a,g);return e.apply(this,arguments)},g.guid=e.guid||f.guid++):g=e;if(a==="unload"&&c!=="one")this.one(a,d,e);else for(var i=0,j=this.length;i<j;i++)f.event.add(this[i],a,g,d);return this}}),f.fn.extend({unbind:function(a,b){if(typeof a=="object"&&!a.preventDefault)for(var c in a)this.unbind(c,a[c]);else for(var d=0,e=this.length;d<e;d++)f.event.remove(this[d],a,b);return this},delegate:function(a,b,c,d){return this.live(b,c,d,a)},undelegate:function(a,b,c){return arguments.length===0?this.unbind("live"):this.die(b,null,c,a)},trigger:function(a,b){return this.each(function(){f.event.trigger(a,b,this)})},triggerHandler:function(a,b){if(this[0])return f.event.trigger(a,b,this[0],!0)},toggle:function(a){var b=arguments,c=a.guid||f.guid++,d=0,e=function(c){var e=(f.data(this,"lastToggle"+a.guid)||0)%d;f.data(this,"lastToggle"+a.guid,e+1),c.preventDefault();return b[e].apply(this,arguments)||!1};e.guid=c;while(d<b.length)b[d++].guid=c;return this.click(e)},hover:function(a,b){return this.mouseenter(a).mouseleave(b||a)}});var L={focus:"focusin",blur:"focusout",mouseenter:"mouseover",mouseleave:"mouseout"};f.each(["live","die"],function(a,c){f.fn[c]=function(a,d,e,g){var h,i=0,j,k,l,m=g||this.selector,n=g?this:f(this.context);if(typeof a=="object"&&!a.preventDefault){for(var o in a)n[c](o,d,a[o],m);return this}if(c==="die"&&!a&&g&&g.charAt(0)==="."){n.unbind(g);return this}if(d===!1||f.isFunction(d))e=d||D,d=b;a=(a||"").split(" ");while((h=a[i++])!=null){j=x.exec(h),k="",j&&(k=j[0],h=h.replace(x,""));if(h==="hover"){a.push("mouseenter"+k,"mouseleave"+k);continue}l=h,L[h]?(a.push(L[h]+k),h=h+k):h=(L[h]||h)+k;if(c==="live")for(var p=0,q=n.length;p<q;p++)f.event.add(n[p],"live."+N(h,m),{data:d,selector:m,handler:e,origType:h,origHandler:e,preType:l});else n.unbind("live."+N(h,m),e)}return this}}),f.each("blur focus focusin focusout load resize scroll unload click dblclick mousedown mouseup mousemove mouseover mouseout mouseenter mouseleave change select submit keydown keypress keyup error".split(" "),function(a,b){f.fn[b]=function(a,c){c==null&&(c=a,a=null);return arguments.length>0?this.bind(b,a,c):this.trigger(b)},f.attrFn&&(f.attrFn[b]=!0)}),function(){function u(a,b,c,d,e,f){for(var g=0,h=d.length;g<h;g++){var i=d[g];if(i){var j=!1;i=i[a];while(i){if(i.sizcache===c){j=d[i.sizset];break}if(i.nodeType===1){f||(i.sizcache=c,i.sizset=g);if(typeof b!="string"){if(i===b){j=!0;break}}else if(k.filter(b,[i]).length>0){j=i;break}}i=i[a]}d[g]=j}}}function t(a,b,c,d,e,f){for(var g=0,h=d.length;g<h;g++){var i=d[g];if(i){var j=!1;i=i[a];while(i){if(i.sizcache===c){j=d[i.sizset];break}i.nodeType===1&&!f&&(i.sizcache=c,i.sizset=g);if(i.nodeName.toLowerCase()===b){j=i;break}i=i[a]}d[g]=j}}}var a=/((?:\((?:\([^()]+\)|[^()]+)+\)|\[(?:\[[^\[\]]*\]|['"][^'"]*['"]|[^\[\]'"]+)+\]|\\.|[^ >+~,(\[\\]+)+|[>+~])(\s*,\s*)?((?:.|\r|\n)*)/g,d=0,e=Object.prototype.toString,g=!1,h=!0,i=/\\/g,j=/\W/;[0,0].sort(function(){h=!1;return 0});var k=function(b,d,f,g){f=f||[],d=d||c;var h=d;if(d.nodeType!==1&&d.nodeType!==9)return[];if(!b||typeof b!="string")return f;var i,j,n,o,q,r,s,t,u=!0,w=k.isXML(d),x=[],y=b;do{a.exec(""),i=a.exec(y);if(i){y=i[3],x.push(i[1]);if(i[2]){o=i[3];break}}}while(i);if(x.length>1&&m.exec(b))if(x.length===2&&l.relative[x[0]])j=v(x[0]+x[1],d);else{j=l.relative[x[0]]?[d]:k(x.shift(),d);while(x.length)b=x.shift(),l.relative[b]&&(b+=x.shift()),j=v(b,j)}else{!g&&x.length>1&&d.nodeType===9&&!w&&l.match.ID.test(x[0])&&!l.match.ID.test(x[x.length-1])&&(q=k.find(x.shift(),d,w),d=q.expr?k.filter(q.expr,q.set)[0]:q.set[0]);if(d){q=g?{expr:x.pop(),set:p(g)}:k.find(x.pop(),x.length===1&&(x[0]==="~"||x[0]==="+")&&d.parentNode?d.parentNode:d,w),j=q.expr?k.filter(q.expr,q.set):q.set,x.length>0?n=p(j):u=!1;while(x.length)r=x.pop(),s=r,l.relative[r]?s=x.pop():r="",s==null&&(s=d),l.relative[r](n,s,w)}else n=x=[]}n||(n=j),n||k.error(r||b);if(e.call(n)==="[object Array]")if(!u)f.push.apply(f,n);else if(d&&d.nodeType===1)for(t=0;n[t]!=null;t++)n[t]&&(n[t]===!0||n[t].nodeType===1&&k.contains(d,n[t]))&&f.push(j[t]);else for(t=0;n[t]!=null;t++)n[t]&&n[t].nodeType===1&&f.push(j[t]);else p(n,f);o&&(k(o,h,f,g),k.uniqueSort(f));return f};k.uniqueSort=function(a){if(r){g=h,a.sort(r);if(g)for(var b=1;b<a.length;b++)a[b]===a[b-1]&&a.splice(b--,1)}return a},k.matches=function(a,b){return k(a,null,null,b)},k.matchesSelector=function(a,b){return k(b,null,null,[a]).length>0},k.find=function(a,b,c){var d;if(!a)return[];for(var e=0,f=l.order.length;e<f;e++){var g,h=l.order[e];if(g=l.leftMatch[h].exec(a)){var j=g[1];g.splice(1,1);if(j.substr(j.length-1)!=="\\"){g[1]=(g[1]||"").replace(i,""),d=l.find[h](g,b,c);if(d!=null){a=a.replace(l.match[h],"");break}}}}d||(d=typeof b.getElementsByTagName!="undefined"?b.getElementsByTagName("*"):[]);return{set:d,expr:a}},k.filter=function(a,c,d,e){var f,g,h=a,i=[],j=c,m=c&&c[0]&&k.isXML(c[0]);while(a&&c.length){for(var n in l.filter)if((f=l.leftMatch[n].exec(a))!=null&&f[2]){var o,p,q=l.filter[n],r=f[1];g=!1,f.splice(1,1);if(r.substr(r.length-1)==="\\")continue;j===i&&(i=[]);if(l.preFilter[n]){f=l.preFilter[n](f,j,d,i,e,m);if(!f)g=o=!0;else if(f===!0)continue}if(f)for(var s=0;(p=j[s])!=null;s++)if(p){o=q(p,f,s,j);var t=e^!!o;d&&o!=null?t?g=!0:j[s]=!1:t&&(i.push(p),g=!0)}if(o!==b){d||(j=i),a=a.replace(l.match[n],"");if(!g)return[];break}}if(a===h)if(g==null)k.error(a);else break;h=a}return j},k.error=function(a){throw"Syntax error, unrecognized expression: "+a};var l=k.selectors={order:["ID","NAME","TAG"],match:{ID:/#((?:[\w\u00c0-\uFFFF\-]|\\.)+)/,CLASS:/\.((?:[\w\u00c0-\uFFFF\-]|\\.)+)/,NAME:/\[name=['"]*((?:[\w\u00c0-\uFFFF\-]|\\.)+)['"]*\]/,ATTR:/\[\s*((?:[\w\u00c0-\uFFFF\-]|\\.)+)\s*(?:(\S?=)\s*(?:(['"])(.*?)\3|(#?(?:[\w\u00c0-\uFFFF\-]|\\.)*)|)|)\s*\]/,TAG:/^((?:[\w\u00c0-\uFFFF\*\-]|\\.)+)/,CHILD:/:(only|nth|last|first)-child(?:\(\s*(even|odd|(?:[+\-]?\d+|(?:[+\-]?\d*)?n\s*(?:[+\-]\s*\d+)?))\s*\))?/,POS:/:(nth|eq|gt|lt|first|last|even|odd)(?:\((\d*)\))?(?=[^\-]|$)/,PSEUDO:/:((?:[\w\u00c0-\uFFFF\-]|\\.)+)(?:\((['"]?)((?:\([^\)]+\)|[^\(\)]*)+)\2\))?/},leftMatch:{},attrMap:{"class":"className","for":"htmlFor"},attrHandle:{href:function(a){return a.getAttribute("href")},type:function(a){return a.getAttribute("type")}},relative:{"+":function(a,b){var c=typeof b=="string",d=c&&!j.test(b),e=c&&!d;d&&(b=b.toLowerCase());for(var f=0,g=a.length,h;f<g;f++)if(h=a[f]){while((h=h.previousSibling)&&h.nodeType!==1);a[f]=e||h&&h.nodeName.toLowerCase()===b?h||!1:h===b}e&&k.filter(b,a,!0)},">":function(a,b){var c,d=typeof b=="string",e=0,f=a.length;if(d&&!j.test(b)){b=b.toLowerCase();for(;e<f;e++){c=a[e];if(c){var g=c.parentNode;a[e]=g.nodeName.toLowerCase()===b?g:!1}}}else{for(;e<f;e++)c=a[e],c&&(a[e]=d?c.parentNode:c.parentNode===b);d&&k.filter(b,a,!0)}},"":function(a,b,c){var e,f=d++,g=u;typeof b=="string"&&!j.test(b)&&(b=b.toLowerCase(),e=b,g=t),g("parentNode",b,f,a,e,c)},"~":function(a,b,c){var e,f=d++,g=u;typeof b=="string"&&!j.test(b)&&(b=b.toLowerCase(),e=b,g=t),g("previousSibling",b,f,a,e,c)}},find:{ID:function(a,b,c){if(typeof b.getElementById!="undefined"&&!c){var d=b.getElementById(a[1]);return d&&d.parentNode?[d]:[]}},NAME:function(a,b){if(typeof b.getElementsByName!="undefined"){var c=[],d=b.getElementsByName(a[1]);for(var e=0,f=d.length;e<f;e++)d[e].getAttribute("name")===a[1]&&c.push(d[e]);return c.length===0?null:c}},TAG:function(a,b){if(typeof b.getElementsByTagName!="undefined")return b.getElementsByTagName(a[1])}},preFilter:{CLASS:function(a,b,c,d,e,f){a=" "+a[1].replace(i,"")+" ";if(f)return a;for(var g=0,h;(h=b[g])!=null;g++)h&&(e^(h.className&&(" "+h.className+" ").replace(/[\t\n\r]/g," ").indexOf(a)>=0)?c||d.push(h):c&&(b[g]=!1));return!1},ID:function(a){return a[1].replace(i,"")},TAG:function(a,b){return a[1].replace(i,"").toLowerCase()},CHILD:function(a){if(a[1]==="nth"){a[2]||k.error(a[0]),a[2]=a[2].replace(/^\+|\s*/g,"");var b=/(-?)(\d*)(?:n([+\-]?\d*))?/.exec(a[2]==="even"&&"2n"||a[2]==="odd"&&"2n+1"||!/\D/.test(a[2])&&"0n+"+a[2]||a[2]);a[2]=b[1]+(b[2]||1)-0,a[3]=b[3]-0}else a[2]&&k.error(a[0]);a[0]=d++;return a},ATTR:function(a,b,c,d,e,f){var g=a[1]=a[1].replace(i,"");!f&&l.attrMap[g]&&(a[1]=l.attrMap[g]),a[4]=(a[4]||a[5]||"").replace(i,""),a[2]==="~="&&(a[4]=" "+a[4]+" ");return a},PSEUDO:function(b,c,d,e,f){if(b[1]==="not")if((a.exec(b[3])||"").length>1||/^\w/.test(b[3]))b[3]=k(b[3],null,null,c);else{var g=k.filter(b[3],c,d,!0^f);d||e.push.apply(e,g);return!1}else if(l.match.POS.test(b[0])||l.match.CHILD.test(b[0]))return!0;return b},POS:function(a){a.unshift(!0);return a}},filters:{enabled:function(a){return a.disabled===!1&&a.type!=="hidden"},disabled:function(a){return a.disabled===!0},checked:function(a){return a.checked===!0},selected:function(a){a.parentNode&&a.parentNode.selectedIndex;return a.selected===!0},parent:function(a){return!!a.firstChild},empty:function(a){return!a.firstChild},has:function(a,b,c){return!!k(c[3],a).length},header:function(a){return/h\d/i.test(a.nodeName)},text:function(a){var b=a.getAttribute("type"),c=a.type;return a.nodeName.toLowerCase()==="input"&&"text"===c&&(b===c||b===null)},radio:function(a){return a.nodeName.toLowerCase()==="input"&&"radio"===a.type},checkbox:function(a){return a.nodeName.toLowerCase()==="input"&&"checkbox"===a.type},file:function(a){return a.nodeName.toLowerCase()==="input"&&"file"===a.type},password:function(a){return a.nodeName.toLowerCase()==="input"&&"password"===a.type},submit:function(a){var b=a.nodeName.toLowerCase();return(b==="input"||b==="button")&&"submit"===a.type},image:function(a){return a.nodeName.toLowerCase()==="input"&&"image"===a.type},reset:function(a){var b=a.nodeName.toLowerCase();return(b==="input"||b==="button")&&"reset"===a.type},button:function(a){var b=a.nodeName.toLowerCase();return b==="input"&&"button"===a.type||b==="button"},input:function(a){return/input|select|textarea|button/i.test(a.nodeName)},focus:function(a){return a===a.ownerDocument.activeElement}},setFilters:{first:function(a,b){return b===0},last:function(a,b,c,d){return b===d.length-1},even:function(a,b){return b%2===0},odd:function(a,b){return b%2===1},lt:function(a,b,c){return b<c[3]-0},gt:function(a,b,c){return b>c[3]-0},nth:function(a,b,c){return c[3]-0===b},eq:function(a,b,c){return c[3]-0===b}},filter:{PSEUDO:function(a,b,c,d){var e=b[1],f=l.filters[e];if(f)return f(a,c,b,d);if(e==="contains")return(a.textContent||a.innerText||k.getText([a])||"").indexOf(b[3])>=0;if(e==="not"){var g=b[3];for(var h=0,i=g.length;h<i;h++)if(g[h]===a)return!1;return!0}k.error(e)},CHILD:function(a,b){var c=b[1],d=a;switch(c){case"only":case"first":while(d=d.previousSibling)if(d.nodeType===1)return!1;if(c==="first")return!0;d=a;case"last":while(d=d.nextSibling)if(d.nodeType===1)return!1;return!0;case"nth":var e=b[2],f=b[3];if(e===1&&f===0)return!0;var g=b[0],h=a.parentNode;if(h&&(h.sizcache!==g||!a.nodeIndex)){var i=0;for(d=h.firstChild;d;d=d.nextSibling)d.nodeType===1&&(d.nodeIndex=++i);h.sizcache=g}var j=a.nodeIndex-f;return e===0?j===0:j%e===0&&j/e>=0}},ID:function(a,b){return a.nodeType===1&&a.getAttribute("id")===b},TAG:function(a,b){return b==="*"&&a.nodeType===1||a.nodeName.toLowerCase()===b},CLASS:function(a,b){return(" "+(a.className||a.getAttribute("class"))+" ").indexOf(b)>-1},ATTR:function(a,b){var c=b[1],d=l.attrHandle[c]?l.attrHandle[c](a):a[c]!=null?a[c]:a.getAttribute(c),e=d+"",f=b[2],g=b[4];return d==null?f==="!=":f==="="?e===g:f==="*="?e.indexOf(g)>=0:f==="~="?(" "+e+" ").indexOf(g)>=0:g?f==="!="?e!==g:f==="^="?e.indexOf(g)===0:f==="$="?e.substr(e.length-g.length)===g:f==="|="?e===g||e.substr(0,g.length+1)===g+"-":!1:e&&d!==!1},POS:function(a,b,c,d){var e=b[2],f=l.setFilters[e];if(f)return f(a,c,b,d)}}},m=l.match.POS,n=function(a,b){return"\\"+(b-0+1)};for(var o in l.match)l.match[o]=new RegExp(l.match[o].source+/(?![^\[]*\])(?![^\(]*\))/.source),l.leftMatch[o]=new RegExp(/(^(?:.|\r|\n)*?)/.source+l.match[o].source.replace(/\\(\d+)/g,n));var p=function(a,b){a=Array.prototype.slice.call(a,0);if(b){b.push.apply(b,a);return b}return a};try{Array.prototype.slice.call(c.documentElement.childNodes,0)[0].nodeType}catch(q){p=function(a,b){var c=0,d=b||[];if(e.call(a)==="[object Array]")Array.prototype.push.apply(d,a);else if(typeof a.length=="number")for(var f=a.length;c<f;c++)d.push(a[c]);else for(;a[c];c++)d.push(a[c]);return d}}var r,s;c.documentElement.compareDocumentPosition?r=function(a,b){if(a===b){g=!0;return 0}if(!a.compareDocumentPosition||!b.compareDocumentPosition)return a.compareDocumentPosition?-1:1;return a.compareDocumentPosition(b)&4?-1:1}:(r=function(a,b){if(a===b){g=!0;return 0}if(a.sourceIndex&&b.sourceIndex)return a.sourceIndex-b.sourceIndex;var c,d,e=[],f=[],h=a.parentNode,i=b.parentNode,j=h;if(h===i)return s(a,b);if(!h)return-1;if(!i)return 1;while(j)e.unshift(j),j=j.parentNode;j=i;while(j)f.unshift(j),j=j.parentNode;c=e.length,d=f.length;for(var k=0;k<c&&k<d;k++)if(e[k]!==f[k])return s(e[k],f[k]);return k===c?s(a,f[k],-1):s(e[k],b,1)},s=function(a,b,c){if(a===b)return c;var d=a.nextSibling;while(d){if(d===b)return-1;d=d.nextSibling}return 1}),k.getText=function(a){var b="",c;for(var d=0;a[d];d++)c=a[d],c.nodeType===3||c.nodeType===4?b+=c.nodeValue:c.nodeType!==8&&(b+=k.getText(c.childNodes));return b},function(){var a=c.createElement("div"),d="script"+(new Date).getTime(),e=c.documentElement;a.innerHTML="<a name='"+d+"'/>",e.insertBefore(a,e.firstChild),c.getElementById(d)&&(l.find.ID=function(a,c,d){if(typeof c.getElementById!="undefined"&&!d){var e=c.getElementById(a[1]);return e?e.id===a[1]||typeof e.getAttributeNode!="undefined"&&e.getAttributeNode("id").nodeValue===a[1]?[e]:b:[]}},l.filter.ID=function(a,b){var c=typeof a.getAttributeNode!="undefined"&&a.getAttributeNode("id");return a.nodeType===1&&c&&c.nodeValue===b}),e.removeChild(a),e=a=null}(),function(){var a=c.createElement("div");a.appendChild(c.createComment("")),a.getElementsByTagName("*").length>0&&(l.find.TAG=function(a,b){var c=b.getElementsByTagName(a[1]);if(a[1]==="*"){var d=[];for(var e=0;c[e];e++)c[e].nodeType===1&&d.push(c[e]);c=d}return c}),a.innerHTML="<a href='#'></a>",a.firstChild&&typeof a.firstChild.getAttribute!="undefined"&&a.firstChild.getAttribute("href")!=="#"&&(l.attrHandle.href=function(a){return a.getAttribute("href",2)}),a=null}(),c.querySelectorAll&&function(){var a=k,b=c.createElement("div"),d="__sizzle__";b.innerHTML="<p class='TEST'></p>";if(!b.querySelectorAll||b.querySelectorAll(".TEST").length!==0){k=function(b,e,f,g){e=e||c;if(!g&&!k.isXML(e)){var h=/^(\w+$)|^\.([\w\-]+$)|^#([\w\-]+$)/.exec(b);if(h&&(e.nodeType===1||e.nodeType===9)){if(h[1])return p(e.getElementsByTagName(b),f);if(h[2]&&l.find.CLASS&&e.getElementsByClassName)return p(e.getElementsByClassName(h[2]),f)}if(e.nodeType===9){if(b==="body"&&e.body)return p([e.body],f);if(h&&h[3]){var i=e.getElementById(h[3]);if(!i||!i.parentNode)return p([],f);if(i.id===h[3])return p([i],f)}try{return p(e.querySelectorAll(b),f)}catch(j){}}else if(e.nodeType===1&&e.nodeName.toLowerCase()!=="object"){var m=e,n=e.getAttribute("id"),o=n||d,q=e.parentNode,r=/^\s*[+~]/.test(b);n?o=o.replace(/'/g,"\\$&"):e.setAttribute("id",o),r&&q&&(e=e.parentNode);try{if(!r||q)return p(e.querySelectorAll("[id='"+o+"'] "+b),f)}catch(s){}finally{n||m.removeAttribute("id")}}}return a(b,e,f,g)};for(var e in a)k[e]=a[e];b=null}}(),function(){var a=c.documentElement,b=a.matchesSelector||a.mozMatchesSelector||a.webkitMatchesSelector||a.msMatchesSelector;if(b){var d=!b.call(c.createElement("div"),"div"),e=!1;try{b.call(c.documentElement,"[test!='']:sizzle")}catch(f){e=!0}k.matchesSelector=function(a,c){c=c.replace(/\=\s*([^'"\]]*)\s*\]/g,"='$1']");if(!k.isXML(a))try{if(e||!l.match.PSEUDO.test(c)&&!/!=/.test(c)){var f=b.call(a,c);if(f||!d||a.document&&a.document.nodeType!==11)return f}}catch(g){}return k(c,null,null,[a]).length>0}}}(),function(){var a=c.createElement("div");a.innerHTML="<div class='test e'></div><div class='test'></div>";if(!!a.getElementsByClassName&&a.getElementsByClassName("e").length!==0){a.lastChild.className="e";if(a.getElementsByClassName("e").length===1)return;l.order.splice(1,0,"CLASS"),l.find.CLASS=function(a,b,c){if(typeof b.getElementsByClassName!="undefined"&&!c)return b.getElementsByClassName(a[1])},a=null}}(),c.documentElement.contains?k.contains=function(a,b){return a!==b&&(a.contains?a.contains(b):!0)}:c.documentElement.compareDocumentPosition?k.contains=function(a,b){return!!(a.compareDocumentPosition(b)&16)}:k.contains=function(){return!1},k.isXML=function(a){var b=(a?a.ownerDocument||a:0).documentElement;return b?b.nodeName!=="HTML":!1};var v=function(a,b){var c,d=[],e="",f=b.nodeType?[b]:b;while(c=l.match.PSEUDO.exec(a))e+=c[0],a=a.replace(l.match.PSEUDO,"");a=l.relative[a]?a+"*":a;for(var g=0,h=f.length;g<h;g++)k(a,f[g],d);return k.filter(e,d)};f.find=k,f.expr=k.selectors,f.expr[":"]=f.expr.filters,f.unique=k.uniqueSort,f.text=k.getText,f.isXMLDoc=k.isXML,f.contains=k.contains}();var O=/Until$/,P=/^(?:parents|prevUntil|prevAll)/,Q=/,/,R=/^.[^:#\[\.,]*$/,S=Array.prototype.slice,T=f.expr.match.POS,U={children:!0,contents:!0,next:!0,prev:!0};f.fn.extend({find:function(a){var b=this,c,d;if(typeof a!="string")return f(a).filter(function(){for(c=0,d=b.length;c<d;c++)if(f.contains(b[c],this))return!0});var e=this.pushStack("","find",a),g,h,i;for(c=0,d=this.length;c<d;c++){g=e.length,f.find(a,this[c],e);if(c>0)for(h=g;h<e.length;h++)for(i=0;i<g;i++)if(e[i]===e[h]){e.splice(h--,1);break}}return e},has:function(a){var b=f(a);return this.filter(function(){for(var a=0,c=b.length;a<c;a++)if(f.contains(this,b[a]))return!0})},not:function(a){return this.pushStack(W(this,a,!1),"not",a)},filter:function(a){return this.pushStack(W(this,a,!0),"filter",a)},is:function(a){return!!a&&(typeof a=="string"?f.filter(a,this).length>0:this.filter(a).length>0)},closest:function(a,b){var c=[],d,e,g=this[0];if(f.isArray(a)){var h,i,j={},k=1;if(g&&a.length){for(d=0,e=a.length;d<e;d++)i=a[d],j[i]||(j[i]=T.test(i)?f(i,b||this.context):i);while(g&&g.ownerDocument&&g!==b){for(i in j)h=j[i],(h.jquery?h.index(g)>-1:f(g).is(h))&&c.push({selector:i,elem:g,level:k});g=g.parentNode,k++}}return c}var l=T.test(a)||typeof a!="string"?f(a,b||this.context):0;for(d=0,e=this.length;d<e;d++){g=this[d];while(g){if(l?l.index(g)>-1:f.find.matchesSelector(g,a)){c.push(g);break}g=g.parentNode;if(!g||!g.ownerDocument||g===b||g.nodeType===11)break}}c=c.length>1?f.unique(c):c;return this.pushStack(c,"closest",a)},index:function(a){if(!a||typeof a=="string")return f.inArray(this[0],a?f(a):this.parent().children());return f.inArray(a.jquery?a[0]:a,this)},add:function(a,b){var c=typeof a=="string"?f(a,b):f.makeArray(a&&a.nodeType?[a]:a),d=f.merge(this.get(),c);return this.pushStack(V(c[0])||V(d[0])?d:f.unique(d))},andSelf:function(){return this.add(this.prevObject)}}),f.each({parent:function(a){var b=a.parentNode;return b&&b.nodeType!==11?b:null},parents:function(a){return f.dir(a,"parentNode")},parentsUntil:function(a,b,c){return f.dir(a,"parentNode",c)},next:function(a){return f.nth(a,2,"nextSibling")},prev:function(a){return f.nth(a,2,"previousSibling")},nextAll:function(a){return f.dir(a,"nextSibling")},prevAll:function(a){return f.dir(a,"previousSibling")},nextUntil:function(a,b,c){return f.dir(a,"nextSibling",c)},prevUntil:function(a,b,c){return f.dir(a,"previousSibling",c)},siblings:function(a){return f.sibling(a.parentNode.firstChild,a)},children:function(a){return f.sibling(a.firstChild)},contents:function(a){return f.nodeName(a,"iframe")?a.contentDocument||a.contentWindow.document:f.makeArray(a.childNodes)}},function(a,b){f.fn[a]=function(c,d){var e=f.map(this,b,c),g=S.call(arguments);O.test(a)||(d=c),d&&typeof d=="string"&&(e=f.filter(d,e)),e=this.length>1&&!U[a]?f.unique(e):e,(this.length>1||Q.test(d))&&P.test(a)&&(e=e.reverse());return this.pushStack(e,a,g.join(","))}}),f.extend({filter:function(a,b,c){c&&(a=":not("+a+")");return b.length===1?f.find.matchesSelector(b[0],a)?[b[0]]:[]:f.find.matches(a,b)},dir:function(a,c,d){var e=[],g=a[c];while(g&&g.nodeType!==9&&(d===b||g.nodeType!==1||!f(g).is(d)))g.nodeType===1&&e.push(g),g=g[c];return e},nth:function(a,b,c,d){b=b||1;var e=0;for(;a;a=a[c])if(a.nodeType===1&&++e===b)break;return a},sibling:function(a,b){var c=[];for(;a;a=a.nextSibling)a.nodeType===1&&a!==b&&c.push(a);return c}});var X=/ jQuery\d+="(?:\d+|null)"/g,Y=/^\s+/,Z=/<(?!area|br|col|embed|hr|img|input|link|meta|param)(([\w:]+)[^>]*)\/>/ig,$=/<([\w:]+)/,_=/<tbody/i,ba=/<|&#?\w+;/,bb=/<(?:script|object|embed|option|style)/i,bc=/checked\s*(?:[^=]|=\s*.checked.)/i,bd=/\/(java|ecma)script/i,be=/^\s*<!(?:\[CDATA\[|\-\-)/,bf={option:[1,"<select multiple='multiple'>","</select>"],legend:[1,"<fieldset>","</fieldset>"],thead:[1,"<table>","</table>"],tr:[2,"<table><tbody>","</tbody></table>"],td:[3,"<table><tbody><tr>","</tr></tbody></table>"],col:[2,"<table><tbody></tbody><colgroup>","</colgroup></table>"],area:[1,"<map>","</map>"],_default:[0,"",""]};bf.optgroup=bf.option,bf.tbody=bf.tfoot=bf.colgroup=bf.caption=bf.thead,bf.th=bf.td,f.support.htmlSerialize||(bf._default=[1,"div<div>","</div>"]),f.fn.extend({text:function(a){if(f.isFunction(a))return this.each(function(b){var c=f(this);c.text(a.call(this,b,c.text()))});if(typeof a!="object"&&a!==b)return this.empty().append((this[0]&&this[0].ownerDocument||c).createTextNode(a));return f.text(this)},wrapAll:function(a){if(f.isFunction(a))return this.each(function(b){f(this).wrapAll(a.call(this,b))});if(this[0]){var b=f(a,this[0].ownerDocument).eq(0).clone(!0);this[0].parentNode&&b.insertBefore(this[0]),b.map(function(){var a=this;while(a.firstChild&&a.firstChild.nodeType===1)a=a.firstChild;return a}).append(this)}return this},wrapInner:function(a){if(f.isFunction(a))return this.each(function(b){f(this).wrapInner(a.call(this,b))});return this.each(function(){var b=f(this),c=b.contents();c.length?c.wrapAll(a):b.append(a)})},wrap:function(a){return this.each(function(){f(this).wrapAll(a)})},unwrap:function(){return this.parent().each(function(){f.nodeName(this,"body")||f(this).replaceWith(this.childNodes)}).end()},append:function(){return this.domManip(arguments,!0,function(a){this.nodeType===1&&this.appendChild(a)})},prepend:function(){return this.domManip(arguments,!0,function(a){this.nodeType===1&&this.insertBefore(a,this.firstChild)})},before:function(){if(this[0]&&this[0].parentNode)return this.domManip(arguments,!1,function(a){this.parentNode.insertBefore(a,this)});if(arguments.length){var a=f(arguments[0]);a.push.apply(a,this.toArray());return this.pushStack(a,"before",arguments)}},after:function(){if(this[0]&&this[0].parentNode)return this.domManip(arguments,!1,function(a){this.parentNode.insertBefore(a,this.nextSibling)});if(arguments.length){var a=this.pushStack(this,"after",arguments);a.push.apply(a,f(arguments[0]).toArray());return a}},remove:function(a,b){for(var c=0,d;(d=this[c])!=null;c++)if(!a||f.filter(a,[d]).length)!b&&d.nodeType===1&&(f.cleanData(d.getElementsByTagName("*")),f.cleanData([d])),d.parentNode&&d.parentNode.removeChild(d);return this},empty:function(){for(var a=0,b;(b=this[a])!=null;a++){b.nodeType===1&&f.cleanData(b.getElementsByTagName("*"));while(b.firstChild)b.removeChild(b.firstChild)}return this},clone:function(a,b){a=a==null?!1:a,b=b==null?a:b;return this.map(function(){return f.clone(this,a,b)})},html:function(a){if(a===b)return this[0]&&this[0].nodeType===1?this[0].innerHTML.replace(X,""):null;if(typeof a=="string"&&!bb.test(a)&&(f.support.leadingWhitespace||!Y.test(a))&&!bf[($.exec(a)||["",""])[1].toLowerCase()]){a=a.replace(Z,"<$1></$2>");try{for(var c=0,d=this.length;c<d;c++)this[c].nodeType===1&&(f.cleanData(this[c].getElementsByTagName("*")),this[c].innerHTML=a)}catch(e){this.empty().append(a)}}else f.isFunction(a)?this.each(function(b){var c=f(this);c.html(a.call(this,b,c.html()))}):this.empty().append(a);return this},replaceWith:function(a){if(this[0]&&this[0].parentNode){if(f.isFunction(a))return this.each(function(b){var c=f(this),d=c.html();c.replaceWith(a.call(this,b,d))});typeof a!="string"&&(a=f(a).detach());return this.each(function(){var b=this.nextSibling,c=this.parentNode;f(this).remove(),b?f(b).before(a):f(c).append(a)})}return this.length?this.pushStack(f(f.isFunction(a)?a():a),"replaceWith",a):this},detach:function(a){return this.remove(a,!0)},domManip:function(a,c,d){var e,g,h,i,j=a[0],k=[];if(!f.support.checkClone&&arguments.length===3&&typeof j=="string"&&bc.test(j))return this.each(function(){f(this).domManip(a,c,d,!0)});if(f.isFunction(j))return this.each(function(e){var g=f(this);a[0]=j.call(this,e,c?g.html():b),g.domManip(a,c,d)});if(this[0]){i=j&&j.parentNode,f.support.parentNode&&i&&i.nodeType===11&&i.childNodes.length===this.length?e={fragment:i}:e=f.buildFragment(a,this,k),h=e.fragment,h.childNodes.length===1?g=h=h.firstChild:g=h.firstChild;if(g){c=c&&f.nodeName(g,"tr");for(var l=0,m=this.length,n=m-1;l<m;l++)d.call(c?bg(this[l],g):this[l],e.cacheable||m>1&&l<n?f.clone(h,!0,!0):h)}k.length&&f.each(k,bm)}return this}}),f.buildFragment=function(a,b,d){var e,g,h,i;b&&b[0]&&(i=b[0].ownerDocument||b[0]),i.createDocumentFragment||(i=c),a.length===1&&typeof a[0]=="string"&&a[0].length<512&&i===c&&a[0].charAt(0)==="<"&&!bb.test(a[0])&&(f.support.checkClone||!bc.test(a[0]))&&(g=!0,h=f.fragments[a[0]],h&&h!==1&&(e=h)),e||(e=i.createDocumentFragment(),f.clean(a,i,e,d)),g&&(f.fragments[a[0]]=h?e:1);return{fragment:e,cacheable:g}},f.fragments={},f.each({appendTo:"append",prependTo:"prepend",insertBefore:"before",insertAfter:"after",replaceAll:"replaceWith"},function(a,b){f.fn[a]=function(c){var d=[],e=f(c),g=this.length===1&&this[0].parentNode;if(g&&g.nodeType===11&&g.childNodes.length===1&&e.length===1){e[b](this[0]);return this}for(var h=0,i=e.length;h<i;h++){var j=(h>0?this.clone(!0):this).get();f(e[h])[b](j),d=d.concat(j
		)}return this.pushStack(d,a,e.selector)}}),f.extend({clone:function(a,b,c){var d=a.cloneNode(!0),e,g,h;if((!f.support.noCloneEvent||!f.support.noCloneChecked)&&(a.nodeType===1||a.nodeType===11)&&!f.isXMLDoc(a)){bi(a,d),e=bj(a),g=bj(d);for(h=0;e[h];++h)bi(e[h],g[h])}if(b){bh(a,d);if(c){e=bj(a),g=bj(d);for(h=0;e[h];++h)bh(e[h],g[h])}}e=g=null;return d},clean:function(a,b,d,e){var g;b=b||c,typeof b.createElement=="undefined"&&(b=b.ownerDocument||b[0]&&b[0].ownerDocument||c);var h=[],i;for(var j=0,k;(k=a[j])!=null;j++){typeof k=="number"&&(k+="");if(!k)continue;if(typeof k=="string")if(!ba.test(k))k=b.createTextNode(k);else{k=k.replace(Z,"<$1></$2>");var l=($.exec(k)||["",""])[1].toLowerCase(),m=bf[l]||bf._default,n=m[0],o=b.createElement("div");o.innerHTML=m[1]+k+m[2];while(n--)o=o.lastChild;if(!f.support.tbody){var p=_.test(k),q=l==="table"&&!p?o.firstChild&&o.firstChild.childNodes:m[1]==="<table>"&&!p?o.childNodes:[];for(i=q.length-1;i>=0;--i)f.nodeName(q[i],"tbody")&&!q[i].childNodes.length&&q[i].parentNode.removeChild(q[i])}!f.support.leadingWhitespace&&Y.test(k)&&o.insertBefore(b.createTextNode(Y.exec(k)[0]),o.firstChild),k=o.childNodes}var r;if(!f.support.appendChecked)if(k[0]&&typeof (r=k.length)=="number")for(i=0;i<r;i++)bl(k[i]);else bl(k);k.nodeType?h.push(k):h=f.merge(h,k)}if(d){g=function(a){return!a.type||bd.test(a.type)};for(j=0;h[j];j++)if(e&&f.nodeName(h[j],"script")&&(!h[j].type||h[j].type.toLowerCase()==="text/javascript"))e.push(h[j].parentNode?h[j].parentNode.removeChild(h[j]):h[j]);else{if(h[j].nodeType===1){var s=f.grep(h[j].getElementsByTagName("script"),g);h.splice.apply(h,[j+1,0].concat(s))}d.appendChild(h[j])}}return h},cleanData:function(a){var b,c,d=f.cache,e=f.expando,g=f.event.special,h=f.support.deleteExpando;for(var i=0,j;(j=a[i])!=null;i++){if(j.nodeName&&f.noData[j.nodeName.toLowerCase()])continue;c=j[f.expando];if(c){b=d[c]&&d[c][e];if(b&&b.events){for(var k in b.events)g[k]?f.event.remove(j,k):f.removeEvent(j,k,b.handle);b.handle&&(b.handle.elem=null)}h?delete j[f.expando]:j.removeAttribute&&j.removeAttribute(f.expando),delete d[c]}}}});var bn=/alpha\([^)]*\)/i,bo=/opacity=([^)]*)/,bp=/([A-Z]|^ms)/g,bq=/^-?\d+(?:px)?$/i,br=/^-?\d/,bs=/^[+\-]=/,bt=/[^+\-\.\de]+/g,bu={position:"absolute",visibility:"hidden",display:"block"},bv=["Left","Right"],bw=["Top","Bottom"],bx,by,bz;f.fn.css=function(a,c){if(arguments.length===2&&c===b)return this;return f.access(this,a,c,!0,function(a,c,d){return d!==b?f.style(a,c,d):f.css(a,c)})},f.extend({cssHooks:{opacity:{get:function(a,b){if(b){var c=bx(a,"opacity","opacity");return c===""?"1":c}return a.style.opacity}}},cssNumber:{fillOpacity:!0,fontWeight:!0,lineHeight:!0,opacity:!0,orphans:!0,widows:!0,zIndex:!0,zoom:!0},cssProps:{"float":f.support.cssFloat?"cssFloat":"styleFloat"},style:function(a,c,d,e){if(!!a&&a.nodeType!==3&&a.nodeType!==8&&!!a.style){var g,h,i=f.camelCase(c),j=a.style,k=f.cssHooks[i];c=f.cssProps[i]||i;if(d===b){if(k&&"get"in k&&(g=k.get(a,!1,e))!==b)return g;return j[c]}h=typeof d;if(h==="number"&&isNaN(d)||d==null)return;h==="string"&&bs.test(d)&&(d=+d.replace(bt,"")+parseFloat(f.css(a,c)),h="number"),h==="number"&&!f.cssNumber[i]&&(d+="px");if(!k||!("set"in k)||(d=k.set(a,d))!==b)try{j[c]=d}catch(l){}}},css:function(a,c,d){var e,g;c=f.camelCase(c),g=f.cssHooks[c],c=f.cssProps[c]||c,c==="cssFloat"&&(c="float");if(g&&"get"in g&&(e=g.get(a,!0,d))!==b)return e;if(bx)return bx(a,c)},swap:function(a,b,c){var d={};for(var e in b)d[e]=a.style[e],a.style[e]=b[e];c.call(a);for(e in b)a.style[e]=d[e]}}),f.curCSS=f.css,f.each(["height","width"],function(a,b){f.cssHooks[b]={get:function(a,c,d){var e;if(c){if(a.offsetWidth!==0)return bA(a,b,d);f.swap(a,bu,function(){e=bA(a,b,d)});return e}},set:function(a,b){if(!bq.test(b))return b;b=parseFloat(b);if(b>=0)return b+"px"}}}),f.support.opacity||(f.cssHooks.opacity={get:function(a,b){return bo.test((b&&a.currentStyle?a.currentStyle.filter:a.style.filter)||"")?parseFloat(RegExp.$1)/100+"":b?"1":""},set:function(a,b){var c=a.style,d=a.currentStyle;c.zoom=1;var e=f.isNaN(b)?"":"alpha(opacity="+b*100+")",g=d&&d.filter||c.filter||"";c.filter=bn.test(g)?g.replace(bn,e):g+" "+e}}),f(function(){f.support.reliableMarginRight||(f.cssHooks.marginRight={get:function(a,b){var c;f.swap(a,{display:"inline-block"},function(){b?c=bx(a,"margin-right","marginRight"):c=a.style.marginRight});return c}})}),c.defaultView&&c.defaultView.getComputedStyle&&(by=function(a,c){var d,e,g;c=c.replace(bp,"-$1").toLowerCase();if(!(e=a.ownerDocument.defaultView))return b;if(g=e.getComputedStyle(a,null))d=g.getPropertyValue(c),d===""&&!f.contains(a.ownerDocument.documentElement,a)&&(d=f.style(a,c));return d}),c.documentElement.currentStyle&&(bz=function(a,b){var c,d=a.currentStyle&&a.currentStyle[b],e=a.runtimeStyle&&a.runtimeStyle[b],f=a.style;!bq.test(d)&&br.test(d)&&(c=f.left,e&&(a.runtimeStyle.left=a.currentStyle.left),f.left=b==="fontSize"?"1em":d||0,d=f.pixelLeft+"px",f.left=c,e&&(a.runtimeStyle.left=e));return d===""?"auto":d}),bx=by||bz,f.expr&&f.expr.filters&&(f.expr.filters.hidden=function(a){var b=a.offsetWidth,c=a.offsetHeight;return b===0&&c===0||!f.support.reliableHiddenOffsets&&(a.style.display||f.css(a,"display"))==="none"},f.expr.filters.visible=function(a){return!f.expr.filters.hidden(a)});var bB=/%20/g,bC=/\[\]$/,bD=/\r?\n/g,bE=/#.*$/,bF=/^(.*?):[ \t]*([^\r\n]*)\r?$/mg,bG=/^(?:color|date|datetime|email|hidden|month|number|password|range|search|tel|text|time|url|week)$/i,bH=/^(?:about|app|app\-storage|.+\-extension|file|widget):$/,bI=/^(?:GET|HEAD)$/,bJ=/^\/\//,bK=/\?/,bL=/<script\b[^<]*(?:(?!<\/script>)<[^<]*)*<\/script>/gi,bM=/^(?:select|textarea)/i,bN=/\s+/,bO=/([?&])_=[^&]*/,bP=/^([\w\+\.\-]+:)(?:\/\/([^\/?#:]*)(?::(\d+))?)?/,bQ=f.fn.load,bR={},bS={},bT,bU;try{bT=e.href}catch(bV){bT=c.createElement("a"),bT.href="",bT=bT.href}bU=bP.exec(bT.toLowerCase())||[],f.fn.extend({load:function(a,c,d){if(typeof a!="string"&&bQ)return bQ.apply(this,arguments);if(!this.length)return this;var e=a.indexOf(" ");if(e>=0){var g=a.slice(e,a.length);a=a.slice(0,e)}var h="GET";c&&(f.isFunction(c)?(d=c,c=b):typeof c=="object"&&(c=f.param(c,f.ajaxSettings.traditional),h="POST"));var i=this;f.ajax({url:a,type:h,dataType:"html",data:c,complete:function(a,b,c){c=a.responseText,a.isResolved()&&(a.done(function(a){c=a}),i.html(g?f("<div>").append(c.replace(bL,"")).find(g):c)),d&&i.each(d,[c,b,a])}});return this},serialize:function(){return f.param(this.serializeArray())},serializeArray:function(){return this.map(function(){return this.elements?f.makeArray(this.elements):this}).filter(function(){return this.name&&!this.disabled&&(this.checked||bM.test(this.nodeName)||bG.test(this.type))}).map(function(a,b){var c=f(this).val();return c==null?null:f.isArray(c)?f.map(c,function(a,c){return{name:b.name,value:a.replace(bD,"\r\n")}}):{name:b.name,value:c.replace(bD,"\r\n")}}).get()}}),f.each("ajaxStart ajaxStop ajaxComplete ajaxError ajaxSuccess ajaxSend".split(" "),function(a,b){f.fn[b]=function(a){return this.bind(b,a)}}),f.each(["get","post"],function(a,c){f[c]=function(a,d,e,g){f.isFunction(d)&&(g=g||e,e=d,d=b);return f.ajax({type:c,url:a,data:d,success:e,dataType:g})}}),f.extend({getScript:function(a,c){return f.get(a,b,c,"script")},getJSON:function(a,b,c){return f.get(a,b,c,"json")},ajaxSetup:function(a,b){b?f.extend(!0,a,f.ajaxSettings,b):(b=a,a=f.extend(!0,f.ajaxSettings,b));for(var c in{context:1,url:1})c in b?a[c]=b[c]:c in f.ajaxSettings&&(a[c]=f.ajaxSettings[c]);return a},ajaxSettings:{url:bT,isLocal:bH.test(bU[1]),global:!0,type:"GET",contentType:"application/x-www-form-urlencoded",processData:!0,async:!0,accepts:{xml:"application/xml, text/xml",html:"text/html",text:"text/plain",json:"application/json, text/javascript","*":"*/*"},contents:{xml:/xml/,html:/html/,json:/json/},responseFields:{xml:"responseXML",text:"responseText"},converters:{"* text":a.String,"text html":!0,"text json":f.parseJSON,"text xml":f.parseXML}},ajaxPrefilter:bW(bR),ajaxTransport:bW(bS),ajax:function(a,c){function w(a,c,l,m){if(s!==2){s=2,q&&clearTimeout(q),p=b,n=m||"",v.readyState=a?4:0;var o,r,u,w=l?bZ(d,v,l):b,x,y;if(a>=200&&a<300||a===304){if(d.ifModified){if(x=v.getResponseHeader("Last-Modified"))f.lastModified[k]=x;if(y=v.getResponseHeader("Etag"))f.etag[k]=y}if(a===304)c="notmodified",o=!0;else try{r=b$(d,w),c="success",o=!0}catch(z){c="parsererror",u=z}}else{u=c;if(!c||a)c="error",a<0&&(a=0)}v.status=a,v.statusText=c,o?h.resolveWith(e,[r,c,v]):h.rejectWith(e,[v,c,u]),v.statusCode(j),j=b,t&&g.trigger("ajax"+(o?"Success":"Error"),[v,d,o?r:u]),i.resolveWith(e,[v,c]),t&&(g.trigger("ajaxComplete",[v,d]),--f.active||f.event.trigger("ajaxStop"))}}typeof a=="object"&&(c=a,a=b),c=c||{};var d=f.ajaxSetup({},c),e=d.context||d,g=e!==d&&(e.nodeType||e instanceof f)?f(e):f.event,h=f.Deferred(),i=f._Deferred(),j=d.statusCode||{},k,l={},m={},n,o,p,q,r,s=0,t,u,v={readyState:0,setRequestHeader:function(a,b){if(!s){var c=a.toLowerCase();a=m[c]=m[c]||a,l[a]=b}return this},getAllResponseHeaders:function(){return s===2?n:null},getResponseHeader:function(a){var c;if(s===2){if(!o){o={};while(c=bF.exec(n))o[c[1].toLowerCase()]=c[2]}c=o[a.toLowerCase()]}return c===b?null:c},overrideMimeType:function(a){s||(d.mimeType=a);return this},abort:function(a){a=a||"abort",p&&p.abort(a),w(0,a);return this}};h.promise(v),v.success=v.done,v.error=v.fail,v.complete=i.done,v.statusCode=function(a){if(a){var b;if(s<2)for(b in a)j[b]=[j[b],a[b]];else b=a[v.status],v.then(b,b)}return this},d.url=((a||d.url)+"").replace(bE,"").replace(bJ,bU[1]+"//"),d.dataTypes=f.trim(d.dataType||"*").toLowerCase().split(bN),d.crossDomain==null&&(r=bP.exec(d.url.toLowerCase()),d.crossDomain=!(!r||r[1]==bU[1]&&r[2]==bU[2]&&(r[3]||(r[1]==="http:"?80:443))==(bU[3]||(bU[1]==="http:"?80:443)))),d.data&&d.processData&&typeof d.data!="string"&&(d.data=f.param(d.data,d.traditional)),bX(bR,d,c,v);if(s===2)return!1;t=d.global,d.type=d.type.toUpperCase(),d.hasContent=!bI.test(d.type),t&&f.active++===0&&f.event.trigger("ajaxStart");if(!d.hasContent){d.data&&(d.url+=(bK.test(d.url)?"&":"?")+d.data),k=d.url;if(d.cache===!1){var x=f.now(),y=d.url.replace(bO,"$1_="+x);d.url=y+(y===d.url?(bK.test(d.url)?"&":"?")+"_="+x:"")}}(d.data&&d.hasContent&&d.contentType!==!1||c.contentType)&&v.setRequestHeader("Content-Type",d.contentType),d.ifModified&&(k=k||d.url,f.lastModified[k]&&v.setRequestHeader("If-Modified-Since",f.lastModified[k]),f.etag[k]&&v.setRequestHeader("If-None-Match",f.etag[k])),v.setRequestHeader("Accept",d.dataTypes[0]&&d.accepts[d.dataTypes[0]]?d.accepts[d.dataTypes[0]]+(d.dataTypes[0]!=="*"?", */*; q=0.01":""):d.accepts["*"]);for(u in d.headers)v.setRequestHeader(u,d.headers[u]);if(d.beforeSend&&(d.beforeSend.call(e,v,d)===!1||s===2)){v.abort();return!1}for(u in{success:1,error:1,complete:1})v[u](d[u]);p=bX(bS,d,c,v);if(!p)w(-1,"No Transport");else{v.readyState=1,t&&g.trigger("ajaxSend",[v,d]),d.async&&d.timeout>0&&(q=setTimeout(function(){v.abort("timeout")},d.timeout));try{s=1,p.send(l,w)}catch(z){status<2?w(-1,z):f.error(z)}}return v},param:function(a,c){var d=[],e=function(a,b){b=f.isFunction(b)?b():b,d[d.length]=encodeURIComponent(a)+"="+encodeURIComponent(b)};c===b&&(c=f.ajaxSettings.traditional);if(f.isArray(a)||a.jquery&&!f.isPlainObject(a))f.each(a,function(){e(this.name,this.value)});else for(var g in a)bY(g,a[g],c,e);return d.join("&").replace(bB,"+")}}),f.extend({active:0,lastModified:{},etag:{}});var b_=f.now(),ca=/(\=)\?(&|$)|\?\?/i;f.ajaxSetup({jsonp:"callback",jsonpCallback:function(){return f.expando+"_"+b_++}}),f.ajaxPrefilter("json jsonp",function(b,c,d){var e=b.contentType==="application/x-www-form-urlencoded"&&typeof b.data=="string";if(b.dataTypes[0]==="jsonp"||b.jsonp!==!1&&(ca.test(b.url)||e&&ca.test(b.data))){var g,h=b.jsonpCallback=f.isFunction(b.jsonpCallback)?b.jsonpCallback():b.jsonpCallback,i=a[h],j=b.url,k=b.data,l="$1"+h+"$2";b.jsonp!==!1&&(j=j.replace(ca,l),b.url===j&&(e&&(k=k.replace(ca,l)),b.data===k&&(j+=(/\?/.test(j)?"&":"?")+b.jsonp+"="+h))),b.url=j,b.data=k,a[h]=function(a){g=[a]},d.always(function(){a[h]=i,g&&f.isFunction(i)&&a[h](g[0])}),b.converters["script json"]=function(){g||f.error(h+" was not called");return g[0]},b.dataTypes[0]="json";return"script"}}),f.ajaxSetup({accepts:{script:"text/javascript, application/javascript, application/ecmascript, application/x-ecmascript"},contents:{script:/javascript|ecmascript/},converters:{"text script":function(a){f.globalEval(a);return a}}}),f.ajaxPrefilter("script",function(a){a.cache===b&&(a.cache=!1),a.crossDomain&&(a.type="GET",a.global=!1)}),f.ajaxTransport("script",function(a){if(a.crossDomain){var d,e=c.head||c.getElementsByTagName("head")[0]||c.documentElement;return{send:function(f,g){d=c.createElement("script"),d.async="async",a.scriptCharset&&(d.charset=a.scriptCharset),d.src=a.url,d.onload=d.onreadystatechange=function(a,c){if(c||!d.readyState||/loaded|complete/.test(d.readyState))d.onload=d.onreadystatechange=null,e&&d.parentNode&&e.removeChild(d),d=b,c||g(200,"success")},e.insertBefore(d,e.firstChild)},abort:function(){d&&d.onload(0,1)}}}});var cb=a.ActiveXObject?function(){for(var a in cd)cd[a](0,1)}:!1,cc=0,cd;f.ajaxSettings.xhr=a.ActiveXObject?function(){return!this.isLocal&&ce()||cf()}:ce,function(a){f.extend(f.support,{ajax:!!a,cors:!!a&&"withCredentials"in a})}(f.ajaxSettings.xhr()),f.support.ajax&&f.ajaxTransport(function(c){if(!c.crossDomain||f.support.cors){var d;return{send:function(e,g){var h=c.xhr(),i,j;c.username?h.open(c.type,c.url,c.async,c.username,c.password):h.open(c.type,c.url,c.async);if(c.xhrFields)for(j in c.xhrFields)h[j]=c.xhrFields[j];c.mimeType&&h.overrideMimeType&&h.overrideMimeType(c.mimeType),!c.crossDomain&&!e["X-Requested-With"]&&(e["X-Requested-With"]="XMLHttpRequest");try{for(j in e)h.setRequestHeader(j,e[j])}catch(k){}h.send(c.hasContent&&c.data||null),d=function(a,e){var j,k,l,m,n;try{if(d&&(e||h.readyState===4)){d=b,i&&(h.onreadystatechange=f.noop,cb&&delete cd[i]);if(e)h.readyState!==4&&h.abort();else{j=h.status,l=h.getAllResponseHeaders(),m={},n=h.responseXML,n&&n.documentElement&&(m.xml=n),m.text=h.responseText;try{k=h.statusText}catch(o){k=""}!j&&c.isLocal&&!c.crossDomain?j=m.text?200:404:j===1223&&(j=204)}}}catch(p){e||g(-1,p)}m&&g(j,k,m,l)},!c.async||h.readyState===4?d():(i=++cc,cb&&(cd||(cd={},f(a).unload(cb)),cd[i]=d),h.onreadystatechange=d)},abort:function(){d&&d(0,1)}}}});var cg={},ch,ci,cj=/^(?:toggle|show|hide)$/,ck=/^([+\-]=)?([\d+.\-]+)([a-z%]*)$/i,cl,cm=[["height","marginTop","marginBottom","paddingTop","paddingBottom"],["width","marginLeft","marginRight","paddingLeft","paddingRight"],["opacity"]],cn,co=a.webkitRequestAnimationFrame||a.mozRequestAnimationFrame||a.oRequestAnimationFrame;f.fn.extend({show:function(a,b,c){var d,e;if(a||a===0)return this.animate(cr("show",3),a,b,c);for(var g=0,h=this.length;g<h;g++)d=this[g],d.style&&(e=d.style.display,!f._data(d,"olddisplay")&&e==="none"&&(e=d.style.display=""),e===""&&f.css(d,"display")==="none"&&f._data(d,"olddisplay",cs(d.nodeName)));for(g=0;g<h;g++){d=this[g];if(d.style){e=d.style.display;if(e===""||e==="none")d.style.display=f._data(d,"olddisplay")||""}}return this},hide:function(a,b,c){if(a||a===0)return this.animate(cr("hide",3),a,b,c);for(var d=0,e=this.length;d<e;d++)if(this[d].style){var g=f.css(this[d],"display");g!=="none"&&!f._data(this[d],"olddisplay")&&f._data(this[d],"olddisplay",g)}for(d=0;d<e;d++)this[d].style&&(this[d].style.display="none");return this},_toggle:f.fn.toggle,toggle:function(a,b,c){var d=typeof a=="boolean";f.isFunction(a)&&f.isFunction(b)?this._toggle.apply(this,arguments):a==null||d?this.each(function(){var b=d?a:f(this).is(":hidden");f(this)[b?"show":"hide"]()}):this.animate(cr("toggle",3),a,b,c);return this},fadeTo:function(a,b,c,d){return this.filter(":hidden").css("opacity",0).show().end().animate({opacity:b},a,c,d)},animate:function(a,b,c,d){var e=f.speed(b,c,d);if(f.isEmptyObject(a))return this.each(e.complete,[!1]);a=f.extend({},a);return this[e.queue===!1?"each":"queue"](function(){e.queue===!1&&f._mark(this);var b=f.extend({},e),c=this.nodeType===1,d=c&&f(this).is(":hidden"),g,h,i,j,k,l,m,n,o;b.animatedProperties={};for(i in a){g=f.camelCase(i),i!==g&&(a[g]=a[i],delete a[i]),h=a[g],f.isArray(h)?(b.animatedProperties[g]=h[1],h=a[g]=h[0]):b.animatedProperties[g]=b.specialEasing&&b.specialEasing[g]||b.easing||"swing";if(h==="hide"&&d||h==="show"&&!d)return b.complete.call(this);c&&(g==="height"||g==="width")&&(b.overflow=[this.style.overflow,this.style.overflowX,this.style.overflowY],f.css(this,"display")==="inline"&&f.css(this,"float")==="none"&&(f.support.inlineBlockNeedsLayout?(j=cs(this.nodeName),j==="inline"?this.style.display="inline-block":(this.style.display="inline",this.style.zoom=1)):this.style.display="inline-block"))}b.overflow!=null&&(this.style.overflow="hidden");for(i in a)k=new f.fx(this,b,i),h=a[i],cj.test(h)?k[h==="toggle"?d?"show":"hide":h]():(l=ck.exec(h),m=k.cur(),l?(n=parseFloat(l[2]),o=l[3]||(f.cssNumber[i]?"":"px"),o!=="px"&&(f.style(this,i,(n||1)+o),m=(n||1)/k.cur()*m,f.style(this,i,m+o)),l[1]&&(n=(l[1]==="-="?-1:1)*n+m),k.custom(m,n,o)):k.custom(m,h,""));return!0})},stop:function(a,b){a&&this.queue([]),this.each(function(){var a=f.timers,c=a.length;b||f._unmark(!0,this);while(c--)a[c].elem===this&&(b&&a[c](!0),a.splice(c,1))}),b||this.dequeue();return this}}),f.each({slideDown:cr("show",1),slideUp:cr("hide",1),slideToggle:cr("toggle",1),fadeIn:{opacity:"show"},fadeOut:{opacity:"hide"},fadeToggle:{opacity:"toggle"}},function(a,b){f.fn[a]=function(a,c,d){return this.animate(b,a,c,d)}}),f.extend({speed:function(a,b,c){var d=a&&typeof a=="object"?f.extend({},a):{complete:c||!c&&b||f.isFunction(a)&&a,duration:a,easing:c&&b||b&&!f.isFunction(b)&&b};d.duration=f.fx.off?0:typeof d.duration=="number"?d.duration:d.duration in f.fx.speeds?f.fx.speeds[d.duration]:f.fx.speeds._default,d.old=d.complete,d.complete=function(a){f.isFunction(d.old)&&d.old.call(this),d.queue!==!1?f.dequeue(this):a!==!1&&f._unmark(this)};return d},easing:{linear:function(a,b,c,d){return c+d*a},swing:function(a,b,c,d){return(-Math.cos(a*Math.PI)/2+.5)*d+c}},timers:[],fx:function(a,b,c){this.options=b,this.elem=a,this.prop=c,b.orig=b.orig||{}}}),f.fx.prototype={update:function(){this.options.step&&this.options.step.call(this.elem,this.now,this),(f.fx.step[this.prop]||f.fx.step._default)(this)},cur:function(){if(this.elem[this.prop]!=null&&(!this.elem.style||this.elem.style[this.prop]==null))return this.elem[this.prop];var a,b=f.css(this.elem,this.prop);return isNaN(a=parseFloat(b))?!b||b==="auto"?0:b:a},custom:function(a,b,c){function h(a){return d.step(a)}var d=this,e=f.fx,g;this.startTime=cn||cp(),this.start=a,this.end=b,this.unit=c||this.unit||(f.cssNumber[this.prop]?"":"px"),this.now=this.start,this.pos=this.state=0,h.elem=this.elem,h()&&f.timers.push(h)&&!cl&&(co?(cl=!0,g=function(){cl&&(co(g),e.tick())},co(g)):cl=setInterval(e.tick,e.interval))},show:function(){this.options.orig[this.prop]=f.style(this.elem,this.prop),this.options.show=!0,this.custom(this.prop==="width"||this.prop==="height"?1:0,this.cur()),f(this.elem).show()},hide:function(){this.options.orig[this.prop]=f.style(this.elem,this.prop),this.options.hide=!0,this.custom(this.cur(),0)},step:function(a){var b=cn||cp(),c=!0,d=this.elem,e=this.options,g,h;if(a||b>=e.duration+this.startTime){this.now=this.end,this.pos=this.state=1,this.update(),e.animatedProperties[this.prop]=!0;for(g in e.animatedProperties)e.animatedProperties[g]!==!0&&(c=!1);if(c){e.overflow!=null&&!f.support.shrinkWrapBlocks&&f.each(["","X","Y"],function(a,b){d.style["overflow"+b]=e.overflow[a]}),e.hide&&f(d).hide();if(e.hide||e.show)for(var i in e.animatedProperties)f.style(d,i,e.orig[i]);e.complete.call(d)}return!1}e.duration==Infinity?this.now=b:(h=b-this.startTime,this.state=h/e.duration,this.pos=f.easing[e.animatedProperties[this.prop]](this.state,h,0,1,e.duration),this.now=this.start+(this.end-this.start)*this.pos),this.update();return!0}},f.extend(f.fx,{tick:function(){for(var a=f.timers,b=0;b<a.length;++b)a[b]()||a.splice(b--,1);a.length||f.fx.stop()},interval:13,stop:function(){clearInterval(cl),cl=null},speeds:{slow:600,fast:200,_default:400},step:{opacity:function(a){f.style(a.elem,"opacity",a.now)},_default:function(a){a.elem.style&&a.elem.style[a.prop]!=null?a.elem.style[a.prop]=(a.prop==="width"||a.prop==="height"?Math.max(0,a.now):a.now)+a.unit:a.elem[a.prop]=a.now}}}),f.expr&&f.expr.filters&&(f.expr.filters.animated=function(a){return f.grep(f.timers,function(b){return a===b.elem}).length});var ct=/^t(?:able|d|h)$/i,cu=/^(?:body|html)$/i;"getBoundingClientRect"in c.documentElement?f.fn.offset=function(a){var b=this[0],c;if(a)return this.each(function(b){f.offset.setOffset(this,a,b)});if(!b||!b.ownerDocument)return null;if(b===b.ownerDocument.body)return f.offset.bodyOffset(b);try{c=b.getBoundingClientRect()}catch(d){}var e=b.ownerDocument,g=e.documentElement;if(!c||!f.contains(g,b))return c?{top:c.top,left:c.left}:{top:0,left:0};var h=e.body,i=cv(e),j=g.clientTop||h.clientTop||0,k=g.clientLeft||h.clientLeft||0,l=i.pageYOffset||f.support.boxModel&&g.scrollTop||h.scrollTop,m=i.pageXOffset||f.support.boxModel&&g.scrollLeft||h.scrollLeft,n=c.top+l-j,o=c.left+m-k;return{top:n,left:o}}:f.fn.offset=function(a){var b=this[0];if(a)return this.each(function(b){f.offset.setOffset(this,a,b)});if(!b||!b.ownerDocument)return null;if(b===b.ownerDocument.body)return f.offset.bodyOffset(b);f.offset.initialize();var c,d=b.offsetParent,e=b,g=b.ownerDocument,h=g.documentElement,i=g.body,j=g.defaultView,k=j?j.getComputedStyle(b,null):b.currentStyle,l=b.offsetTop,m=b.offsetLeft;while((b=b.parentNode)&&b!==i&&b!==h){if(f.offset.supportsFixedPosition&&k.position==="fixed")break;c=j?j.getComputedStyle(b,null):b.currentStyle,l-=b.scrollTop,m-=b.scrollLeft,b===d&&(l+=b.offsetTop,m+=b.offsetLeft,f.offset.doesNotAddBorder&&(!f.offset.doesAddBorderForTableAndCells||!ct.test(b.nodeName))&&(l+=parseFloat(c.borderTopWidth)||0,m+=parseFloat(c.borderLeftWidth)||0),e=d,d=b.offsetParent),f.offset.subtractsBorderForOverflowNotVisible&&c.overflow!=="visible"&&(l+=parseFloat(c.borderTopWidth)||0,m+=parseFloat(c.borderLeftWidth)||0),k=c}if(k.position==="relative"||k.position==="static")l+=i.offsetTop,m+=i.offsetLeft;f.offset.supportsFixedPosition&&k.position==="fixed"&&(l+=Math.max(h.scrollTop,i.scrollTop),m+=Math.max(h.scrollLeft,i.scrollLeft));return{top:l,left:m}},f.offset={initialize:function(){var a=c.body,b=c.createElement("div"),d,e,g,h,i=parseFloat(f.css(a,"marginTop"))||0,j="<div style='position:absolute;top:0;left:0;margin:0;border:5px solid #000;padding:0;width:1px;height:1px;'><div></div></div><table style='position:absolute;top:0;left:0;margin:0;border:5px solid #000;padding:0;width:1px;height:1px;' cellpadding='0' cellspacing='0'><tr><td></td></tr></table>";f.extend(b.style,{position:"absolute",top:0,left:0,margin:0,border:0,width:"1px",height:"1px",visibility:"hidden"}),b.innerHTML=j,a.insertBefore(b,a.firstChild),d=b.firstChild,e=d.firstChild,h=d.nextSibling.firstChild.firstChild,this.doesNotAddBorder=e.offsetTop!==5,this.doesAddBorderForTableAndCells=h.offsetTop===5,e.style.position="fixed",e.style.top="20px",this.supportsFixedPosition=e.offsetTop===20||e.offsetTop===15,e.style.position=e.style.top="",d.style.overflow="hidden",d.style.position="relative",this.subtractsBorderForOverflowNotVisible=e.offsetTop===-5,this.doesNotIncludeMarginInBodyOffset=a.offsetTop!==i,a.removeChild(b),f.offset.initialize=f.noop},bodyOffset:function(a){var b=a.offsetTop,c=a.offsetLeft;f.offset.initialize(),f.offset.doesNotIncludeMarginInBodyOffset&&(b+=parseFloat(f.css(a,"marginTop"))||0,c+=parseFloat(f.css(a,"marginLeft"))||0);return{top:b,left:c}},setOffset:function(a,b,c){var d=f.css(a,"position");d==="static"&&(a.style.position="relative");var e=f(a),g=e.offset(),h=f.css(a,"top"),i=f.css(a,"left"),j=(d==="absolute"||d==="fixed")&&f.inArray("auto",[h,i])>-1,k={},l={},m,n;j?(l=e.position(),m=l.top,n=l.left):(m=parseFloat(h)||0,n=parseFloat(i)||0),f.isFunction(b)&&(b=b.call(a,c,g)),b.top!=null&&(k.top=b.top-g.top+m),b.left!=null&&(k.left=b.left-g.left+n),"using"in b?b.using.call(a,k):e.css(k)}},f.fn.extend({position:function(){if(!this[0])return null;var a=this[0],b=this.offsetParent(),c=this.offset(),d=cu.test(b[0].nodeName)?{top:0,left:0}:b.offset();c.top-=parseFloat(f.css(a,"marginTop"))||0,c.left-=parseFloat(f.css(a,"marginLeft"))||0,d.top+=parseFloat(f.css(b[0],"borderTopWidth"))||0,d.left+=parseFloat(f.css(b[0],"borderLeftWidth"))||0;return{top:c.top-d.top,left:c.left-d.left}},offsetParent:function(){return this.map(function(){var a=this.offsetParent||c.body;while(a&&!cu.test(a.nodeName)&&f.css(a,"position")==="static")a=a.offsetParent;return a})}}),f.each(["Left","Top"],function(a,c){var d="scroll"+c;f.fn[d]=function(c){var e,g;if(c===b){e=this[0];if(!e)return null;g=cv(e);return g?"pageXOffset"in g?g[a?"pageYOffset":"pageXOffset"]:f.support.boxModel&&g.document.documentElement[d]||g.document.body[d]:e[d]}return this.each(function(){g=cv(this),g?g.scrollTo(a?f(g).scrollLeft():c,a?c:f(g).scrollTop()):this[d]=c})}}),f.each(["Height","Width"],function(a,c){var d=c.toLowerCase();f.fn["inner"+c]=function(){var a=this[0];return a&&a.style?parseFloat(f.css(a,d,"padding")):null},f.fn["outer"+c]=function(a){var b=this[0];return b&&b.style?parseFloat(f.css(b,d,a?"margin":"border")):null},f.fn[d]=function(a){var e=this[0];if(!e)return a==null?null:this;if(f.isFunction(a))return this.each(function(b){var c=f(this);c[d](a.call(this,b,c[d]()))});if(f.isWindow(e)){var g=e.document.documentElement["client"+c];return e.document.compatMode==="CSS1Compat"&&g||e.document.body["client"+c]||g}if(e.nodeType===9)return Math.max(e.documentElement["client"+c],e.body["scroll"+c],e.documentElement["scroll"+c],e.body["offset"+c],e.documentElement["offset"+c]);if(a===b){var h=f.css(e,d),i=parseFloat(h);return f.isNaN(i)?h:i}return this.css(d,typeof a=="string"?a:a+"px")}}),a.jQuery=a.$=f})(window);
	</script>
	
	<script type="text/javascript">
		/* --- Tablesorter: http://tablesorter.com/ --- */
		/* Slightly modified for use with Snap2HTML: Removed trim to allow folders to sort at top. Replaced parseInt with parseFloat to fix sort problems with some file sizes */
		(function($){$.extend({tablesorter:new
		function(){var parsers=[],widgets=[];this.defaults={cssHeader:"header",cssAsc:"headerSortUp",cssDesc:"headerSortDown",cssChildRow:"expand-child",sortInitialOrder:"asc",sortMultiSortKey:"shiftKey",sortForce:null,sortAppend:null,sortLocaleCompare:true,textExtraction:"simple",parsers:{},widgets:[],widgetZebra:{css:["even","odd"]},headers:{},widthFixed:false,cancelSelection:true,sortList:[],headerList:[],dateFormat:"us",decimal:'/\.|\,/g',onRenderHeader:null,selectorHeaders:'thead th',debug:false};function benchmark(s,d){log(s+","+(new Date().getTime()-d.getTime())+"ms");}
		this.benchmark=benchmark;function log(s){if(typeof console!="undefined"&&typeof console.debug!="undefined"){console.log(s);}else{alert(s);}}
		function buildParserCache(table,$headers){if(table.config.debug){var parsersDebug="";}
		if(table.tBodies.length==0)return;var rows=table.tBodies[0].rows;if(rows[0]){var list=[],cells=rows[0].cells,l=cells.length;for(var i=0;i<l;i++){var p=false;if($.metadata&&($($headers[i]).metadata()&&$($headers[i]).metadata().sorter)){p=getParserById($($headers[i]).metadata().sorter);}else if((table.config.headers[i]&&table.config.headers[i].sorter)){p=getParserById(table.config.headers[i].sorter);}
		if(!p){p=detectParserForColumn(table,rows,-1,i);}
		if(table.config.debug){parsersDebug+="column:"+i+" parser:"+p.id+"\n";}
		list.push(p);}}
		if(table.config.debug){log(parsersDebug);}
		return list;};function detectParserForColumn(table,rows,rowIndex,cellIndex){var l=parsers.length,node=false,nodeValue=false,keepLooking=true;while(nodeValue==''&&keepLooking){rowIndex++;if(rows[rowIndex]){node=getNodeFromRowAndCellIndex(rows,rowIndex,cellIndex);nodeValue=trimAndGetNodeText(table.config,node);if(table.config.debug){log('Checking if value was empty on row:'+rowIndex);}}else{keepLooking=false;}}
		for(var i=1;i<l;i++){if(parsers[i].is(nodeValue,table,node)){return parsers[i];}}
		return parsers[0];}
		function getNodeFromRowAndCellIndex(rows,rowIndex,cellIndex){return rows[rowIndex].cells[cellIndex];}
		function trimAndGetNodeText(config,node){return $.trim(getElementText(config,node));}
		function getParserById(name){var l=parsers.length;for(var i=0;i<l;i++){if(parsers[i].id.toLowerCase()==name.toLowerCase()){return parsers[i];}}
		return false;}
		function buildCache(table){if(table.config.debug){var cacheTime=new Date();}
		var totalRows=(table.tBodies[0]&&table.tBodies[0].rows.length)||0,totalCells=(table.tBodies[0].rows[0]&&table.tBodies[0].rows[0].cells.length)||0,parsers=table.config.parsers,cache={row:[],normalized:[]};for(var i=0;i<totalRows;++i){var c=$(table.tBodies[0].rows[i]),cols=[];if(c.hasClass(table.config.cssChildRow)){cache.row[cache.row.length-1]=cache.row[cache.row.length-1].add(c);continue;}
		cache.row.push(c);for(var j=0;j<totalCells;++j){cols.push(parsers[j].format(getElementText(table.config,c[0].cells[j]),table,c[0].cells[j]));}
		cols.push(cache.normalized.length);cache.normalized.push(cols);cols=null;};if(table.config.debug){benchmark("Building cache for "+totalRows+" rows:",cacheTime);}
		return cache;};function getElementText(config,node){var text="";if(!node)return"";if(!config.supportsTextContent)config.supportsTextContent=node.textContent||false;if(config.textExtraction=="simple"){if(config.supportsTextContent){text=node.textContent;}else{if(node.childNodes[0]&&node.childNodes[0].hasChildNodes()){text=node.childNodes[0].innerHTML;}else{text=node.innerHTML;}}}else{if(typeof(config.textExtraction)=="function"){text=config.textExtraction(node);}else{text=$(node).text();}}
		return text;}
		function appendToTable(table,cache){if(table.config.debug){var appendTime=new Date()}
		var c=cache,r=c.row,n=c.normalized,totalRows=n.length,checkCell=(n[0].length-1),tableBody=$(table.tBodies[0]),rows=[];for(var i=0;i<totalRows;i++){var pos=n[i][checkCell];rows.push(r[pos]);if(!table.config.appender){var l=r[pos].length;for(var j=0;j<l;j++){tableBody[0].appendChild(r[pos][j]);}}}
		if(table.config.appender){table.config.appender(table,rows);}
		rows=null;if(table.config.debug){benchmark("Rebuilt table:",appendTime);}
		applyWidget(table);setTimeout(function(){$(table).trigger("sortEnd");},0);};function buildHeaders(table){if(table.config.debug){var time=new Date();}
		var meta=($.metadata)?true:false;var header_index=computeTableHeaderCellIndexes(table);$tableHeaders=$(table.config.selectorHeaders,table).each(function(index){this.column=header_index[this.parentNode.rowIndex+"-"+this.cellIndex];this.order=formatSortingOrder(table.config.sortInitialOrder);this.count=this.order;if(checkHeaderMetadata(this)||checkHeaderOptions(table,index))this.sortDisabled=true;if(checkHeaderOptionsSortingLocked(table,index))this.order=this.lockedOrder=checkHeaderOptionsSortingLocked(table,index);if(!this.sortDisabled){var $th=$(this).addClass(table.config.cssHeader);if(table.config.onRenderHeader)table.config.onRenderHeader.apply($th);}
		table.config.headerList[index]=this;});if(table.config.debug){benchmark("Built headers:",time);log($tableHeaders);}
		return $tableHeaders;};function computeTableHeaderCellIndexes(t){var matrix=[];var lookup={};var thead=t.getElementsByTagName('THEAD')[0];var trs=thead.getElementsByTagName('TR');for(var i=0;i<trs.length;i++){var cells=trs[i].cells;for(var j=0;j<cells.length;j++){var c=cells[j];var rowIndex=c.parentNode.rowIndex;var cellId=rowIndex+"-"+c.cellIndex;var rowSpan=c.rowSpan||1;var colSpan=c.colSpan||1
		var firstAvailCol;if(typeof(matrix[rowIndex])=="undefined"){matrix[rowIndex]=[];}
		for(var k=0;k<matrix[rowIndex].length+1;k++){if(typeof(matrix[rowIndex][k])=="undefined"){firstAvailCol=k;break;}}
		lookup[cellId]=firstAvailCol;for(var k=rowIndex;k<rowIndex+rowSpan;k++){if(typeof(matrix[k])=="undefined"){matrix[k]=[];}
		var matrixrow=matrix[k];for(var l=firstAvailCol;l<firstAvailCol+colSpan;l++){matrixrow[l]="x";}}}}
		return lookup;}
		function checkCellColSpan(table,rows,row){var arr=[],r=table.tHead.rows,c=r[row].cells;for(var i=0;i<c.length;i++){var cell=c[i];if(cell.colSpan>1){arr=arr.concat(checkCellColSpan(table,headerArr,row++));}else{if(table.tHead.length==1||(cell.rowSpan>1||!r[row+1])){arr.push(cell);}}}
		return arr;};function checkHeaderMetadata(cell){if(($.metadata)&&($(cell).metadata().sorter===false)){return true;};return false;}
		function checkHeaderOptions(table,i){if((table.config.headers[i])&&(table.config.headers[i].sorter===false)){return true;};return false;}
		function checkHeaderOptionsSortingLocked(table,i){if((table.config.headers[i])&&(table.config.headers[i].lockedOrder))return table.config.headers[i].lockedOrder;return false;}
		function applyWidget(table){var c=table.config.widgets;var l=c.length;for(var i=0;i<l;i++){getWidgetById(c[i]).format(table);}}
		function getWidgetById(name){var l=widgets.length;for(var i=0;i<l;i++){if(widgets[i].id.toLowerCase()==name.toLowerCase()){return widgets[i];}}};function formatSortingOrder(v){if(typeof(v)!="Number"){return(v.toLowerCase()=="desc")?1:0;}else{return(v==1)?1:0;}}
		function isValueInArray(v,a){var l=a.length;for(var i=0;i<l;i++){if(a[i][0]==v){return true;}}
		return false;}
		function setHeadersCss(table,$headers,list,css){$headers.removeClass(css[0]).removeClass(css[1]);var h=[];$headers.each(function(offset){if(!this.sortDisabled){h[this.column]=$(this);}});var l=list.length;for(var i=0;i<l;i++){h[list[i][0]].addClass(css[list[i][1]]);}}
		function fixColumnWidth(table,$headers){var c=table.config;if(c.widthFixed){var colgroup=$('<colgroup>');$("tr:first td",table.tBodies[0]).each(function(){colgroup.append($('<col>').css('width',$(this).width()));});$(table).prepend(colgroup);};}
		function updateHeaderSortCount(table,sortList){var c=table.config,l=sortList.length;for(var i=0;i<l;i++){var s=sortList[i],o=c.headerList[s[0]];o.count=s[1];o.count++;}}
		function multisort(table,sortList,cache){if(table.config.debug){var sortTime=new Date();}
		var dynamicExp="var sortWrapper = function(a,b) {",l=sortList.length;for(var i=0;i<l;i++){var c=sortList[i][0];var order=sortList[i][1];var s=(table.config.parsers[c].type=="text")?((order==0)?makeSortFunction("text","asc",c):makeSortFunction("text","desc",c)):((order==0)?makeSortFunction("numeric","asc",c):makeSortFunction("numeric","desc",c));var e="e"+i;dynamicExp+="var "+e+" = "+s;dynamicExp+="if("+e+") { return "+e+"; } ";dynamicExp+="else { ";}
		var orgOrderCol=cache.normalized[0].length-1;dynamicExp+="return a["+orgOrderCol+"]-b["+orgOrderCol+"];";for(var i=0;i<l;i++){dynamicExp+="}; ";}
		dynamicExp+="return 0; ";dynamicExp+="}; ";if(table.config.debug){benchmark("Evaling expression:"+dynamicExp,new Date());}
		eval(dynamicExp);cache.normalized.sort(sortWrapper);if(table.config.debug){benchmark("Sorting on "+sortList.toString()+" and dir "+order+" time:",sortTime);}
		return cache;};function makeSortFunction(type,direction,index){var a="a["+index+"]",b="b["+index+"]";if(type=='text'&&direction=='asc'){return"("+a+" == "+b+" ? 0 : ("+a+" === null ? Number.POSITIVE_INFINITY : ("+b+" === null ? Number.NEGATIVE_INFINITY : ("+a+" < "+b+") ? -1 : 1 )));";}else if(type=='text'&&direction=='desc'){return"("+a+" == "+b+" ? 0 : ("+a+" === null ? Number.POSITIVE_INFINITY : ("+b+" === null ? Number.NEGATIVE_INFINITY : ("+b+" < "+a+") ? -1 : 1 )));";}else if(type=='numeric'&&direction=='asc'){return"("+a+" === null && "+b+" === null) ? 0 :("+a+" === null ? Number.POSITIVE_INFINITY : ("+b+" === null ? Number.NEGATIVE_INFINITY : "+a+" - "+b+"));";}else if(type=='numeric'&&direction=='desc'){return"("+a+" === null && "+b+" === null) ? 0 :("+a+" === null ? Number.POSITIVE_INFINITY : ("+b+" === null ? Number.NEGATIVE_INFINITY : "+b+" - "+a+"));";}};function makeSortText(i){return"((a["+i+"] < b["+i+"]) ? -1 : ((a["+i+"] > b["+i+"]) ? 1 : 0));";};function makeSortTextDesc(i){return"((b["+i+"] < a["+i+"]) ? -1 : ((b["+i+"] > a["+i+"]) ? 1 : 0));";};function makeSortNumeric(i){return"a["+i+"]-b["+i+"];";};function makeSortNumericDesc(i){return"b["+i+"]-a["+i+"];";};function sortText(a,b){if(table.config.sortLocaleCompare)return a.localeCompare(b);return((a<b)?-1:((a>b)?1:0));};function sortTextDesc(a,b){if(table.config.sortLocaleCompare)return b.localeCompare(a);return((b<a)?-1:((b>a)?1:0));};function sortNumeric(a,b){return a-b;};function sortNumericDesc(a,b){return b-a;};function getCachedSortType(parsers,i){return parsers[i].type;};this.construct=function(settings){return this.each(function(){if(!this.tHead||!this.tBodies)return;var $this,$document,$headers,cache,config,shiftDown=0,sortOrder;this.config={};config=$.extend(this.config,$.tablesorter.defaults,settings);$this=$(this);$.data(this,"tablesorter",config);$headers=buildHeaders(this);this.config.parsers=buildParserCache(this,$headers);cache=buildCache(this);var sortCSS=[config.cssDesc,config.cssAsc];fixColumnWidth(this);$headers.click(function(e){var totalRows=($this[0].tBodies[0]&&$this[0].tBodies[0].rows.length)||0;if(!this.sortDisabled&&totalRows>0){$this.trigger("sortStart");var $cell=$(this);var i=this.column;this.order=this.count++%2;if(this.lockedOrder)this.order=this.lockedOrder;if(!e[config.sortMultiSortKey]){config.sortList=[];if(config.sortForce!=null){var a=config.sortForce;for(var j=0;j<a.length;j++){if(a[j][0]!=i){config.sortList.push(a[j]);}}}
		config.sortList.push([i,this.order]);}else{if(isValueInArray(i,config.sortList)){for(var j=0;j<config.sortList.length;j++){var s=config.sortList[j],o=config.headerList[s[0]];if(s[0]==i){o.count=s[1];o.count++;s[1]=o.count%2;}}}else{config.sortList.push([i,this.order]);}};setTimeout(function(){setHeadersCss($this[0],$headers,config.sortList,sortCSS);appendToTable($this[0],multisort($this[0],config.sortList,cache));},1);return false;}}).mousedown(function(){if(config.cancelSelection){this.onselectstart=function(){return false};return false;}});$this.bind("update",function(){var me=this;setTimeout(function(){me.config.parsers=buildParserCache(me,$headers);cache=buildCache(me);},1);}).bind("updateCell",function(e,cell){var config=this.config;var pos=[(cell.parentNode.rowIndex-1),cell.cellIndex];cache.normalized[pos[0]][pos[1]]=config.parsers[pos[1]].format(getElementText(config,cell),cell);}).bind("sorton",function(e,list){$(this).trigger("sortStart");config.sortList=list;var sortList=config.sortList;updateHeaderSortCount(this,sortList);setHeadersCss(this,$headers,sortList,sortCSS);appendToTable(this,multisort(this,sortList,cache));}).bind("appendCache",function(){appendToTable(this,cache);}).bind("applyWidgetId",function(e,id){getWidgetById(id).format(this);}).bind("applyWidgets",function(){applyWidget(this);});if($.metadata&&($(this).metadata()&&$(this).metadata().sortlist)){config.sortList=$(this).metadata().sortlist;}
		if(config.sortList.length>0){$this.trigger("sorton",[config.sortList]);}
		applyWidget(this);});};this.addParser=function(parser){var l=parsers.length,a=true;for(var i=0;i<l;i++){if(parsers[i].id.toLowerCase()==parser.id.toLowerCase()){a=false;}}
		if(a){parsers.push(parser);};};this.addWidget=function(widget){widgets.push(widget);};this.formatFloat=function(s){var i=parseFloat(s);return(isNaN(i))?0:i;};this.formatInt=function(s){var i=parseInt(s);return(isNaN(i))?0:i;};this.isDigit=function(s,config){return/^[-+]?\d*$/.test($.trim(s.replace(/[,.']/g,'')));};this.clearTableBody=function(table){if($.browser.msie){function empty(){while(this.firstChild)
		this.removeChild(this.firstChild);}
		empty.apply(table.tBodies[0]);}else{table.tBodies[0].innerHTML="";}};}});$.fn.extend({tablesorter:$.tablesorter.construct});var ts=$.tablesorter;ts.addParser({id:"text",is:function(s){return true;},format:function(s){return s.toLocaleLowerCase();},type:"text"});ts.addParser({id:"digit",is:function(s,table){var c=table.config;return $.tablesorter.isDigit(s,c);},format:function(s){return $.tablesorter.formatFloat(s);},type:"numeric"});ts.addParser({id:"ipAddress",is:function(s){return/^\d{2,3}[\.]\d{2,3}[\.]\d{2,3}[\.]\d{2,3}$/.test(s);},format:function(s){var a=s.split("."),r="",l=a.length;for(var i=0;i<l;i++){var item=a[i];if(item.length==2){r+="0"+item;}else{r+=item;}}
		return $.tablesorter.formatFloat(r);},type:"numeric"});ts.addParser({id:"url",is:function(s){return/^(https?|ftp|file):\/\/$/.test(s);},format:function(s){return jQuery.trim(s.replace(new RegExp(/(https?|ftp|file):\/\//),''));},type:"text"});ts.addParser({id:"isoDate",is:function(s){return/^\d{4}[\/-]\d{1,2}[\/-]\d{1,2}$/.test(s);},format:function(s){return $.tablesorter.formatFloat((s!="")?new Date(s.replace(new RegExp(/-/g),"/")).getTime():"0");},type:"numeric"});ts.addParser({id:"percent",is:function(s){return/\%$/.test($.trim(s));},format:function(s){return $.tablesorter.formatFloat(s.replace(new RegExp(/%/g),""));},type:"numeric"});ts.addParser({id:"usLongDate",is:function(s){return s.match(new RegExp(/^[A-Za-z]{3,10}\.? [0-9]{1,2}, ([0-9]{4}|'?[0-9]{2}) (([0-2]?[0-9]:[0-5][0-9])|([0-1]?[0-9]:[0-5][0-9]\s(AM|PM)))$/));},format:function(s){return $.tablesorter.formatFloat(new Date(s).getTime());},type:"numeric"});ts.addParser({id:"shortDate",is:function(s){return/\d{1,2}[\/\-]\d{1,2}[\/\-]\d{2,4}/.test(s);},format:function(s,table){var c=table.config;s=s.replace(/\-/g,"/");if(c.dateFormat=="us"){s=s.replace(/(\d{1,2})[\/\-](\d{1,2})[\/\-](\d{4})/,"$3/$1/$2");}else if(c.dateFormat=="uk"){s=s.replace(/(\d{1,2})[\/\-](\d{1,2})[\/\-](\d{4})/,"$3/$2/$1");}else if(c.dateFormat=="dd/mm/yy"||c.dateFormat=="dd-mm-yy"){s=s.replace(/(\d{1,2})[\/\-](\d{1,2})[\/\-](\d{2})/,"$1/$2/$3");}
		return $.tablesorter.formatFloat(new Date(s).getTime());},type:"numeric"});ts.addParser({id:"time",is:function(s){return/^(([0-2]?[0-9]:[0-5][0-9])|([0-1]?[0-9]:[0-5][0-9]\s(am|pm)))$/.test(s);},format:function(s){return $.tablesorter.formatFloat(new Date("2000/01/01 "+s).getTime());},type:"numeric"});ts.addParser({id:"metadata",is:function(s){return false;},format:function(s,table,cell){var c=table.config,p=(!c.parserMetadataName)?'sortValue':c.parserMetadataName;return $(cell).metadata()[p];},type:"numeric"});ts.addParser({id:"filesize",is:function(s){return/^.*(bytes|KB|MB|GB|TB)$/.test(s);},format:function(s){if(s.indexOf("bytes")>=0)return parseFloat(s);if(s.indexOf("KB")>=0)return parseFloat(s)*1024;if(s.indexOf("MB")>=0)return parseFloat(s)*1024*1024;if(s.indexOf("GB")>=0)return parseFloat(s)*1024*1024*1024;if(s.indexOf("TB")>=0)return parseFloat(s)*1024*1024*1024*1024;},type:"numeric"});ts.addWidget({id:"zebra",format:function(table){if(table.config.debug){var time=new Date();}
		var $tr,row=-1,odd;$("tr:visible",table.tBodies[0]).each(function(i){$tr=$(this);if(!$tr.hasClass(table.config.cssChildRow))row++;odd=(row%2==0);$tr.removeClass(table.config.widgetZebra.css[odd?0:1]).addClass(table.config.widgetZebra.css[odd?1:0])});if(table.config.debug){$.tablesorter.benchmark("Applying Zebra widget",time);}}});})(jQuery);
	</script> 

	<script type="text/javascript">
		/* --- Splitter: http://methvin.com/splitter/ --- */
		;(function($){$.fn.splitter=function(args){args=args||{};return this.each(function(){var zombie;function startSplitMouse(evt){if(opts.outline)
		zombie=zombie||bar.clone(false).insertAfter(A);panes.css("-webkit-user-select","none");bar.addClass(opts.activeClass);A._posSplit=A[0][opts.pxSplit]-evt[opts.eventPos];$(document).bind("mousemove",doSplitMouse).bind("mouseup",endSplitMouse);}
		function doSplitMouse(evt){var newPos=A._posSplit+evt[opts.eventPos];if(opts.outline){newPos=Math.max(0,Math.min(newPos,splitter._DA-bar._DA));bar.css(opts.origin,newPos);}else
		resplit(newPos);}
		function endSplitMouse(evt){bar.removeClass(opts.activeClass);var newPos=A._posSplit+evt[opts.eventPos];if(opts.outline){zombie.remove();zombie=null;resplit(newPos);}
		panes.css("-webkit-user-select","text");$(document).unbind("mousemove",doSplitMouse).unbind("mouseup",endSplitMouse);}
		function resplit(newPos){newPos=Math.max(A._min,splitter._DA-B._max,Math.min(newPos,A._max,splitter._DA-bar._DA-B._min));bar._DA=bar[0][opts.pxSplit];bar.css(opts.origin,newPos).css(opts.fixed,splitter._DF);A.css(opts.origin,0).css(opts.split,newPos).css(opts.fixed,splitter._DF);B.css(opts.origin,newPos+bar._DA).css(opts.split,splitter._DA-bar._DA-newPos).css(opts.fixed,splitter._DF);if(!$.browser.msie)
		panes.trigger("resize");}
		function dimSum(jq,dims){var sum=0;for(var i=1;i<arguments.length;i++)
		sum+=Math.max(parseInt(jq.css(arguments[i]))||0,0);return sum;}
		var vh=(args.splitHorizontal?'h':args.splitVertical?'v':args.type)||'v';var opts=$.extend({activeClass:'active',pxPerKey:8,tabIndex:0,accessKey:''},{v:{keyLeft:39,keyRight:37,cursor:"e-resize",splitbarClass:"vsplitbar",outlineClass:"voutline",type:'v',eventPos:"pageX",origin:"left",split:"width",pxSplit:"offsetWidth",side1:"Left",side2:"Right",fixed:"height",pxFixed:"offsetHeight",side3:"Top",side4:"Bottom"},h:{keyTop:40,keyBottom:38,cursor:"n-resize",splitbarClass:"hsplitbar",outlineClass:"houtline",type:'h',eventPos:"pageY",origin:"top",split:"height",pxSplit:"offsetHeight",side1:"Top",side2:"Bottom",fixed:"width",pxFixed:"offsetWidth",side3:"Left",side4:"Right"}}[vh],args);var splitter=$(this).css({position:"relative"});var panes=$(">*",splitter[0]).css({position:"absolute","z-index":"1","-moz-outline-style":"none"});var A=$(panes[0]);var B=$(panes[1]);var focuser=$('<a href="javascript:void(0)"></a>').attr({accessKey:opts.accessKey,tabIndex:opts.tabIndex,title:opts.splitbarClass}).bind($.browser.opera?"click":"focus",function(){this.focus();bar.addClass(opts.activeClass)}).bind("keydown",function(e){var key=e.which||e.keyCode;var dir=key==opts["key"+opts.side1]?1:key==opts["key"+opts.side2]?-1:0;if(dir)
		resplit(A[0][opts.pxSplit]+dir*opts.pxPerKey,false);}).bind("blur",function(){bar.removeClass(opts.activeClass)});var bar=$(panes[2]||'<div></div>').insertAfter(A).css("z-index","100").append(focuser).attr({"class":opts.splitbarClass,unselectable:"on"}).css({position:"absolute","user-select":"none","-webkit-user-select":"none","-khtml-user-select":"none","-moz-user-select":"none"}).bind("mousedown",startSplitMouse);if(/^(auto|default|)$/.test(bar.css("cursor")))
		bar.css("cursor",opts.cursor);bar._DA=bar[0][opts.pxSplit];splitter._PBF=$.boxModel?dimSum(splitter,"border"+opts.side3+"Width","border"+opts.side4+"Width"):0;splitter._PBA=$.boxModel?dimSum(splitter,"border"+opts.side1+"Width","border"+opts.side2+"Width"):0;A._pane=opts.side1;B._pane=opts.side2;$.each([A,B],function(){this._min=opts["min"+this._pane]||dimSum(this,"min-"+opts.split);this._max=opts["max"+this._pane]||dimSum(this,"max-"+opts.split)||9999;this._init=opts["size"+this._pane]===true?parseInt($.curCSS(this[0],opts.split)):opts["size"+this._pane];});var initPos=A._init;if(!isNaN(B._init))
		initPos=splitter[0][opts.pxSplit]-splitter._PBA-B._init-bar._DA;if(opts.cookie){if(!$.cookie)
		alert('jQuery.splitter(): jQuery cookie plugin required');var ckpos=parseInt($.cookie(opts.cookie));if(!isNaN(ckpos))
		initPos=ckpos;$(window).bind("unload",function(){var state=String(bar.css(opts.origin));$.cookie(opts.cookie,state,{expires:opts.cookieExpires||365,path:opts.cookiePath||document.location.pathname});});}
		if(isNaN(initPos))
		initPos=Math.round((splitter[0][opts.pxSplit]-splitter._PBA-bar._DA)/2);if(opts.anchorToWindow){splitter._hadjust=dimSum(splitter,"borderTopWidth","borderBottomWidth","marginBottom");splitter._hmin=Math.max(dimSum(splitter,"minHeight"),20);$(window).bind("resize",function(){var top=splitter.offset().top;var wh=$(window).height();splitter.css("height",Math.max(wh-top-splitter._hadjust,splitter._hmin)+"px");if(!$.browser.msie)splitter.trigger("resize");}).trigger("resize");}
		else if(opts.resizeToWidth&&!$.browser.msie)
		$(window).bind("resize",function(){splitter.trigger("resize");});splitter.bind("resize",function(e,size){if(e.target!=this)return;splitter._DF=splitter[0][opts.pxFixed]-splitter._PBF;splitter._DA=splitter[0][opts.pxSplit]-splitter._PBA;if(splitter._DF<=0||splitter._DA<=0)return;resplit(!isNaN(size)?size:(!(opts.sizeRight||opts.sizeBottom)?A[0][opts.pxSplit]:splitter._DA-B[0][opts.pxSplit]-bar._DA));}).trigger("resize",[initPos]);});};})(jQuery);
	</script> 

	<script type="text/javascript">
		/* --- jQuery UI v1.8.24:  https://github.com/jquery/jquery-ui --- */
		/* --- Used by DynaTree --- Only required modules included --- */
		/* jquery.ui.core.js */
		(function(a,b){function c(b,c){var e=b.nodeName.toLowerCase();if("area"===e){var f=b.parentNode,g=f.name,h;return!b.href||!g||f.nodeName.toLowerCase()!=="map"?!1:(h=a("img[usemap=#"+g+"]")[0],!!h&&d(h))}return(/input|select|textarea|button|object/.test(e)?!b.disabled:"a"==e?b.href||c:c)&&d(b)}function d(b){return!a(b).parents().andSelf().filter(function(){return a.curCSS(this,"visibility")==="hidden"||a.expr.filters.hidden(this)}).length}a.ui=a.ui||{};if(a.ui.version)return;a.extend(a.ui,{version:"1.8.24",keyCode:{ALT:18,BACKSPACE:8,CAPS_LOCK:20,COMMA:188,COMMAND:91,COMMAND_LEFT:91,COMMAND_RIGHT:93,CONTROL:17,DELETE:46,DOWN:40,END:35,ENTER:13,ESCAPE:27,HOME:36,INSERT:45,LEFT:37,MENU:93,NUMPAD_ADD:107,NUMPAD_DECIMAL:110,NUMPAD_DIVIDE:111,NUMPAD_ENTER:108,NUMPAD_MULTIPLY:106,NUMPAD_SUBTRACT:109,PAGE_DOWN:34,PAGE_UP:33,PERIOD:190,RIGHT:39,SHIFT:16,SPACE:32,TAB:9,UP:38,WINDOWS:91}}),a.fn.extend({propAttr:a.fn.prop||a.fn.attr,_focus:a.fn.focus,focus:function(b,c){return typeof b=="number"?this.each(function(){var d=this;setTimeout(function(){a(d).focus(),c&&c.call(d)},b)}):this._focus.apply(this,arguments)},scrollParent:function(){var b;return a.browser.msie&&/(static|relative)/.test(this.css("position"))||/absolute/.test(this.css("position"))?b=this.parents().filter(function(){return/(relative|absolute|fixed)/.test(a.curCSS(this,"position",1))&&/(auto|scroll)/.test(a.curCSS(this,"overflow",1)+a.curCSS(this,"overflow-y",1)+a.curCSS(this,"overflow-x",1))}).eq(0):b=this.parents().filter(function(){return/(auto|scroll)/.test(a.curCSS(this,"overflow",1)+a.curCSS(this,"overflow-y",1)+a.curCSS(this,"overflow-x",1))}).eq(0),/fixed/.test(this.css("position"))||!b.length?a(document):b},zIndex:function(c){if(c!==b)return this.css("zIndex",c);if(this.length){var d=a(this[0]),e,f;while(d.length&&d[0]!==document){e=d.css("position");if(e==="absolute"||e==="relative"||e==="fixed"){f=parseInt(d.css("zIndex"),10);if(!isNaN(f)&&f!==0)return f}d=d.parent()}}return 0},disableSelection:function(){return this.bind((a.support.selectstart?"selectstart":"mousedown")+".ui-disableSelection",function(a){a.preventDefault()})},enableSelection:function(){return this.unbind(".ui-disableSelection")}}),a("<a>").outerWidth(1).jquery||a.each(["Width","Height"],function(c,d){function h(b,c,d,f){return a.each(e,function(){c-=parseFloat(a.curCSS(b,"padding"+this,!0))||0,d&&(c-=parseFloat(a.curCSS(b,"border"+this+"Width",!0))||0),f&&(c-=parseFloat(a.curCSS(b,"margin"+this,!0))||0)}),c}var e=d==="Width"?["Left","Right"]:["Top","Bottom"],f=d.toLowerCase(),g={innerWidth:a.fn.innerWidth,innerHeight:a.fn.innerHeight,outerWidth:a.fn.outerWidth,outerHeight:a.fn.outerHeight};a.fn["inner"+d]=function(c){return c===b?g["inner"+d].call(this):this.each(function(){a(this).css(f,h(this,c)+"px")})},a.fn["outer"+d]=function(b,c){return typeof b!="number"?g["outer"+d].call(this,b):this.each(function(){a(this).css(f,h(this,b,!0,c)+"px")})}}),a.extend(a.expr[":"],{data:a.expr.createPseudo?a.expr.createPseudo(function(b){return function(c){return!!a.data(c,b)}}):function(b,c,d){return!!a.data(b,d[3])},focusable:function(b){return c(b,!isNaN(a.attr(b,"tabindex")))},tabbable:function(b){var d=a.attr(b,"tabindex"),e=isNaN(d);return(e||d>=0)&&c(b,!e)}}),a(function(){var b=document.body,c=b.appendChild(c=document.createElement("div"));c.offsetHeight,a.extend(c.style,{minHeight:"100px",height:"auto",padding:0,borderWidth:0}),a.support.minHeight=c.offsetHeight===100,a.support.selectstart="onselectstart"in c,b.removeChild(c).style.display="none"}),a.curCSS||(a.curCSS=a.css),a.extend(a.ui,{plugin:{add:function(b,c,d){var e=a.ui[b].prototype;for(var f in d)e.plugins[f]=e.plugins[f]||[],e.plugins[f].push([c,d[f]])},call:function(a,b,c){var d=a.plugins[b];if(!d||!a.element[0].parentNode)return;for(var e=0;e<d.length;e++)a.options[d[e][0]]&&d[e][1].apply(a.element,c)}},contains:function(a,b){return document.compareDocumentPosition?a.compareDocumentPosition(b)&16:a!==b&&a.contains(b)},hasScroll:function(b,c){if(a(b).css("overflow")==="hidden")return!1;var d=c&&c==="left"?"scrollLeft":"scrollTop",e=!1;return b[d]>0?!0:(b[d]=1,e=b[d]>0,b[d]=0,e)},isOverAxis:function(a,b,c){return a>b&&a<b+c},isOver:function(b,c,d,e,f,g){return a.ui.isOverAxis(b,d,f)&&a.ui.isOverAxis(c,e,g)}})})(jQuery);;/*! jQuery UI - v1.8.24 - 2012-09-28
		/* jquery.ui.widget.js */
		(function(a,b){if(a.cleanData){var c=a.cleanData;a.cleanData=function(b){for(var d=0,e;(e=b[d])!=null;d++)try{a(e).triggerHandler("remove")}catch(f){}c(b)}}else{var d=a.fn.remove;a.fn.remove=function(b,c){return this.each(function(){return c||(!b||a.filter(b,[this]).length)&&a("*",this).add([this]).each(function(){try{a(this).triggerHandler("remove")}catch(b){}}),d.call(a(this),b,c)})}}a.widget=function(b,c,d){var e=b.split(".")[0],f;b=b.split(".")[1],f=e+"-"+b,d||(d=c,c=a.Widget),a.expr[":"][f]=function(c){return!!a.data(c,b)},a[e]=a[e]||{},a[e][b]=function(a,b){arguments.length&&this._createWidget(a,b)};var g=new c;g.options=a.extend(!0,{},g.options),a[e][b].prototype=a.extend(!0,g,{namespace:e,widgetName:b,widgetEventPrefix:a[e][b].prototype.widgetEventPrefix||b,widgetBaseClass:f},d),a.widget.bridge(b,a[e][b])},a.widget.bridge=function(c,d){a.fn[c]=function(e){var f=typeof e=="string",g=Array.prototype.slice.call(arguments,1),h=this;return e=!f&&g.length?a.extend.apply(null,[!0,e].concat(g)):e,f&&e.charAt(0)==="_"?h:(f?this.each(function(){var d=a.data(this,c),f=d&&a.isFunction(d[e])?d[e].apply(d,g):d;if(f!==d&&f!==b)return h=f,!1}):this.each(function(){var b=a.data(this,c);b?b.option(e||{})._init():a.data(this,c,new d(e,this))}),h)}},a.Widget=function(a,b){arguments.length&&this._createWidget(a,b)},a.Widget.prototype={widgetName:"widget",widgetEventPrefix:"",options:{disabled:!1},_createWidget:function(b,c){a.data(c,this.widgetName,this),this.element=a(c),this.options=a.extend(!0,{},this.options,this._getCreateOptions(),b);var d=this;this.element.bind("remove."+this.widgetName,function(){d.destroy()}),this._create(),this._trigger("create"),this._init()},_getCreateOptions:function(){return a.metadata&&a.metadata.get(this.element[0])[this.widgetName]},_create:function(){},_init:function(){},destroy:function(){this.element.unbind("."+this.widgetName).removeData(this.widgetName),this.widget().unbind("."+this.widgetName).removeAttr("aria-disabled").removeClass(this.widgetBaseClass+"-disabled "+"ui-state-disabled")},widget:function(){return this.element},option:function(c,d){var e=c;if(arguments.length===0)return a.extend({},this.options);if(typeof c=="string"){if(d===b)return this.options[c];e={},e[c]=d}return this._setOptions(e),this},_setOptions:function(b){var c=this;return a.each(b,function(a,b){c._setOption(a,b)}),this},_setOption:function(a,b){return this.options[a]=b,a==="disabled"&&this.widget()[b?"addClass":"removeClass"](this.widgetBaseClass+"-disabled"+" "+"ui-state-disabled").attr("aria-disabled",b),this},enable:function(){return this._setOption("disabled",!1)},disable:function(){return this._setOption("disabled",!0)},_trigger:function(b,c,d){var e,f,g=this.options[b];d=d||{},c=a.Event(c),c.type=(b===this.widgetEventPrefix?b:this.widgetEventPrefix+b).toLowerCase(),c.target=this.element[0],f=c.originalEvent;if(f)for(e in f)e in c||(c[e]=f[e]);return this.element.trigger(c,d),!(a.isFunction(g)&&g.call(this.element[0],c,d)===!1||c.isDefaultPrevented())}}})(jQuery);;/*! jQuery UI - v1.8.24 - 2012-09-28
		/* jquery.ui.position.js */
		(function(a,b){a.ui=a.ui||{};var c=/left|center|right/,d=/top|center|bottom/,e="center",f={},g=a.fn.position,h=a.fn.offset;a.fn.position=function(b){if(!b||!b.of)return g.apply(this,arguments);b=a.extend({},b);var h=a(b.of),i=h[0],j=(b.collision||"flip").split(" "),k=b.offset?b.offset.split(" "):[0,0],l,m,n;return i.nodeType===9?(l=h.width(),m=h.height(),n={top:0,left:0}):i.setTimeout?(l=h.width(),m=h.height(),n={top:h.scrollTop(),left:h.scrollLeft()}):i.preventDefault?(b.at="left top",l=m=0,n={top:b.of.pageY,left:b.of.pageX}):(l=h.outerWidth(),m=h.outerHeight(),n=h.offset()),a.each(["my","at"],function(){var a=(b[this]||"").split(" ");a.length===1&&(a=c.test(a[0])?a.concat([e]):d.test(a[0])?[e].concat(a):[e,e]),a[0]=c.test(a[0])?a[0]:e,a[1]=d.test(a[1])?a[1]:e,b[this]=a}),j.length===1&&(j[1]=j[0]),k[0]=parseInt(k[0],10)||0,k.length===1&&(k[1]=k[0]),k[1]=parseInt(k[1],10)||0,b.at[0]==="right"?n.left+=l:b.at[0]===e&&(n.left+=l/2),b.at[1]==="bottom"?n.top+=m:b.at[1]===e&&(n.top+=m/2),n.left+=k[0],n.top+=k[1],this.each(function(){var c=a(this),d=c.outerWidth(),g=c.outerHeight(),h=parseInt(a.curCSS(this,"marginLeft",!0))||0,i=parseInt(a.curCSS(this,"marginTop",!0))||0,o=d+h+(parseInt(a.curCSS(this,"marginRight",!0))||0),p=g+i+(parseInt(a.curCSS(this,"marginBottom",!0))||0),q=a.extend({},n),r;b.my[0]==="right"?q.left-=d:b.my[0]===e&&(q.left-=d/2),b.my[1]==="bottom"?q.top-=g:b.my[1]===e&&(q.top-=g/2),f.fractions||(q.left=Math.round(q.left),q.top=Math.round(q.top)),r={left:q.left-h,top:q.top-i},a.each(["left","top"],function(c,e){a.ui.position[j[c]]&&a.ui.position[j[c]][e](q,{targetWidth:l,targetHeight:m,elemWidth:d,elemHeight:g,collisionPosition:r,collisionWidth:o,collisionHeight:p,offset:k,my:b.my,at:b.at})}),a.fn.bgiframe&&c.bgiframe(),c.offset(a.extend(q,{using:b.using}))})},a.ui.position={fit:{left:function(b,c){var d=a(window),e=c.collisionPosition.left+c.collisionWidth-d.width()-d.scrollLeft();b.left=e>0?b.left-e:Math.max(b.left-c.collisionPosition.left,b.left)},top:function(b,c){var d=a(window),e=c.collisionPosition.top+c.collisionHeight-d.height()-d.scrollTop();b.top=e>0?b.top-e:Math.max(b.top-c.collisionPosition.top,b.top)}},flip:{left:function(b,c){if(c.at[0]===e)return;var d=a(window),f=c.collisionPosition.left+c.collisionWidth-d.width()-d.scrollLeft(),g=c.my[0]==="left"?-c.elemWidth:c.my[0]==="right"?c.elemWidth:0,h=c.at[0]==="left"?c.targetWidth:-c.targetWidth,i=-2*c.offset[0];b.left+=c.collisionPosition.left<0?g+h+i:f>0?g+h+i:0},top:function(b,c){if(c.at[1]===e)return;var d=a(window),f=c.collisionPosition.top+c.collisionHeight-d.height()-d.scrollTop(),g=c.my[1]==="top"?-c.elemHeight:c.my[1]==="bottom"?c.elemHeight:0,h=c.at[1]==="top"?c.targetHeight:-c.targetHeight,i=-2*c.offset[1];b.top+=c.collisionPosition.top<0?g+h+i:f>0?g+h+i:0}}},a.offset.setOffset||(a.offset.setOffset=function(b,c){/static/.test(a.curCSS(b,"position"))&&(b.style.position="relative");var d=a(b),e=d.offset(),f=parseInt(a.curCSS(b,"top",!0),10)||0,g=parseInt(a.curCSS(b,"left",!0),10)||0,h={top:c.top-e.top+f,left:c.left-e.left+g};"using"in c?c.using.call(b,h):d.css(h)},a.fn.offset=function(b){var c=this[0];return!c||!c.ownerDocument?null:b?a.isFunction(b)?this.each(function(c){a(this).offset(b.call(this,c,a(this).offset()))}):this.each(function(){a.offset.setOffset(this,b)}):h.call(this)}),a.curCSS||(a.curCSS=a.css),function(){var b=document.getElementsByTagName("body")[0],c=document.createElement("div"),d,e,g,h,i;d=document.createElement(b?"div":"body"),g={visibility:"hidden",width:0,height:0,border:0,margin:0,background:"none"},b&&a.extend(g,{position:"absolute",left:"-1000px",top:"-1000px"});for(var j in g)d.style[j]=g[j];d.appendChild(c),e=b||document.documentElement,e.insertBefore(d,e.firstChild),c.style.cssText="position: absolute; left: 10.7432222px; top: 10.432325px; height: 30px; width: 201px;",h=a(c).offset(function(a,b){return b}).offset(),d.innerHTML="",e.removeChild(d),i=h.top+h.left+(b?2e3:0),f.fractions=i>21&&i<22}()})(jQuery);;/*! jQuery UI - v1.8.24 - 2012-09-28
		/* jquery.effects.core.js */
		jQuery.effects||function(a,b){function c(b){var c;return b&&b.constructor==Array&&b.length==3?b:(c=/rgb\(\s*([0-9]{1,3})\s*,\s*([0-9]{1,3})\s*,\s*([0-9]{1,3})\s*\)/.exec(b))?[parseInt(c[1],10),parseInt(c[2],10),parseInt(c[3],10)]:(c=/rgb\(\s*([0-9]+(?:\.[0-9]+)?)\%\s*,\s*([0-9]+(?:\.[0-9]+)?)\%\s*,\s*([0-9]+(?:\.[0-9]+)?)\%\s*\)/.exec(b))?[parseFloat(c[1])*2.55,parseFloat(c[2])*2.55,parseFloat(c[3])*2.55]:(c=/#([a-fA-F0-9]{2})([a-fA-F0-9]{2})([a-fA-F0-9]{2})/.exec(b))?[parseInt(c[1],16),parseInt(c[2],16),parseInt(c[3],16)]:(c=/#([a-fA-F0-9])([a-fA-F0-9])([a-fA-F0-9])/.exec(b))?[parseInt(c[1]+c[1],16),parseInt(c[2]+c[2],16),parseInt(c[3]+c[3],16)]:(c=/rgba\(0, 0, 0, 0\)/.exec(b))?e.transparent:e[a.trim(b).toLowerCase()]}function d(b,d){var e;do{e=(a.curCSS||a.css)(b,d);if(e!=""&&e!="transparent"||a.nodeName(b,"body"))break;d="backgroundColor"}while(b=b.parentNode);return c(e)}function h(){var a=document.defaultView?document.defaultView.getComputedStyle(this,null):this.currentStyle,b={},c,d;if(a&&a.length&&a[0]&&a[a[0]]){var e=a.length;while(e--)c=a[e],typeof a[c]=="string"&&(d=c.replace(/\-(\w)/g,function(a,b){return b.toUpperCase()}),b[d]=a[c])}else for(c in a)typeof a[c]=="string"&&(b[c]=a[c]);return b}function i(b){var c,d;for(c in b)d=b[c],(d==null||a.isFunction(d)||c in g||/scrollbar/.test(c)||!/color/i.test(c)&&isNaN(parseFloat(d)))&&delete b[c];return b}function j(a,b){var c={_:0},d;for(d in b)a[d]!=b[d]&&(c[d]=b[d]);return c}function k(b,c,d,e){typeof b=="object"&&(e=c,d=null,c=b,b=c.effect),a.isFunction(c)&&(e=c,d=null,c={});if(typeof c=="number"||a.fx.speeds[c])e=d,d=c,c={};return a.isFunction(d)&&(e=d,d=null),c=c||{},d=d||c.duration,d=a.fx.off?0:typeof d=="number"?d:d in a.fx.speeds?a.fx.speeds[d]:a.fx.speeds._default,e=e||c.complete,[b,c,d,e]}function l(b){return!b||typeof b=="number"||a.fx.speeds[b]?!0:typeof b=="string"&&!a.effects[b]?!0:!1}a.effects={},a.each(["backgroundColor","borderBottomColor","borderLeftColor","borderRightColor","borderTopColor","borderColor","color","outlineColor"],function(b,e){a.fx.step[e]=function(a){a.colorInit||(a.start=d(a.elem,e),a.end=c(a.end),a.colorInit=!0),a.elem.style[e]="rgb("+Math.max(Math.min(parseInt(a.pos*(a.end[0]-a.start[0])+a.start[0],10),255),0)+","+Math.max(Math.min(parseInt(a.pos*(a.end[1]-a.start[1])+a.start[1],10),255),0)+","+Math.max(Math.min(parseInt(a.pos*(a.end[2]-a.start[2])+a.start[2],10),255),0)+")"}});var e={aqua:[0,255,255],azure:[240,255,255],beige:[245,245,220],black:[0,0,0],blue:[0,0,255],brown:[165,42,42],cyan:[0,255,255],darkblue:[0,0,139],darkcyan:[0,139,139],darkgrey:[169,169,169],darkgreen:[0,100,0],darkkhaki:[189,183,107],darkmagenta:[139,0,139],darkolivegreen:[85,107,47],darkorange:[255,140,0],darkorchid:[153,50,204],darkred:[139,0,0],darksalmon:[233,150,122],darkviolet:[148,0,211],fuchsia:[255,0,255],gold:[255,215,0],green:[0,128,0],indigo:[75,0,130],khaki:[240,230,140],lightblue:[173,216,230],lightcyan:[224,255,255],lightgreen:[144,238,144],lightgrey:[211,211,211],lightpink:[255,182,193],lightyellow:[255,255,224],lime:[0,255,0],magenta:[255,0,255],maroon:[128,0,0],navy:[0,0,128],olive:[128,128,0],orange:[255,165,0],pink:[255,192,203],purple:[128,0,128],violet:[128,0,128],red:[255,0,0],silver:[192,192,192],white:[255,255,255],yellow:[255,255,0],transparent:[255,255,255]},f=["add","remove","toggle"],g={border:1,borderBottom:1,borderColor:1,borderLeft:1,borderRight:1,borderTop:1,borderWidth:1,margin:1,padding:1};a.effects.animateClass=function(b,c,d,e){return a.isFunction(d)&&(e=d,d=null),this.queue(function(){var g=a(this),k=g.attr("style")||" ",l=i(h.call(this)),m,n=g.attr("class")||"";a.each(f,function(a,c){b[c]&&g[c+"Class"](b[c])}),m=i(h.call(this)),g.attr("class",n),g.animate(j(l,m),{queue:!1,duration:c,easing:d,complete:function(){a.each(f,function(a,c){b[c]&&g[c+"Class"](b[c])}),typeof g.attr("style")=="object"?(g.attr("style").cssText="",g.attr("style").cssText=k):g.attr("style",k),e&&e.apply(this,arguments),a.dequeue(this)}})})},a.fn.extend({_addClass:a.fn.addClass,addClass:function(b,c,d,e){return c?a.effects.animateClass.apply(this,[{add:b},c,d,e]):this._addClass(b)},_removeClass:a.fn.removeClass,removeClass:function(b,c,d,e){return c?a.effects.animateClass.apply(this,[{remove:b},c,d,e]):this._removeClass(b)},_toggleClass:a.fn.toggleClass,toggleClass:function(c,d,e,f,g){return typeof d=="boolean"||d===b?e?a.effects.animateClass.apply(this,[d?{add:c}:{remove:c},e,f,g]):this._toggleClass(c,d):a.effects.animateClass.apply(this,[{toggle:c},d,e,f])},switchClass:function(b,c,d,e,f){return a.effects.animateClass.apply(this,[{add:c,remove:b},d,e,f])}}),a.extend(a.effects,{version:"1.8.24",save:function(a,b){for(var c=0;c<b.length;c++)b[c]!==null&&a.data("ec.storage."+b[c],a[0].style[b[c]])},restore:function(a,b){for(var c=0;c<b.length;c++)b[c]!==null&&a.css(b[c],a.data("ec.storage."+b[c]))},setMode:function(a,b){return b=="toggle"&&(b=a.is(":hidden")?"show":"hide"),b},getBaseline:function(a,b){var c,d;switch(a[0]){case"top":c=0;break;case"middle":c=.5;break;case"bottom":c=1;break;default:c=a[0]/b.height}switch(a[1]){case"left":d=0;break;case"center":d=.5;break;case"right":d=1;break;default:d=a[1]/b.width}return{x:d,y:c}},createWrapper:function(b){if(b.parent().is(".ui-effects-wrapper"))return b.parent();var c={width:b.outerWidth(!0),height:b.outerHeight(!0),"float":b.css("float")},d=a("<div></div>").addClass("ui-effects-wrapper").css({fontSize:"100%",background:"transparent",border:"none",margin:0,padding:0}),e=document.activeElement;try{e.id}catch(f){e=document.body}return b.wrap(d),(b[0]===e||a.contains(b[0],e))&&a(e).focus(),d=b.parent(),b.css("position")=="static"?(d.css({position:"relative"}),b.css({position:"relative"})):(a.extend(c,{position:b.css("position"),zIndex:b.css("z-index")}),a.each(["top","left","bottom","right"],function(a,d){c[d]=b.css(d),isNaN(parseInt(c[d],10))&&(c[d]="auto")}),b.css({position:"relative",top:0,left:0,right:"auto",bottom:"auto"})),d.css(c).show()},removeWrapper:function(b){var c,d=document.activeElement;return b.parent().is(".ui-effects-wrapper")?(c=b.parent().replaceWith(b),(b[0]===d||a.contains(b[0],d))&&a(d).focus(),c):b},setTransition:function(b,c,d,e){return e=e||{},a.each(c,function(a,c){var f=b.cssUnit(c);f[0]>0&&(e[c]=f[0]*d+f[1])}),e}}),a.fn.extend({effect:function(b,c,d,e){var f=k.apply(this,arguments),g={options:f[1],duration:f[2],callback:f[3]},h=g.options.mode,i=a.effects[b];return a.fx.off||!i?h?this[h](g.duration,g.callback):this.each(function(){g.callback&&g.callback.call(this)}):i.call(this,g)},_show:a.fn.show,show:function(a){if(l(a))return this._show.apply(this,arguments);var b=k.apply(this,arguments);return b[1].mode="show",this.effect.apply(this,b)},_hide:a.fn.hide,hide:function(a){if(l(a))return this._hide.apply(this,arguments);var b=k.apply(this,arguments);return b[1].mode="hide",this.effect.apply(this,b)},__toggle:a.fn.toggle,toggle:function(b){if(l(b)||typeof b=="boolean"||a.isFunction(b))return this.__toggle.apply(this,arguments);var c=k.apply(this,arguments);return c[1].mode="toggle",this.effect.apply(this,c)},cssUnit:function(b){var c=this.css(b),d=[];return a.each(["em","px","%","pt"],function(a,b){c.indexOf(b)>0&&(d=[parseFloat(c),b])}),d}});var m={};a.each(["Quad","Cubic","Quart","Quint","Expo"],function(a,b){m[b]=function(b){return Math.pow(b,a+2)}}),a.extend(m,{Sine:function(a){return 1-Math.cos(a*Math.PI/2)},Circ:function(a){return 1-Math.sqrt(1-a*a)},Elastic:function(a){return a===0||a===1?a:-Math.pow(2,8*(a-1))*Math.sin(((a-1)*80-7.5)*Math.PI/15)},Back:function(a){return a*a*(3*a-2)},Bounce:function(a){var b,c=4;while(a<((b=Math.pow(2,--c))-1)/11);return 1/Math.pow(4,3-c)-7.5625*Math.pow((b*3-2)/22-a,2)}}),a.each(m,function(b,c){a.easing["easeIn"+b]=c,a.easing["easeOut"+b]=function(a){return 1-c(1-a)},a.easing["easeInOut"+b]=function(a){return a<.5?c(a*2)/2:c(a*-2+2)/-2+1}})}(jQuery);;/*! jQuery UI - v1.8.24 - 2012-09-28
		/* jquery.effects.transfer.js */
		(function(a,b){a.effects.transfer=function(b){return this.queue(function(){var c=a(this),d=a(b.options.to),e=d.offset(),f={top:e.top,left:e.left,height:d.innerHeight(),width:d.innerWidth()},g=c.offset(),h=a('<div class="ui-effects-transfer"></div>').appendTo(document.body).addClass(b.options.className).css({top:g.top,left:g.left,height:c.innerHeight(),width:c.innerWidth(),position:"absolute"}).animate(f,b.duration,b.options.easing,function(){h.remove(),b.callback&&b.callback.apply(c[0],arguments),c.dequeue()})})}})(jQuery);;
	</script>

	<script type="text/javascript">
		/* --- Dynatree Plugin - v1.2.4 https://github.com/mar10/dynatree --- */
		/* --- Slightly modified for use with Snap2HTML(in "_onClick: function(event) {" focus x3 was removed to prevent page from jumping around) */
		function _log(e,t){return;if(!_canLog)return;var n=Array.prototype.slice.apply(arguments,[1]),r=new Date,i=r.getHours()+":"+r.getMinutes()+":"+r.getSeconds()+"."+r.getMilliseconds();n[0]=i+" - "+n[0];try{switch(e){case"info":window.console.info.apply(window.console,n);break;case"warn":window.console.warn.apply(window.console,n);break;default:window.console.log.apply(window.console,n)}}catch(s){window.console?s.number===-2146827850&&window.console.log(n.join(", ")):_canLog=!1}}function _checkBrowser(){function n(e){e=e.toLowerCase();var t=/(chrome)[ \/]([\w.]+)/.exec(e)||/(webkit)[ \/]([\w.]+)/.exec(e)||/(opera)(?:.*version|)[ \/]([\w.]+)/.exec(e)||/(msie) ([\w.]+)/.exec(e)||e.indexOf("compatible")<0&&/(mozilla)(?:.*? rv:([\w.]+)|)/.exec(e)||[];return{browser:t[1]||"",version:t[2]||"0"}}var e,t;return e=n(navigator.userAgent),t={},e.browser&&(t[e.browser]=!0,t.version=e.version),t.chrome?t.webkit=!0:t.webkit&&(t.safari=!0),t}function logMsg(e){Array.prototype.unshift.apply(arguments,["debug"]),_log.apply(this,arguments)}var _canLog=!0,BROWSER=jQuery.browser||_checkBrowser(),getDynaTreePersistData=null,DTNodeStatus_Error=-1,DTNodeStatus_Loading=1,DTNodeStatus_Ok=0;(function($){function getDtNodeFromElement(e){return alert("getDtNodeFromElement is deprecated"),$.ui.dynatree.getNode(e)}function noop(){}function versionCompare(e,t){var n=(""+e).split("."),r=(""+t).split("."),i=Math.min(n.length,r.length),s,o,u;for(u=0;u<i;u++){s=parseInt(n[u],10),o=parseInt(r[u],10),isNaN(s)&&(s=n[u]),isNaN(o)&&(o=r[u]);if(s==o)continue;return s>o?1:s<o?-1:NaN}return n.length===r.length?0:n.length<r.length?-1:1}function _initDragAndDrop(e){var t=e.options.dnd||null;t&&(t.onDragStart||t.onDrop)&&_registerDnd(),t&&t.onDragStart&&e.$tree.draggable({addClasses:!1,appendTo:"body",containment:!1,delay:0,distance:4,revert:!1,scroll:!0,scrollSpeed:7,scrollSensitivity:10,connectToDynatree:!0,helper:function(e){var t=$.ui.dynatree.getNode(e.target);return t?t.tree._onDragEvent("helper",t,null,e,null,null):"<div></div>"},start:function(e,t){var n=t.helper.data("dtSourceNode");return!!n},_last:null}),t&&t.onDrop&&e.$tree.droppable({addClasses:!1,tolerance:"intersect",greedy:!1,_last:null})}var Class={create:function(){return function(){this.initialize.apply(this,arguments)}}},DynaTreeNode=Class.create();DynaTreeNode.prototype={initialize:function(e,t,n){this.parent=e,this.tree=t,typeof n=="string"&&(n={title:n}),n.key?n.key=""+n.key:n.key="_"+t._nodeCount++,this.data=$.extend({},$.ui.dynatree.nodedatadefaults,n),this.li=null,this.span=null,this.ul=null,this.childList=null,this._isLoading=!1,this.hasSubSel=!1,this.bExpanded=!1,this.bSelected=!1},toString:function(){return"DynaTreeNode<"+this.data.key+">: '"+this.data.title+"'"},toDict:function(e,t){var n=$.extend({},this.data);n.activate=this.tree.activeNode===this,n.focus=this.tree.focusNode===this,n.expand=this.bExpanded,n.select=this.bSelected,t&&t(n);if(e&&this.childList){n.children=[];for(var r=0,i=this.childList.length;r<i;r++)n.children.push(this.childList[r].toDict(!0,t))}else delete n.children;return n},fromDict:function(e){var t=e.children;if(t===undefined){this.data=$.extend(this.data,e),this.render();return}e=$.extend({},e),e.children=undefined,this.data=$.extend(this.data,e),this.removeChildren(),this.addChild(t)},_getInnerHtml:function(){var e=this.tree,t=e.options,n=e.cache,r=this.getLevel(),i=this.data,s="",o;r<t.minExpandLevel?r>1&&(s+=n.tagConnector):this.hasChildren()!==!1?s+=n.tagExpander:s+=n.tagConnector,t.checkbox&&i.hideCheckbox!==!0&&!i.isStatusNode&&(s+=n.tagCheckbox),i.icon?(i.icon.charAt(0)==="/"?o=i.icon:o=t.imagePath+i.icon,s+="<img src='"+o+"' alt='' />"):i.icon!==!1&&(i.iconClass?s+="<span class=' "+i.iconClass+"'></span>":s+=n.tagNodeIcon);var u="";t.onCustomRender&&(u=t.onCustomRender.call(e,this)||"");if(!u){var a=i.tooltip?' title="'+i.tooltip.replace(/\"/g,"&quot;")+'"':"",f=i.href||"#";t.noLink||i.noLink?u='<span style="display:inline-block;" class="'+t.classNames.title+'"'+a+">"+i.title+"</span>":u='<a href="'+f+'" class="'+t.classNames.title+'"'+a+">"+i.title+"</a>"}return s+=u,s},_fixOrder:function(){var e=this.childList;if(!e||!this.ul)return;var t=this.ul.firstChild;for(var n=0,r=e.length-1;n<r;n++){var i=e[n],s=t.dtnode;i!==s?(this.tree.logDebug("_fixOrder: mismatch at index "+n+": "+i+" != "+s),this.ul.insertBefore(i.li,s.li)):t=t.nextSibling}},render:function(e,t){var n=this.tree,r=this.parent,i=this.data,s=n.options,o=s.classNames,u=this.isLastSibling(),a=!1;if(!r&&!this.ul)this.li=this.span=null,this.ul=document.createElement("ul"),s.minExpandLevel>1?this.ul.className=o.container+" "+o.noConnector:this.ul.className=o.container;else if(r){this.li||(a=!0,this.li=document.createElement("li"),this.li.dtnode=this,i.key&&s.generateIds&&(this.li.id=s.idPrefix+i.key),this.span=document.createElement("span"),this.span.className=o.title,this.li.appendChild(this.span),r.ul||(r.ul=document.createElement("ul"),r.ul.style.display="none",r.li.appendChild(r.ul)),r.ul.appendChild(this.li)),this.span.innerHTML=this._getInnerHtml();var f=[];f.push(o.node),i.isFolder&&f.push(o.folder),this.bExpanded&&f.push(o.expanded),this.hasChildren()!==!1&&f.push(o.hasChildren),i.isLazy&&this.childList===null&&f.push(o.lazy),u&&f.push(o.lastsib),this.bSelected&&f.push(o.selected),this.hasSubSel&&f.push(o.partsel),n.activeNode===this&&f.push(o.active),i.addClass&&f.push(i.addClass),f.push(o.combinedExpanderPrefix+(this.bExpanded?"e":"c")+(i.isLazy&&this.childList===null?"d":"")+(u?"l":"")),f.push(o.combinedIconPrefix+(this.bExpanded?"e":"c")+(i.isFolder?"f":"")),this.span.className=f.join(" "),this.li.className=u?o.lastsib:"",a&&s.onCreate&&s.onCreate.call(n,this,this.span),s.onRender&&s.onRender.call(n,this,this.span)}if((this.bExpanded||t===!0)&&this.childList){for(var l=0,c=this.childList.length;l<c;l++)this.childList[l].render(!1,t);this._fixOrder()}if(this.ul){var h=this.ul.style.display==="none",p=!!this.bExpanded;if(e&&s.fx&&h===p){var d=s.fx.duration||200;$(this.ul).animate(s.fx,d)}else this.ul.style.display=this.bExpanded||!r?"":"none"}},getKeyPath:function(e){var t=[];return this.visitParents(function(e){e.parent&&t.unshift(e.data.key)},!e),"/"+t.join(this.tree.options.keyPathSeparator)},getParent:function(){return this.parent},getChildren:function(){return this.hasChildren()===undefined?undefined:this.childList},hasChildren:function(){if(this.data.isLazy)return this.childList===null||this.childList===undefined?undefined:this.childList.length===0?!1:this.childList.length===1&&this.childList[0].isStatusNode()?undefined:!0;return!!this.childList},isFirstSibling:function(){var e=this.parent;return!e||e.childList[0]===this},isLastSibling:function(){var e=this.parent;return!e||e.childList[e.childList.length-1]===this},isLoading:function(){return!!this._isLoading},getPrevSibling:function(){if(!this.parent)return null;var e=this.parent.childList;for(var t=1,n=e.length;t<n;t++)if(e[t]===this)return e[t-1];return null},getNextSibling:function(){if(!this.parent)return null;var e=this.parent.childList;for(var t=0,n=e.length-1;t<n;t++)if(e[t]===this)return e[t+1];return null},isStatusNode:function(){return this.data.isStatusNode===!0},isChildOf:function(e){return this.parent&&this.parent===e},isDescendantOf:function(e){if(!e)return!1;var t=this.parent;while(t){if(t===e)return!0;t=t.parent}return!1},countChildren:function(){var e=this.childList;if(!e)return 0;var t=e.length;for(var n=0,r=t;n<r;n++){var i=e[n];t+=i.countChildren()}return t},sortChildren:function(e,t){var n=this.childList;if(!n)return;e=e||function(e,t){var n=e.data.title.toLowerCase(),r=t.data.title.toLowerCase();return n===r?0:n>r?1:-1},n.sort(e);if(t)for(var r=0,i=n.length;r<i;r++)n[r].childList&&n[r].sortChildren(e,"$norender$");t!=="$norender$"&&this.render()},_setStatusNode:function(e){var t=this.childList?this.childList[0]:null;if(!e){if(t&&t.isStatusNode()){try{this.ul&&(this.ul.removeChild(t.li),t.li=null)}catch(n){}this.childList.length===1?this.childList=[]:this.childList.shift()}}else t?(e.isStatusNode=!0,e.key="_statusNode",t.data=e,t.render()):(e.isStatusNode=!0,e.key="_statusNode",t=this.addChild(e))},setLazyNodeStatus:function(e,t){var n=t&&t.tooltip?t.tooltip:null,r=t&&t.info?" ("+t.info+")":"";switch(e){case DTNodeStatus_Ok:this._setStatusNode(null),$(this.span).removeClass(this.tree.options.classNames.nodeLoading),this._isLoading=!1,this.tree.options.autoFocus&&(this===this.tree.tnRoot&&this.childList&&this.childList.length>0?this.childList[0].focus():this.focus());break;case DTNodeStatus_Loading:this._isLoading=!0,$(this.span).addClass(this.tree.options.classNames.nodeLoading),this.parent||this._setStatusNode({title:this.tree.options.strings.loading+r,tooltip:n,addClass:this.tree.options.classNames.nodeWait});break;case DTNodeStatus_Error:this._isLoading=!1,this._setStatusNode({title:this.tree.options.strings.loadError+r,tooltip:n,addClass:this.tree.options.classNames.nodeError});break;default:throw"Bad LazyNodeStatus: '"+e+"'."}},_parentList:function(e,t){var n=[],r=t?this:this.parent;while(r)(e||r.parent)&&n.unshift(r),r=r.parent;return n},getLevel:function(){var e=0,t=this.parent;while(t)e++,t=t.parent;return e},_getTypeForOuterNodeEvent:function(e){var t=this.tree.options.classNames,n=e.target;if(n.className.indexOf(t.node)<0)return null;var r=e.pageX-n.offsetLeft,i=e.pageY-n.offsetTop;for(var s=0,o=n.childNodes.length;s<o;s++){var u=n.childNodes[s],a=u.offsetLeft-n.offsetLeft,f=u.offsetTop-n.offsetTop,l=u.clientWidth,c=u.clientHeight;if(r>=a&&r<=a+l&&i>=f&&i<=f+c){if(u.className==t.title)return"title";if(u.className==t.expander)return"expander";if(u.className==t.checkbox)return"checkbox";if(u.className==t.nodeIcon)return"icon"}}return"prefix"},getEventTargetType:function(e){var t=e&&e.target?e.target.className:"",n=this.tree.options.classNames;return t===n.title?"title":t===n.expander?"expander":t===n.checkbox?"checkbox":t===n.nodeIcon?"icon":t===n.empty||t===n.vline||t===n.connector?"prefix":t.indexOf(n.node)>=0?this._getTypeForOuterNodeEvent(e):null},isVisible:function(){var e=this._parentList(!0,!1);for(var t=0,n=e.length;t<n;t++)if(!e[t].bExpanded)return!1;return!0},makeVisible:function(){var e=this._parentList(!0,!1);for(var t=0,n=e.length;t<n;t++)e[t]._expand(!0)},focus:function(){this.makeVisible();try{$(this.span).find(">a").focus()}catch(e){}},isFocused:function(){return this.tree.tnFocused===this},_activate:function(e,t){this.tree.logDebug("dtnode._activate(%o, fireEvents=%o) - %o",e,t,this);var n=this.tree.options;if(this.data.isStatusNode)return;if(t&&n.onQueryActivate&&n.onQueryActivate.call(this.tree,e,this)===!1)return;if(e){if(this.tree.activeNode){if(this.tree.activeNode===this)return;this.tree.activeNode.deactivate()}n.activeVisible&&this.makeVisible(),this.tree.activeNode=this,n.persist&&$.cookie(n.cookieId+"-active",this.data.key,n.cookie),this.tree.persistence.activeKey=this.data.key,$(this.span).addClass(n.classNames.active),t&&n.onActivate&&n.onActivate.call(this.tree,this)}else if(this.tree.activeNode===this){if(n.onQueryActivate&&n.onQueryActivate.call(this.tree,!1,this)===!1)return;$(this.span).removeClass(n.classNames.active),n.persist&&$.cookie(n.cookieId+"-active","",n.cookie),this.tree.persistence.activeKey=null,this.tree.activeNode=null,t&&n.onDeactivate&&n.onDeactivate.call(this.tree,this)}},activate:function(){this._activate(!0,!0)},activateSilently:function(){this._activate(!0,!1)},deactivate:function(){this._activate(!1,!0)},isActive:function(){return this.tree.activeNode===this},_userActivate:function(){var e=!0,t=!1;if(this.data.isFolder)switch(this.tree.options.clickFolderMode){case 2:e=!1,t=!0;break;case 3:e=t=!0}this.parent===null&&(t=!1),t&&(this.toggleExpand(),this.focus()),e&&this.activate()},_setSubSel:function(e){e?(this.hasSubSel=!0,$(this.span).addClass(this.tree.options.classNames.partsel)):(this.hasSubSel=!1,$(this.span).removeClass(this.tree.options.classNames.partsel))},_updatePartSelectionState:function(){var e;if(!this.hasChildren())return e=this.bSelected&&!this.data.unselectable&&!this.data.isStatusNode,this._setSubSel(!1),e;var t,n,r=this.childList,i=!0,s=!0;for(t=0,n=r.length;t<n;t++){var o=r[t],u=o._updatePartSelectionState();u!==!1&&(s=!1),u!==!0&&(i=!1)}return i?e=!0:s?e=!1:e=undefined,this._setSubSel(e===undefined),this.bSelected=e===!0,e},_fixSelectionState:function(){var e,t,n;if(this.bSelected){this.visit(function(e){e.parent._setSubSel(!0),e.data.unselectable||e._select(!0,!1,!1)}),e=this.parent;while(e){e._setSubSel(!0);var r=!0;for(t=0,n=e.childList.length;t<n;t++){var i=e.childList[t];if(!i.bSelected&&!i.data.isStatusNode&&!i.data.unselectable){r=!1;break}}r&&e._select(!0,!1,!1),e=e.parent}}else{this._setSubSel(!1),this.visit(function(e){e._setSubSel(!1),e._select(!1,!1,!1)}),e=this.parent;while(e){e._select(!1,!1,!1);var s=!1;for(t=0,n=e.childList.length;t<n;t++)if(e.childList[t].bSelected||e.childList[t].hasSubSel){s=!0;break}e._setSubSel(s),e=e.parent}}},_select:function(e,t,n){var r=this.tree.options;if(this.data.isStatusNode)return;if(this.bSelected===e)return;if(t&&r.onQuerySelect&&r.onQuerySelect.call(this.tree,e,this)===!1)return;r.selectMode==1&&e&&this.tree.visit(function(e){if(e.bSelected)return e._select(!1,!1,!1),!1}),this.bSelected=e,e?(r.persist&&this.tree.persistence.addSelect(this.data.key),$(this.span).addClass(r.classNames.selected),n&&r.selectMode===3&&this._fixSelectionState(),t&&r.onSelect&&r.onSelect.call(this.tree,!0,this)):(r.persist&&this.tree.persistence.clearSelect(this.data.key),$(this.span).removeClass(r.classNames.selected),n&&r.selectMode===3&&this._fixSelectionState(),t&&r.onSelect&&r.onSelect.call(this.tree,!1,this))},select:function(e){return this.data.unselectable?this.bSelected:this._select(e!==!1,!0,!0)},toggleSelect:function(){return this.select(!this.bSelected)},isSelected:function(){return this.bSelected},isLazy:function(){return!!this.data.isLazy},_loadContent:function(){try{var e=this.tree.options;this.tree.logDebug("_loadContent: start - %o",this),this.setLazyNodeStatus(DTNodeStatus_Loading),!0===e.onLazyRead.call(this.tree,this)&&(this.setLazyNodeStatus(DTNodeStatus_Ok),this.tree.logDebug("_loadContent: succeeded - %o",this))}catch(t){this.tree.logWarning("_loadContent: failed - %o",t),this.setLazyNodeStatus(DTNodeStatus_Error,{tooltip:""+t})}},_expand:function(e,t){if(this.bExpanded===e){this.tree.logDebug("dtnode._expand(%o) IGNORED - %o",e,this);return}this.tree.logDebug("dtnode._expand(%o) - %o",e,this);var n=this.tree.options;if(!e&&this.getLevel()<n.minExpandLevel){this.tree.logDebug("dtnode._expand(%o) prevented collapse - %o",e,this);return}if(n.onQueryExpand&&n.onQueryExpand.call(this.tree,e,this)===!1)return;this.bExpanded=e,n.persist&&(e?this.tree.persistence.addExpand(this.data.key):this.tree.persistence.clearExpand(this.data.key));var r=(!this.data.isLazy||this.childList!==null)&&!this._isLoading&&!t;this.render(r);if(this.bExpanded&&this.parent&&n.autoCollapse){var i=this._parentList(!1,!0);for(var s=0,o=i.length;s<o;s++)i[s].collapseSiblings()}n.activeVisible&&this.tree.activeNode&&!this.tree.activeNode.isVisible()&&this.tree.activeNode.deactivate();if(e&&this.data.isLazy&&this.childList===null&&!this._isLoading){this._loadContent();return}n.onExpand&&n.onExpand.call(this.tree,e,this)},isExpanded:function(){return this.bExpanded},expand:function(e){e=e!==!1;if(!this.childList&&!this.data.isLazy&&e)return;if(this.parent===null&&!e)return;this._expand(e)},scheduleAction:function(e,t){this.tree.timer&&(clearTimeout(this.tree.timer),this.tree.logDebug("clearTimeout(%o)",this.tree.timer));var n=this;switch(e){case"cancel":break;case"expand":this.tree.timer=setTimeout(function(){n.tree.logDebug("setTimeout: trigger expand"),n.expand(!0)},t);break;case"activate":this.tree.timer=setTimeout(function(){n.tree.logDebug("setTimeout: trigger activate"),n.activate()},t);break;default:throw"Invalid mode "+e}this.tree.logDebug("setTimeout(%s, %s): %s",e,t,this.tree.timer)},toggleExpand:function(){this.expand(!this.bExpanded)},collapseSiblings:function(){if(this.parent===null)return;var e=this.parent.childList;for(var t=0,n=e.length;t<n;t++)e[t]!==this&&e[t].bExpanded&&e[t]._expand(!1)},_onClick:function(e){var t=this.getEventTargetType(e);if(t==="expander")this.toggleExpand();else if(t==="checkbox")this.toggleSelect();else{this._userActivate();var n=this.span.getElementsByTagName("a");if(!n[0])return!0;}e.preventDefault()},_onDblClick:function(e){},_onKeydown:function(e){var t=!0,n;switch(e.which){case 107:case 187:this.bExpanded||this.toggleExpand();break;case 109:case 189:this.bExpanded&&this.toggleExpand();break;case 32:this._userActivate();break;case 8:this.parent&&this.parent.focus();break;case 37:this.bExpanded?(this.toggleExpand(),this.focus()):this.parent&&this.parent.parent&&this.parent.focus();break;case 39:!this.bExpanded&&(this.childList||this.data.isLazy)?(this.toggleExpand(),this.focus()):this.childList&&this.childList[0].focus();break;case 38:n=this.getPrevSibling();while(n&&n.bExpanded&&n.childList)n=n.childList[n.childList.length-1];!n&&this.parent&&this.parent.parent&&(n=this.parent),n&&n.focus();break;case 40:if(this.bExpanded&&this.childList)n=this.childList[0];else{var r=this._parentList(!1,!0);for(var i=r.length-1;i>=0;i--){n=r[i].getNextSibling();if(n)break}}n&&n.focus();break;default:t=!1}t&&e.preventDefault()},_onKeypress:function(e){},_onFocus:function(e){var t=this.tree.options;if(e.type=="blur"||e.type=="focusout")t.onBlur&&t.onBlur.call(this.tree,this),this.tree.tnFocused&&$(this.tree.tnFocused.span).removeClass(t.classNames.focused),this.tree.tnFocused=null,t.persist&&$.cookie(t.cookieId+"-focus","",t.cookie);else if(e.type=="focus"||e.type=="focusin")this.tree.tnFocused&&this.tree.tnFocused!==this&&(this.tree.logDebug("dtnode.onFocus: out of sync: curFocus: %o",this.tree.tnFocused),$(this.tree.tnFocused.span).removeClass(t.classNames.focused)),this.tree.tnFocused=this,t.onFocus&&t.onFocus.call(this.tree,this),$(this.tree.tnFocused.span).addClass(t.classNames.focused),t.persist&&$.cookie(t.cookieId+"-focus",this.data.key,t.cookie)},visit:function(e,t){var n=!0;if(t===!0){n=e(this);if(n===!1||n=="skip")return n}if(this.childList)for(var r=0,i=this.childList.length;r<i;r++){n=this.childList[r].visit(e,!0);if(n===!1)break}return n},visitParents:function(e,t){if(t&&e(this)===!1)return!1;var n=this.parent;while(n){if(e(n)===!1)return!1;n=n.parent}return!0},remove:function(){if(this===this.tree.root)throw"Cannot remove system root";return this.parent.removeChild(this)},removeChild:function(e){var t=this.childList;if(t.length==1){if(e!==t[0])throw"removeChild: invalid child";return this.removeChildren()}e===this.tree.activeNode&&e.deactivate(),this.tree.options.persist&&(e.bSelected&&this.tree.persistence.clearSelect(e.data.key),e.bExpanded&&this.tree.persistence.clearExpand(e.data.key)),e.removeChildren(!0),this.ul&&this.ul.removeChild(e.li);for(var n=0,r=t.length;n<r;n++)if(t[n]===e){this.childList.splice(n,1);break}},removeChildren:function(e,t){this.tree.logDebug("%s.removeChildren(%o)",this,e);var n=this.tree,r=this.childList;if(r){for(var i=0,s=r.length;i<s;i++){var o=r[i];o===n.activeNode&&!t&&o.deactivate(),this.tree.options.persist&&!t&&(o.bSelected&&this.tree.persistence.clearSelect(o.data.key),o.bExpanded&&this.tree.persistence.clearExpand(o.data.key)),o.removeChildren(!0,t),this.ul&&$("li",$(this.ul)).remove()}this.childList=null}e||(this._isLoading=!1,this.render())},setTitle:function(e){this.fromDict({title:e})},reload:function(e){throw"Use reloadChildren() instead"},reloadChildren:function(e){if(this.parent===null)throw"Use tree.reload() instead";if(!this.data.isLazy)throw"node.reloadChildren() requires lazy nodes.";if(e){var t=this,n="nodeLoaded.dynatree."+this.tree.$tree.attr("id")+"."+this.data.key;this.tree.$tree.bind(n,function(r,i,s){t.tree.$tree.unbind(n),t.tree.logDebug("loaded %o, %o, %o",r,i,s);if(i!==t)throw"got invalid load event";e.call(t.tree,i,s)})}this.removeChildren(),this._loadContent()},_loadKeyPath:function(e,t){var n=this.tree;n.logDebug("%s._loadKeyPath(%s)",this,e);if(e==="")throw"Key path must not be empty";var r=e.split(n.options.keyPathSeparator);if(r[0]==="")throw"Key path must be relative (don't start with '/')";var i=r.shift();if(this.childList)for(var s=0,o=this.childList.length;s<o;s++){var u=this.childList[s];if(u.data.key===i){if(r.length===0)t.call(n,u,"ok");else if(!u.data.isLazy||u.childList!==null&&u.childList!==undefined)t.call(n,u,"loaded"),u._loadKeyPath(r.join(n.options.keyPathSeparator),t);else{n.logDebug("%s._loadKeyPath(%s) -> reloading %s...",this,e,u);var a=this;u.reloadChildren(function(i,s){s?(n.logDebug("%s._loadKeyPath(%s) -> reloaded %s.",i,e,i),t.call(n,u,"loaded"),i._loadKeyPath(r.join(n.options.keyPathSeparator),t)):(n.logWarning("%s._loadKeyPath(%s) -> reloadChildren() failed.",a,e),t.call(n,u,"error"))})}return}}t.call(n,undefined,"notfound",i,r.length===0),n.logWarning("Node not found: "+i);return},resetLazy:function(){if(this.parent===null)throw"Use tree.reload() instead";if(!this.data.isLazy)throw"node.resetLazy() requires lazy nodes.";this.expand(!1),this.removeChildren()},_addChildNode:function(e,t){var n=this.tree,r=n.options,i=n.persistence;e.parent=this,this.childList===null?this.childList=[]:t||this.childList.length>0&&$(this.childList[this.childList.length-1].span).removeClass(r.classNames.lastsib);if(t){var s=$.inArray(t,this.childList);if(s<0)throw"<beforeNode> must be a child of <this>";this.childList.splice(s,0,e)}else this.childList.push(e);var o=n.isInitializing();r.persist&&i.cookiesFound&&o?(i.activeKey===e.data.key&&(n.activeNode=e),i.focusedKey===e.data.key&&(n.focusNode=e),e.bExpanded=$.inArray(e.data.key,i.expandedKeyList)>=0,e.bSelected=$.inArray(e.data.key,i.selectedKeyList)>=0):(e.data.activate&&(n.activeNode=e,r.persist&&(i.activeKey=e.data.key)),e.data.focus&&(n.focusNode=e,r.persist&&(i.focusedKey=e.data.key)),e.bExpanded=e.data.expand===!0,e.bExpanded&&r.persist&&i.addExpand(e.data.key),e.bSelected=e.data.select===!0,e.bSelected&&r.persist&&i.addSelect(e.data.key)),r.minExpandLevel>=e.getLevel()&&(this.bExpanded=!0);if(e.bSelected&&r.selectMode==3){var u=this;while(u)u.hasSubSel||u._setSubSel(!0),u=u.parent}return n.bEnableUpdate&&this.render(),e},addChild:function(e,t){if(typeof e=="string")throw"Invalid data type for "+e;if(!e||e.length===0)return;if(e instanceof DynaTreeNode)return this._addChildNode(e,t);e.length||(e=[e]);var n=this.tree.enableUpdate(!1),r=null;for(var i=0,s=e.length;i<s;i++){var o=e[i],u=this._addChildNode(new DynaTreeNode(this,this.tree,o),t);r||(r=u),o.children&&u.addChild(o.children,null)}return this.tree.enableUpdate(n),r},append:function(e){return this.tree.logWarning("node.append() is deprecated (use node.addChild() instead)."),this.addChild(e,null)},appendAjax:function(e){var t=this;this.removeChildren(!1,!0),this.setLazyNodeStatus(DTNodeStatus_Loading);if(e.debugLazyDelay){var n=e.debugLazyDelay;e.debugLazyDelay=0,this.tree.logInfo("appendAjax: waiting for debugLazyDelay "+n),setTimeout(function(){t.appendAjax(e)},n);return}var r=e.success,i=e.error,s="nodeLoaded.dynatree."+this.tree.$tree.attr("id")+"."+this.data.key,o=$.extend({},this.tree.options.ajaxDefaults,e,{success:function(e,n,i){var u=t.tree.phase;t.tree.phase="init",o.postProcess?e=o.postProcess.call(this,e,this.dataType):e&&e.hasOwnProperty("d")&&(e=typeof e.d=="string"?$.parseJSON(e.d):e.d),(!$.isArray(e)||e.length!==0)&&t.addChild(e,null),t.tree.phase="postInit",r&&r.call(o,t,e,n),t.tree.logDebug("trigger "+s),t.tree.$tree.trigger(s,[t,!0]),t.tree.phase=u,t.setLazyNodeStatus(DTNodeStatus_Ok),$.isArray(e)&&e.length===0&&(t.childList=[],t.render())},error:function(e,n,r){t.tree.logWarning("appendAjax failed:",n,":\n",e,"\n",r),i&&i.call(o,t,e,n,r),t.tree.$tree.trigger(s,[t,!1]),t.setLazyNodeStatus(DTNodeStatus_Error,{info:n,tooltip:""+r})}});$.ajax(o)},move:function(e,t){var n;if(this===e)return;if(!this.parent)throw"Cannot move system root";if(t===undefined||t=="over")t="child";var r=this.parent,i=t==="child"?e:e.parent;if(i.isDescendantOf(this))throw"Cannot move a node to it's own descendant";if(this.parent.childList.length==1)this.parent.childList=this.parent.data.isLazy?[]:null,this.parent.bExpanded=!1;else{n=$.inArray(this,this.parent.childList);if(n<0)throw"Internal error";this.parent.childList.splice(n,1)}this.parent.ul&&this.parent.ul.removeChild(this.li),this.parent=i;if(i.hasChildren())switch(t){case"child":i.childList.push(this);break;case"before":n=$.inArray(e,i.childList);if(n<0)throw"Internal error";i.childList.splice(n,0,this);break;case"after":n=$.inArray(e,i.childList);if(n<0)throw"Internal error";i.childList.splice(n+1,0,this);break;default:throw"Invalid mode "+t}else i.childList=[this];i.ul||(i.ul=document.createElement("ul"),i.ul.style.display="none",i.li.appendChild(i.ul)),this.li&&i.ul.appendChild(this.li);if(this.tree!==e.tree)throw this.visit(function(t){t.tree=e.tree},null,!0),"Not yet implemented.";r.isDescendantOf(i)||r.render(),i.isDescendantOf(r)||i.render()},lastentry:undefined};var DynaTreeStatus=Class.create();DynaTreeStatus._getTreePersistData=function(e,t){var n=new DynaTreeStatus(e,t);return n.read(),n.toDict()},getDynaTreePersistData=DynaTreeStatus._getTreePersistData,DynaTreeStatus.prototype={initialize:function(e,t){e===undefined&&(e=$.ui.dynatree.prototype.options.cookieId),t=$.extend({},$.ui.dynatree.prototype.options.cookie,t),this.cookieId=e,this.cookieOpts=t,this.cookiesFound=undefined,this.activeKey=null,this.focusedKey=null,this.expandedKeyList=null,this.selectedKeyList=null},_log:function(e){Array.prototype.unshift.apply(arguments,["debug"]),_log.apply(this,arguments)},read:function(){this.cookiesFound=!1;var e=$.cookie(this.cookieId+"-active");this.activeKey=e===null?"":e,e!==null&&(this.cookiesFound=!0),e=$.cookie(this.cookieId+"-focus"),this.focusedKey=e===null?"":e,e!==null&&(this.cookiesFound=!0),e=$.cookie(this.cookieId+"-expand"),this.expandedKeyList=e===null?[]:e.split(","),e!==null&&(this.cookiesFound=!0),e=$.cookie(this.cookieId+"-select"),this.selectedKeyList=e===null?[]:e.split(","),e!==null&&(this.cookiesFound=!0)},write:function(){$.cookie(this.cookieId+"-active",this.activeKey===null?"":this.activeKey,this.cookieOpts),$.cookie(this.cookieId+"-focus",this.focusedKey===null?"":this.focusedKey,this.cookieOpts),$.cookie(this.cookieId+"-expand",this.expandedKeyList===null?"":this.expandedKeyList.join(","),this.cookieOpts),$.cookie(this.cookieId+"-select",this.selectedKeyList===null?"":this.selectedKeyList.join(","),this.cookieOpts)},addExpand:function(e){$.inArray(e,this.expandedKeyList)<0&&(this.expandedKeyList.push(e),$.cookie(this.cookieId+"-expand",this.expandedKeyList.join(","),this.cookieOpts))},clearExpand:function(e){var t=$.inArray(e,this.expandedKeyList);t>=0&&(this.expandedKeyList.splice(t,1),$.cookie(this.cookieId+"-expand",this.expandedKeyList.join(","),this.cookieOpts))},addSelect:function(e){$.inArray(e,this.selectedKeyList)<0&&(this.selectedKeyList.push(e),$.cookie(this.cookieId+"-select",this.selectedKeyList.join(","),this.cookieOpts))},clearSelect:function(e){var t=$.inArray(e,this.selectedKeyList);t>=0&&(this.selectedKeyList.splice(t,1),$.cookie(this.cookieId+"-select",this.selectedKeyList.join(","),this.cookieOpts))},isReloading:function(){return this.cookiesFound===!0},toDict:function(){return{cookiesFound:this.cookiesFound,activeKey:this.activeKey,focusedKey:this.activeKey,expandedKeyList:this.expandedKeyList,selectedKeyList:this.selectedKeyList}},lastentry:undefined};var DynaTree=Class.create();DynaTree.version="$Version:$",DynaTree.prototype={initialize:function(e){this.phase="init",this.$widget=e,this.options=e.options,this.$tree=e.element,this.timer=null,this.divTree=this.$tree.get(0),_initDragAndDrop(this)},_load:function(e){var t=this.$widget,n=this.options,r=this;this.bEnableUpdate=!0,this._nodeCount=1,this.activeNode=null,this.focusNode=null,n.rootVisible!==undefined&&this.logWarning("Option 'rootVisible' is no longer supported."),n.minExpandLevel<1&&(this.logWarning("Option 'minExpandLevel' must be >= 1."),n.minExpandLevel=1),n.classNames!==$.ui.dynatree.prototype.options.classNames&&(n.classNames=$.extend({},$.ui.dynatree.prototype.options.classNames,n.classNames)),n.ajaxDefaults!==$.ui.dynatree.prototype.options.ajaxDefaults&&(n.ajaxDefaults=$.extend({},$.ui.dynatree.prototype.options.ajaxDefaults,n.ajaxDefaults)),n.dnd!==$.ui.dynatree.prototype.options.dnd&&(n.dnd=$.extend({},$.ui.dynatree.prototype.options.dnd,n.dnd)),n.imagePath||$("script").each(function(){var e=/.*dynatree[^\/]*\.js$/i;if(this.src.search(e)>=0)return this.src.indexOf("/")>=0?n.imagePath=this.src.slice(0,this.src.lastIndexOf("/"))+"/skin/":n.imagePath="skin/",r.logDebug("Guessing imagePath from '%s': '%s'",this.src,n.imagePath),!1}),this.persistence=new DynaTreeStatus(n.cookieId,n.cookie),n.persist&&($.cookie||_log("warn","Please include jquery.cookie.js to use persistence."),this.persistence.read()),this.logDebug("DynaTree.persistence: %o",this.persistence.toDict()),this.cache={tagEmpty:"<span class='"+n.classNames.empty+"'></span>",tagVline:"<span class='"+n.classNames.vline+"'></span>",tagExpander:"<span class='"+n.classNames.expander+"'></span>",tagConnector:"<span class='"+n.classNames.connector+"'></span>",tagNodeIcon:"<span class='"+n.classNames.nodeIcon+"'></span>",tagCheckbox:"<span class='"+n.classNames.checkbox+"'></span>",lastentry:undefined},(n.children||n.initAjax&&n.initAjax.url||n.initId)&&$(this.divTree).empty();var i=this.$tree.find(">ul:first").hide();this.tnRoot=new DynaTreeNode(null,this,{}),this.tnRoot.bExpanded=!0,this.tnRoot.render(),this.divTree.appendChild(this.tnRoot.ul);var s=this.tnRoot,o=n.persist&&this.persistence.isReloading(),u=!1,a=this.enableUpdate(!1);this.logDebug("Dynatree._load(): read tree structure..."),n.children?s.addChild(n.children):n.initAjax&&n.initAjax.url?(u=!0,s.data.isLazy=!0,this._reloadAjax(e)):n.initId?this._createFromTag(s,$("#"+n.initId)):(this._createFromTag(s,i),i.remove()),this._checkConsistency(),!u&&n.selectMode==3&&s._updatePartSelectionState(),this.logDebug("Dynatree._load(): render nodes..."),this.enableUpdate(a),this.logDebug("Dynatree._load(): bind events..."),this.$widget.bind(),this.logDebug("Dynatree._load(): postInit..."),this.phase="postInit",n.persist&&this.persistence.write(),this.focusNode&&this.focusNode.isVisible()&&(this.logDebug("Focus on init: %o",this.focusNode),this.focusNode.focus()),u||(n.onPostInit&&n.onPostInit.call(this,o,!1),e&&e.call(this,"ok")),this.phase="idle"},_reloadAjax:function(e){var t=this.options;if(!t.initAjax||!t.initAjax.url)throw"tree.reload() requires 'initAjax' mode.";var n=this.persistence,r=$.extend({},t.initAjax);r.addActiveKey&&(r.data.activeKey=n.activeKey),r.addFocusedKey&&(r.data.focusedKey=n.focusedKey),r.addExpandedKeyList&&(r.data.expandedKeyList=n.expandedKeyList.join(",")),r.addSelectedKeyList&&(r.data.selectedKeyList=n.selectedKeyList.join(",")),r.success&&this.logWarning("initAjax: success callback is ignored; use onPostInit instead."),r.error&&this.logWarning("initAjax: error callback is ignored; use onPostInit instead.");var i=n.isReloading();r.success=function(n,r,s){t.selectMode==3&&n.tree.tnRoot._updatePartSelectionState(),t.onPostInit&&t.onPostInit.call(n.tree,i,!1),e&&e.call(n.tree,"ok")},r.error=function(n,r,s,o){t.onPostInit&&t.onPostInit.call(n.tree,i,!0,r,s,o),e&&e.call(n.tree,"error",r,s,o)},this.logDebug("Dynatree._init(): send Ajax request..."),this.tnRoot.appendAjax(r)},toString:function(){return"Dynatree '"+this.$tree.attr("id")+"'"},toDict:function(){return this.tnRoot.toDict(!0)},serializeArray:function(e){var t=this.getSelectedNodes(e),n=this.$tree.attr("name")||this.$tree.attr("id"),r=[];for(var i=0,s=t.length;i<s;i++)r.push({name:n,value:t[i].data.key});return r},getPersistData:function(){return this.persistence.toDict()},logDebug:function(e){this.options.debugLevel>=2&&(Array.prototype.unshift.apply(arguments,["debug"]),_log.apply(this,arguments))},logInfo:function(e){this.options.debugLevel>=1&&(Array.prototype.unshift.apply(arguments,["info"]),_log.apply(this,arguments))},logWarning:function(e){Array.prototype.unshift.apply(arguments,["warn"]),_log.apply(this,arguments)},isInitializing:function(){return this.phase=="init"||this.phase=="postInit"},isReloading:function(){return(this.phase=="init"||this.phase=="postInit")&&this.options.persist&&this.persistence.cookiesFound},isUserEvent:function(){return this.phase=="userEvent"},redraw:function(){this.tnRoot.render(!1,!1)},renderInvisibleNodes:function(){this.tnRoot.render(!1,!0)},reload:function(e){this._load(e)},getRoot:function(){return this.tnRoot},enable:function(){this.$widget.enable()},disable:function(){this.$widget.disable()},getNodeByKey:function(e){var t=document.getElementById(this.options.idPrefix+e);if(t)return t.dtnode?t.dtnode:null;var n=null;return this.visit(function(t){if(t.data.key===e)return n=t,!1},!0),n},getActiveNode:function(){return this.activeNode},reactivate:function(e){var t=this.activeNode;t&&(this.activeNode=null,t.activate(),e&&t.focus())},getSelectedNodes:function(e){var t=[];return this.tnRoot.visit(function(n){if(n.bSelected){t.push(n);if(e===!0)return"skip"}}),t},activateKey:function(e){var t=e===null?null:this.getNodeByKey(e);return t?(t.focus(),t.activate(),t):(this.activeNode&&this.activeNode.deactivate(),this.activeNode=null,null)},loadKeyPath:function(e,t){var n=e.split(this.options.keyPathSeparator);return n[0]===""&&n.shift(),n[0]==this.tnRoot.data.key&&(this.logDebug("Removed leading root key."),n.shift()),e=n.join(this.options.keyPathSeparator),this.tnRoot._loadKeyPath(e,t)},selectKey:function(e,t){var n=this.getNodeByKey(e);return n?(n.select(t),n):null},enableUpdate:function(e){return this.bEnableUpdate==e?e:(this.bEnableUpdate=e,e&&this.redraw(),!e)},count:function(){return this.tnRoot.countChildren()},visit:function(e,t){return this.tnRoot.visit(e,t)},_createFromTag:function(parentTreeNode,$ulParent){var self=this;$ulParent.find(">li").each(function(){var $li=$(this),$liSpan=$li.find(">span:first"),$liA=$li.find(">a:first"),title,href=null,target=null,tooltip;if($liSpan.length)title=$liSpan.html();else if($liA.length)title=$liA.html(),href=$liA.attr("href"),target=$liA.attr("target"),tooltip=$liA.attr("title");else{title=$li.html();var iPos=title.search(/<ul/i);iPos>=0?title=$.trim(title.substring(0,iPos)):title=$.trim(title)}var data={title:title,tooltip:tooltip,isFolder:$li.hasClass("folder"),isLazy:$li.hasClass("lazy"),expand:$li.hasClass("expanded"),select:$li.hasClass("selected"),activate:$li.hasClass("active"),focus:$li.hasClass("focused"),noLink:$li.hasClass("noLink")};href&&(data.href=href,data.target=target),$li.attr("title")&&(data.tooltip=$li.attr("title")),$li.attr("id")&&(data.key=""+$li.attr("id"));if($li.attr("data")){var dataAttr=$.trim($li.attr("data"));if(dataAttr){dataAttr.charAt(0)!="{"&&(dataAttr="{"+dataAttr+"}");try{$.extend(data,eval("("+dataAttr+")"))}catch(e){throw"Error parsing node data: "+e+"\ndata:\n'"+dataAttr+"'"}}}var childNode=parentTreeNode.addChild(data),$ul=$li.find(">ul:first");$ul.length&&self._createFromTag(childNode,$ul)})},_checkConsistency:function(){},_setDndStatus:function(e,t,n,r,i){var s=e?$(e.span):null,o=$(t.span);this.$dndMarker||(this.$dndMarker=$("<div id='dynatree-drop-marker'></div>").hide().css({"z-index":1e3}).prependTo($(this.divTree).parent()));if(r==="after"||r==="before"||r==="over"){var u="0 0";switch(r){case"before":this.$dndMarker.removeClass("dynatree-drop-after dynatree-drop-over"),this.$dndMarker.addClass("dynatree-drop-before"),u="0 -8";break;case"after":this.$dndMarker.removeClass("dynatree-drop-before dynatree-drop-over"),this.$dndMarker.addClass("dynatree-drop-after"),u="0 8";break;default:this.$dndMarker.removeClass("dynatree-drop-after dynatree-drop-before"),this.$dndMarker.addClass("dynatree-drop-over"),o.addClass("dynatree-drop-target"),u="8 0"}this.$dndMarker.show().position({my:"left top",at:"left top",of:o,offset:u})}else o.removeClass("dynatree-drop-target"),this.$dndMarker.hide();r==="after"?o.addClass("dynatree-drop-after"):o.removeClass("dynatree-drop-after"),r==="before"?o.addClass("dynatree-drop-before"):o.removeClass("dynatree-drop-before"),i===!0?(s&&s.addClass("dynatree-drop-accept"),o.addClass("dynatree-drop-accept"),n.addClass("dynatree-drop-accept")):(s&&s.removeClass("dynatree-drop-accept"),o.removeClass("dynatree-drop-accept"),n.removeClass("dynatree-drop-accept")),i===!1?(s&&s.addClass("dynatree-drop-reject"),o.addClass("dynatree-drop-reject"),n.addClass("dynatree-drop-reject")):(s&&s.removeClass("dynatree-drop-reject"),o.removeClass("dynatree-drop-reject"),n.removeClass("dynatree-drop-reject"))},_onDragEvent:function(e,t,n,r,i,s){var o=this.options,u=this.options.dnd,a=null,f=$(t.span),l,c;switch(e){case"helper":var h=$("<div class='dynatree-drag-helper'><span class='dynatree-drag-helper-img' /></div>").append($(r.target).closest(".dynatree-title").clone());$("ul.dynatree-container",t.tree.divTree).append(h),h.data("dtSourceNode",t),a=h;break;case"start":t.isStatusNode()?a=!1:u.onDragStart&&(a=u.onDragStart(t)),a===!1?(this.logDebug("tree.onDragStart() cancelled"),i.helper.trigger("mouseup"),i.helper.hide()):f.addClass("dynatree-drag-source");break;case"enter":a=u.onDragEnter?u.onDragEnter(t,n):null,a?a={over:a===!0||a==="over"||$.inArray("over",a)>=0,before:a===!0||a==="before"||$.inArray("before",a)>=0,after:a===!0||a==="after"||$.inArray("after",a)>=0}:a=!1,i.helper.data("enterResponse",a);break;case"over":c=i.helper.data("enterResponse"),l=null;if(c!==!1)if(typeof c=="string")l=c;else{var p=f.offset(),d={x:r.pageX-p.left,y:r.pageY-p.top},v={x:d.x/f.width(),y:d.y/f.height()};c.after&&v.y>.75?l="after":!c.over&&c.after&&v.y>.5?l="after":c.before&&v.y<=.25?l="before":!c.over&&c.before&&v.y<=.5?l="before":c.over&&(l="over"),u.preventVoidMoves&&(t===n?l=null:l==="before"&&n&&t===n.getNextSibling()?l=null:l==="after"&&n&&t===n.getPrevSibling()?l=null:l==="over"&&n&&n.parent===t&&n.isLastSibling()&&(l=null)),i.helper.data("hitMode",l)}l==="over"&&u.autoExpandMS&&t.hasChildren()!==!1&&!t.bExpanded&&t.scheduleAction("expand",u.autoExpandMS);if(l&&u.onDragOver){a=u.onDragOver(t,n,l);if(a==="over"||a==="before"||a==="after")l=a}this._setDndStatus(n,t,i.helper,l,a!==!1&&l!==null);break;case"drop":var m=i.helper.hasClass("dynatree-drop-reject");l=i.helper.data("hitMode"),l&&u.onDrop&&!m&&u.onDrop(t,n,l,i,s);break;case"leave":t.scheduleAction("cancel"),i.helper.data("enterResponse",null),i.helper.data("hitMode",null),this._setDndStatus(n,t,i.helper,"out",undefined),u.onDragLeave&&u.onDragLeave(t,n);break;case"stop":f.removeClass("dynatree-drag-source"),u.onDragStop&&u.onDragStop(t);break;default:throw"Unsupported drag event: "+e}return a},cancelDrag:function(){var e=$.ui.ddmanager.current;e&&e.cancel()},lastentry:undefined},$.widget("ui.dynatree",{_init:function(){if(versionCompare($.ui.version,"1.8")<0)return this.options.debugLevel>=0&&_log("warn","ui.dynatree._init() was called; you should upgrade to jquery.ui.core.js v1.8 or higher."),this._create();this.options.debugLevel>=2&&_log("debug","ui.dynatree._init() was called; no current default functionality.")},_create:function(){var e=this.options;e.debugLevel>=1&&logMsg("Dynatree._create(): version='%s', debugLevel=%o.",$.ui.dynatree.version,this.options.debugLevel),this.options.event+=".dynatree";var t=this.element.get(0);this.tree=new DynaTree(this),this.tree._load(),this.tree.logDebug("Dynatree._init(): done.")},bind:function(){function t(e){e=$.event.fix(e||window.event);var t=$.ui.dynatree.getNode(e.target);return t?t._onFocus(e):!1}this.unbind();var e="click.dynatree dblclick.dynatree";this.options.keyboard&&(e+=" keypress.dynatree keydown.dynatree"),this.element.bind(e,function(e){var t=$.ui.dynatree.getNode(e.target);if(!t)return!0;var n=t.tree,r=n.options;n.logDebug("event(%s): dtnode: %s",e.type,t);var i=n.phase;n.phase="userEvent";try{switch(e.type){case"click":return r.onClick&&r.onClick.call(n,t,e)===!1?!1:t._onClick(e);case"dblclick":return r.onDblClick&&r.onDblClick.call(n,t,e)===!1?!1:t._onDblClick(e);case"keydown":return r.onKeydown&&r.onKeydown.call(n,t,e)===!1?!1:t._onKeydown(e);case"keypress":return r.onKeypress&&r.onKeypress.call(n,t,e)===!1?!1:t._onKeypress(e)}}catch(s){var o=null;n.logWarning("bind(%o): dtnode: %o, error: %o",e,t,s)}finally{n.phase=i}});var n=this.tree.divTree;n.addEventListener?(n.addEventListener("focus",t,!0),n.addEventListener("blur",t,!0)):n.onfocusin=n.onfocusout=t},unbind:function(){this.element.unbind(".dynatree")},enable:function(){this.bind(),$.Widget.prototype.enable.apply(this,arguments)},disable:function(){this.unbind(),$.Widget.prototype.disable.apply(this,arguments)},getTree:function(){return this.tree},getRoot:function(){return this.tree.getRoot()},getActiveNode:function(){return this.tree.getActiveNode()},getSelectedNodes:function(){return this.tree.getSelectedNodes()},lastentry:undefined}),versionCompare($.ui.version,"1.8")<0&&($.ui.dynatree.getter="getTree getRoot getActiveNode getSelectedNodes"),$.ui.dynatree.version="$Version:$",$.ui.dynatree.getNode=function(e){if(e instanceof DynaTreeNode)return e;e.selector!==undefined&&(e=e[0]);while(e){if(e.dtnode)return e.dtnode;e=e.parentNode}return null},$.ui.dynatree.getPersistData=DynaTreeStatus._getTreePersistData,$.ui.dynatree.prototype.options={title:"Dynatree",minExpandLevel:1,imagePath:null,children:null,initId:null,initAjax:null,autoFocus:!0,keyboard:!0,persist:!1,autoCollapse:!1,clickFolderMode:3,activeVisible:!0,checkbox:!1,selectMode:2,fx:null,noLink:!1,onClick:null,onDblClick:null,onKeydown:null,onKeypress:null,onFocus:null,onBlur:null,onQueryActivate:null,onQuerySelect:null,onQueryExpand:null,onPostInit:null,onActivate:null,onDeactivate:null,onSelect:null,onExpand:null,onLazyRead:null,onCustomRender:null,onCreate:null,onRender:null,postProcess:null,dnd:{onDragStart:null,onDragStop:null,autoExpandMS:1e3,preventVoidMoves:!0,onDragEnter:null,onDragOver:null,onDrop:null,onDragLeave:null},ajaxDefaults:{cache:!1,timeout:0,dataType:"json"},strings:{loading:"Loading&#8230;",loadError:"Load error!"},generateIds:!1,idPrefix:"dynatree-id-",keyPathSeparator:"/",cookieId:"dynatree",cookie:{expires:null},classNames:{container:"dynatree-container",node:"dynatree-node",folder:"dynatree-folder",empty:"dynatree-empty",vline:"dynatree-vline",expander:"dynatree-expander",connector:"dynatree-connector",checkbox:"dynatree-checkbox",nodeIcon:"dynatree-icon",title:"dynatree-title",noConnector:"dynatree-no-connector",nodeError:"dynatree-statusnode-error",nodeWait:"dynatree-statusnode-wait",hidden:"dynatree-hidden",combinedExpanderPrefix:"dynatree-exp-",combinedIconPrefix:"dynatree-ico-",nodeLoading:"dynatree-loading",hasChildren:"dynatree-has-children",active:"dynatree-active",selected:"dynatree-selected",expanded:"dynatree-expanded",lazy:"dynatree-lazy",focused:"dynatree-focused",partsel:"dynatree-partsel",lastsib:"dynatree-lastsib"},debugLevel:2,lastentry:undefined},versionCompare($.ui.version,"1.8")<0&&($.ui.dynatree.defaults=$.ui.dynatree.prototype.options),$.ui.dynatree.nodedatadefaults={title:null,key:null,isFolder:!1,isLazy:!1,tooltip:null,href:null,icon:null,addClass:null,noLink:!1,activate:!1,focus:!1,expand:!1,select:!1,hideCheckbox:!1,unselectable:!1,children:null,lastentry:undefined};var didRegisterDnd=!1,_registerDnd=function(){if(didRegisterDnd)return;$.ui.plugin.add("draggable","connectToDynatree",{start:function(e,t){var n=$(this).data("ui-draggable")||$(this).data("draggable"),r=t.helper.data("dtSourceNode")||null;if(r)return n.offset.click.top=-2,n.offset.click.left=16,r.tree._onDragEvent("start",r,null,e,t,n)},drag:function(e,t){var n=$(this).data("ui-draggable")||$(this).data("draggable"),r=t.helper.data("dtSourceNode")||null,i=t.helper.data("dtTargetNode")||null,s=$.ui.dynatree.getNode(e.target);if(e.target&&!s){var o=$(e.target).closest("div.dynatree-drag-helper,#dynatree-drop-marker").length>0;if(o)return}t.helper.data("dtTargetNode",s),i&&i!==s&&i.tree._onDragEvent("leave",i,r,e,t,n),s&&(!s.tree.options.dnd.onDrop||(s===i?s.tree._onDragEvent("over",s,r,e,t,n):s.tree._onDragEvent("enter",s,r,e,t,n)))},stop:function(e,t){var n=$(this).data("ui-draggable")||$(this).data("draggable"),r=t.helper.data("dtSourceNode")||null,i=t.helper.data("dtTargetNode")||null,s=n._mouseDownEvent,o=e.type,u=o=="mouseup"&&e.which==1;logMsg("draggable-connectToDynatree.stop: targetNode(from event): %s, dtTargetNode: %s",i,t.helper.data("dtTargetNode")),u||logMsg("Drag was cancelled"),i&&(u&&i.tree._onDragEvent("drop",i,r,e,t,n),i.tree._onDragEvent("leave",i,r,e,t,n)),r&&r.tree._onDragEvent("stop",r,null,e,t,n)}}),didRegisterDnd=!0}})(jQuery);
	</script>

	<script type="text/javascript">
		'use strict';

		/* --- Snap2HTML Code --- */

		var dirs = [];	// contains all directories

		/*
			Data format:
				Each index in "dirs" array is an array representing a directory:
					First item in array: "directory path*always 0*directory modified date"
						Note that forward slashes are used instead of (Windows style) backslashes
					Then, for each each file in the directory: "filename*size of file*file modified date"
					Second to last item in array tells the total size of directory content
					Last item in array refrences IDs to all subdirectories of this dir (if any).
						ID is the item index in dirs array.
				Note: Modified date is in UNIX format
						
		*/

		// to save space I create aliases for dirs array and push() method on Array object
		var D = dirs;
		Array.prototype.p = Array.prototype.push;

D.p(["Z:/UofA/PhD/Literature*0*1700679379",".gitignore*273*1594498612","all_papers.md*156477*1700679446","all_papers_msc.md*89310*1544806396","books.txt*34499*1545179967","gitu.sh*181*1634759519","Literature.mm*4526601*1544037672","MSc.lnk*923*1520987846","ReadMe.md*99205*1700678883","References.lnk*764*1651081202","topic_cloud.jpg*293254*1700679148","upd_list.bat*26*1526072131",5201513,"1*2*3*4*5*12*13*14*16*27*34*35*49*50*108*109*110*111*112*113*114*115*116*121*123*124*127*130*131*133*134*135*136*141*182*183*184*185*186*189*190*191*198*199*200*201*202*203*206*207*218*219*226*227*228*259*303*315*316*317*323*324*328*338*345*346"])
D.p(["Z:/UofA/PhD/Literature/3d*0*1656263215","A Closed-Form Solution to Single Underwater Camera Calibration Using Triple Wavelength Dispersion and Its Application to Single Camera 3D Reconstruction  tip1709.pdf*4685718*1528932389","Mesh R-CNN 1906.02739 iccv19.pdf*4806512*1581167712","Sparse-to-Dense Depth Prediction from Sparse Depth Samples and a Single Image 1709.07492 icra18.pdf*2963839*1546912889",12456069,""])
D.p(["Z:/UofA/PhD/Literature/active_learning*0*1656263215","Active Learning Literature Survey.pdf*1946080*1565882138",1946080,""])
D.p(["Z:/UofA/PhD/Literature/alignment*0*1656263215","A Robust Method for Mosaicking Sequence Images Obtained from UAV icies10.pdf*721609*1477193202","Face Alignment Across Large Poses A 3D Solution CVPR2016.pdf*5386567*1465506596","Large-pose Face Alignment via CNN-based Dense 3D Model Fitting CVPR2016.pdf*2465018*1465506709","PoseNet A Convolutional Network for Real-Time 6-DOF Camera Relocalization iccv15.pdf*6553499*1453229763",15126693,""])
D.p(["Z:/UofA/PhD/Literature/annotation*0*1656263216","Automatic generation of ground truth for the evaluation of obstacle detection and tracking techniques  1807.05722.pdf*3642512*1540237566","ByLabel A Boundary Based Semi-Automatic Image Annotation Tool wacv18.pdf*9431316*1578328949","Deep Interactive Object Selection ax1603.pdf*4407789*1537202641","Efﬁciently scaling up crowdsourced video annotation ijcv13.pdf*11534593*1518832866","Human-Assisted Motion Annotation cvpr08.pdf*3490327*1521758402",32506537,""])
D.p(["Z:/UofA/PhD/Literature/autoencoder*0*1656263218",".gitignore*28*1558880998","Masked Autoencoders Are Scalable Vision Learners 2111.06377.pdf*7424207*1637121333",7424235,"6*7*8*9*10*11"])
D.p(["Z:/UofA/PhD/Literature/autoencoder/binary*0*1656263217","Learning deep compact descriptor with bagging auto-encoders for object retrieval icip15.pdf*1487375*1557794266","Learning to Hash with Binary Deep Neural Network ax1607.05140 eccv16.pdf*830986*1557807762","Optimal Binary Autoencoding with Pairwise Correlations iclr17.pdf*2556244*1540237568",4874605,""])
D.p(["Z:/UofA/PhD/Literature/autoencoder/denoising*0*1656263217","On denoising autoencoders trained to minimise binary cross-entropy ax1708.08487.pdf*904502*1557796895","Stacked Denoising Autoencoders 10.pdf*1392544*1557777856",2297046,""])
D.p(["Z:/UofA/PhD/Literature/autoencoder/misc*0*1656263217","Reducing the Dimensionality of Data with Neural Networks science0607.pdf*370654*1557891690","Transforming auto-encoders icann11.pdf*408690*1557933219",779344,""])
D.p(["Z:/UofA/PhD/Literature/autoencoder/notes*0*1656263217","beta-VAE Learning Basic Visual Concepts with a Constrained Variational Framework iclr17.pdf*3497*1558880693","Disentangling by Factorising ax1806.pdf*3727*1558880678",7224,""])
D.p(["Z:/UofA/PhD/Literature/autoencoder/sparse*0*1656263218","A Hierarchical Approach for Handwritten Digit Recognition Using Sparse Autoencoder sl_14.pdf*595106*1557891690","Embarrassingly Shallow Autoencoders for Sparse Data ax1905.03375.pdf*1428573*1557868988","Hashing with binary autoencoders ax1501.00756.pdf*903236*1557778482","Stacked sparse autoencoder and history of binary motion image for human activity recognition sp_mta19.pdf*2542262*1557870529","Training Autoencoders in Sparse Domain aaai17.pdf*524953*1557865579",5994130,""])
D.p(["Z:/UofA/PhD/Literature/autoencoder/variational*0*1656263219",".gitignore*139*1558881026","Auto-Encoding Variational Bayes ax1405.pdf*3926653*1557934258","beta-VAE Learning Basic Visual Concepts with a Constrained Variational Framework iclr17.pdf*34561477*1558811732","Complementary Set Variational Autoencoder for Supervised Anomaly Detection icassp18.pdf*742693*1557793955","Deep Convolutional Inverse Graphics Network ax1506 nis15.pdf*4206440*1558552890","Deep Unsupervised Clustering with Gaussian Mixture Variational Autoencoders rejected_iclr17.pdf*5372019*1551847335","Disentangling by Factorising ax1806.pdf*6437053*1558835363","Tutorial on Variational Autoencoders ax1606.05908.pdf*880536*1557778536","Understanding disentangling in beta-VAE nipsw17.pdf*4700584*1557965298","Unsupervised Lesion Detection via Image Restoration with a Normative Prior ax181123.pdf*949787*1551847325",61777381,""])
D.p(["Z:/UofA/PhD/Literature/bayesian*0*1656263220","A practical Bayesian framework for backpropagation networks. nc92.pdf*345543*1520730942","Bayesian Learning for Neural Networks thesis_book95.pdf*20097982*1520730962","Bayesian methods for adaptive models thesis_caltech92.pdf*1203083*1520201363","Keeping the neural net- works simple by minimizing the description length of the weights colt93.pdf*164438*1520717087","Variational Inference A Review for Statisticians ax1712.pdf*201375*1520717161","Variational Inference A Review for Statisticians ax1712_2.pdf*1827075*1540237585",23839496,""])
D.p(["Z:/UofA/PhD/Literature/bio_inspired*0*1656263220","A Bio-Inspired Robot with Visual Perception of Affordances eccv14.pdf*502578*1518832856","Human-level concept learning through probabilistic program induction.pdf*1826353*1485208980","Lessons from the Primate Visual System eccv12.pdf*137851*1518832857","Visual parsing after recovery from blindness ps09.pdf*632184*1521823684",3098966,""])
D.p(["Z:/UofA/PhD/Literature/class separability*0*1656263221","A note on the separability index  0812.1107.pdf*235179*1635569339","Data Separability for Neural Network Classifiers and the Development of a Separability Index 2005.13120.pdf*1448971*1635711321","Separability Index in Supervised Learning.pdf*218111*1635569345",1902261,"15"])
D.p(["Z:/UofA/PhD/Literature/class separability/KS Test*0*1656263221","Critical_KS.pdf*84913*1635734083","kstest.pdf*94050*1635734138","SBL701_KS_test_Tables.pdf*1145232*1635734145",1324195,""])
D.p(["Z:/UofA/PhD/Literature/classification*0*1656263226","Accurate and Eﬃcient Image Classiﬁcation by Exploiting Sparsity Homa_Candidacy.pdf*4344747*1467308012","Anytime recognition of objects and scenes cvpr14.pdf*1446000*1494860786","ImageNet classiﬁcation with deep convolutional neural networks acm17.pdf*1426026*1544371622","Imagenet classiﬁcation with deep convolutional neural networks nips12.pdf*1418820*1544210102","ImageNet Classification with Deep Convolutional Neural Networks nips12.pdf*1418820*1456248877","MACH Embarrassingly parallel K-class classification.pdf*308068*1576338228","Multi-Scale Dense Networks for Resource Efficient Image Classification ax1711.pdf*3182270*1518832870","Place Recognition with ConvNet Landmarks Viewpoint-Robust, Condition-Robust, Training-Free rss15.pdf*8022347*1540237654","Selective Search for Object Recognition IJCV2013.pdf*5942297*1540237654","Very Deep Convolutional Networks for Large-Scale Image Recognition iclr15 1409.1556.pdf*200010*1544213168","Visual object-action recognition Inferring object affordances from human demonstration cviu_11.pdf*1770850*1526068438",29480255,"17*18*19*20*21*22*24*25*26"])
D.p(["Z:/UofA/PhD/Literature/classification/activity*0*1656263223","Continuous Learning of Human Activity Models Using Deep Nets  eccv14.pdf*1383719*1518832870",1383719,""])
D.p(["Z:/UofA/PhD/Literature/classification/animal*0*1656263223","Learning to Recognize Animals by Watching Documentaries Using Subtitles as Weak Supervision 17.pdf*2106640*1526068187",2106640,""])
D.p(["Z:/UofA/PhD/Literature/classification/cell_classification*0*1656263225","10.1007_978-3-319-46976-8.pdf*48013517*1540237655","A deep convolutional neural network for classification of red blood cells in sickle cell anemia plos_cb_1710.pdf*16443230*1517601063","A Deep Residual Inception Network for HEp-2 Cell Classification SL_dlmia17.pdf*1023844*1540237656","Cells classification with deep learning  siu17.pdf*926582*1517601842","Cross-Modal Transfer Learning for HEp-2 Cell Classification Based on Deep Residual Network ism17.pdf*527838*1517601369","Deep convolutional neural network based HEp-2 cell classification  icpr1612.pdf*422886*1517601491","Deep Learning in Label-free Cell Classification nature_srep21471 1603.pdf*2528744*1540237656","Deep Learning of Cell Classification Using Microscope Images of Intracellular Microtubule Networks  icmla1712.pdf*799059*1517601445","DeepPap Deep Convolutional Networks for Cervical Cell Classification  jbhi1711.pdf*1275885*1517601920","DTFD-MIL Double-Tier Feature Distillation Multiple Instance Learning for Histopathology Whole Slide Image Classification cvpr22.pdf*10006813*1656011067","Evaluation of Morphological Features for Breast Cells Classification Using Neural Networks SL_taai.pdf*207886*1540237656","HEp-2 cell classification based on a Deep Autoencoding-Classification convolutional neural network  isbi17.pdf*956033*1517601537","HEp-2 cell classification using a deep neural network trained for natural image classification  siu16.pdf*255971*1517602038","HEp-2 Cell Classification Using K-Support Spatial Pooling in Deep CNNs SL_dlmia1609.pdf*1049629*1540237657","HEp-2 Cell Image Classification With Deep Convolutional Neural Networks  jbhi1703.pdf*1592389*1517601547","HEp-2 specimen classification via deep CNNs and pattern histogram  icpr1612.pdf*1310599*1517601544",87340905,""])
D.p(["Z:/UofA/PhD/Literature/classification/efficient*0*1656263225","Learning Efficient Convolutional Networks Through Network Slimming iccv17.pdf*556728*1558295769",556728,""])
D.p(["Z:/UofA/PhD/Literature/classification/evolution*0*1656263225","Large-Scale Evolution of Image Classifiers ax1706 icml17.pdf*3623310*1551970166","Regularized Evolution for Image Classifier Architecture Search ax190216 aaai19.pdf*719617*1551969103",4342927,""])
D.p(["Z:/UofA/PhD/Literature/classification/pipe_defect*0*1656263226","Automated defect classification in sewer closed circuit television inspections using deep convolutional neural networks AiC1807_SD.pdf*2193138*1552339051","Automated detection of sewer pipe defects in closed-circuit television images using deep learning techniques AiC1811_SD.pdf*5665880*1552339052","Autonomous Structural Visual Inspection Using Region-Based Deep Learning for Detecting Multiple Damage Types 171128 Computer-Aided_Civil_and_Infrastructure_Engineering.pdf*2040853*1552415118","CLASSIFICATION OF UNDERWATER PIPELINE EVENTS USING DEEP CONVOLUTIONAL NEURAL NETWORKS icassp17_poster.pdf*246200*1552338053","Deep learning-based damage detection for sewer pipe inspection using faster R-CNN 180414_Full_Paper_ICCCBE2018.pdf*1154869*1552338939","Development and Improvement of Deep Learning Based Automated Defect Detection for Sewer Pipe Inspection Using Faster R-CNN ACSE18_springer.pdf*4050001*1552338680","Sewer damage detection from imbalanced CCTV inspection data using deep convolutional neural networks with hierarchical classification AiC1905_SD.pdf*3157759*1552339063","Small Defect Detection Using Convolutional Neural Network Features and Random Forests eccvw18.pdf*1260740*1552340289","Visual Inspection of Storm-Water Pipe Systems using Deep Convolutional Neural Networks ICINCO_2018_67_CR.pdf*254649*1552346568",20024089,"23"])
D.p(["Z:/UofA/PhD/Literature/classification/pipe_defect/misc*0*1656263226","A review on computer vision based defect detection and condition assessment of concrete and asphalt civil infrastructure AEI15_SD.pdf*760799*1552339086","Vision-based Structural Inspection using Multiscale Deep Convolutional Neural Networks ax1805.01055.pdf*800981*1552338485",1561780,""])
D.p(["Z:/UofA/PhD/Literature/classification/svm*0*1656263226","A tutorial on support vector machines for pattern recognition.pdf*667404*1495340656","SVM.pdf*546203*1495339577","svm15.pdf*290302*1495340640",1503909,""])
D.p(["Z:/UofA/PhD/Literature/classification/thermal_imaging*0*1656263226","Deep Thermal Imaging Proximate Material Type Recognition in the Wild through Deep Learning of Spatial Surface Temperature Patterns ax1803.pdf*1506163*1525880186",1506163,""])
D.p(["Z:/UofA/PhD/Literature/classification/video*0*1656263228","Beyond Short Snippets Deep Networks for Video Classiﬁcation cvpr15.pdf*1045707*1540237657","Deep Learning from Temporal Coherence in Video icml09.pdf*333390*1525991804","Learning Spatiotemporal Features with 3D Convolutional Networks iccv15.pdf*7002419*1648607318","Long-term Recurrent Convolutional Networks for Visual Recognition and Description ax1411.4389 cvpr15.pdf*2808469*1550671251",11189985,""])
D.p(["Z:/UofA/PhD/Literature/compressed_sensing*0*1656263230","A deep learning approach to compressive sensing with convolutional autoencoders.pdf*2191075*1481144158","A Deep Learning Approach to Structured Signal Recovery ax1508.04065.pdf*528013*1557854750","Compressed sensing IT_April06.pdf*495460*1557845037","Deep Learning Sparse Ternary Projections for Compressed Sensing of Images 1708.08311 GlobalSIP17.pdf*399378*1557763401","Output Encoding by Compressed Sensing for Cell Detection with Deep Convnet aaai20.pdf*4198905*1652195347","Perceptual Compressive Sensing ax1802.00176 prcv18.pdf*2393265*1557763564",10206096,"28*29*30*31*32*33"])
D.p(["Z:/UofA/PhD/Literature/compressed_sensing/compressed_input*0*1656263228","Compressed Sensing using Generative Models ax1703.03208.pdf*2565839*1557763217","ConvCSNet A Convolutional Compressive Sensing Framework Based on Deep Learning ax1801.10342.pdf*1459954*1557760475","ISTA-Net Interpretable Optimization-Inspired Deep Network for Image Compressive Sensing_cvpr18.pdf*846658*1557761082","LAPRAN A Scalable Laplacian Pyramid Reconstructive Adversarial Network for Flexible Compressive Sensing Reconstruction ax1807.09388 eccv18.pdf*2770065*1557759398","Learning to invert Signal recovery via Deep Convolutional Networks ax1701.03891.pdf*368977*1557759178","Multi-Scale Deep Compressive Sensing Network ax1809.05717 vcip.pdf*571810*1557754837","ReconNet Non-Iterative Reconstruction of Images from Compressively Sensed Measurements_CVPR_2016.pdf*6642839*1557757490",15226142,""])
D.p(["Z:/UofA/PhD/Literature/compressed_sensing/MRI*0*1656263229","DAGAN Deep De-Aliasing Generative Adversarial Networks for Fast Compressed Sensing MRI Reconstruction tmi18.pdf*11185682*1557762918","Deep residual learning for compressed sensing MRI isbi17.pdf*3074079*1557763897","Learning a Variational Network for Reconstruction of Accelerated MRI Data ax1704.00447.pdf*7058946*1557764424",21318707,""])
D.p(["Z:/UofA/PhD/Literature/compressed_sensing/review*0*1656263230","A Review of Sparse Recovery Algorithms 1812.pdf*9305990*1557710555","A survey of sparse representation algorithms and applications ax16.pdf*882561*1540237666","A Systematic Review of Compressive Sensing Concepts, Implementations and Applications access18.pdf*12766873*1557845126","Algorithms for First-order Sparse Reinforcement Learning phd16.pdf*2711655*1540237667","An Overview on Algorithms for Sparse Recovery.pdf*961222*1557710561","Boss_1.ppt*4472320*1516253418","Compressive Sensing Performance Comparison Of Sparse Recovery Algorithms ax1801.09744.pdf*2051701*1557710540","Greedy Algorithms for Sparse Reinforcement Learning icml2012.pdf*568503*1516253684","Learning Fast Approximations of Sparse Coding icml10.pdf*226490*1520967798","Learning Sparse Representations in Reinforcement Learning with Sparse Coding ax1707.pdf*613113*1540237667","Learning Sparse Representations in Reinforcement Learning with Sparse Coding ijcai17.pdf*534335*1540237667","Sparse Multi-Task Reinforcement Learning.pdf*405900*1516253701","Sparse Recovery Using Sparse Matrices.pdf*215263*1557754649","Tutorial Sparse Recovery Using Sparse Matrices.pdf*1743743*1557710571",37459669,""])
D.p(["Z:/UofA/PhD/Literature/compressed_sensing/sparse_coding*0*1557880620",0,""])
D.p(["Z:/UofA/PhD/Literature/compressed_sensing/sparse_input*0*1656263230","BCS Compressive Sensing for Binary Sparse Signals.pdf*175501*1557778600",175501,""])
D.p(["Z:/UofA/PhD/Literature/compressed_sensing/video*0*1656263230","CSVideoNet A Real-time End-to-end Learning Framework for High-frame-rate Video Compressive Sensing ax1612.05203 wacv18.pdf*1698104*1557807997","Deep Fully-Connected Networks for Video Compressive Sensing ax1603.04930v2 els_dsp18.pdf*12514637*1557763059",14212741,""])
D.p(["Z:/UofA/PhD/Literature/curve_revovery*0*1656263231","A Robust Rigid Skeleton Extraction Method from Noisy Visual Hull Model ijars15.pdf*2568283*1547584928","Analytic Curve Detection from a Noisy Binary Edge Map using Genetic Algorithm.pdf*379720*1547584771",2948003,""])
D.p(["Z:/UofA/PhD/Literature/datasets*0*1698254383","1 year, 1000 km The Oxford RobotCar dataset  ijrr16_11.pdf*29326905*1498409255","80 Million Tiny Images A Large Data Set for Nonparametric Object and Scene Recognition pami08.pdf*1472404*1452790093","A benchmark for comparison of cell tracking algorithms bioinformatics14.pdf*321177*1469642573","A Public Video Dataset for Road Transportation Applications (2013) .pdf*1864501*1497013798","Beyond Standard Benchmarks Parameterizing Performance Evaluation in Visual Object Tracking_iccv17.pdf*2035352*1538067334","Cats and Dogs cvpr12.pdf*7796937*1521941446","Data Engineering for Everyone 2102.11447.pdf*962081*1615035096","Microsoft COCO Common Objects in Context ax1502 eccv14.pdf*8007319*1560560758","Objectnet A large-scale bias-controlled dataset for pushing the limits of object recognition models nips19.pdf*17100003*1576166095","Semantic Understanding of Scenes through ADE20K Dataset ax1608.05442 cvpr17 ijcv19.pdf*8009943*1564544728","Semantic Understanding of Scenes through the ADE20K Dataset ax1608.05442.pdf*8009943*1564521320","Sim4CV A Photo-Realistic Simulator for Computer Vision Applications ijcv18.pdf*4177193*1564148410","The Unmanned Aerial Vehicle Benchmark Object Detection and Tracking_eccv18.pdf*5946776*1538354880","Training a Convolutional Neural Network for Multi-Class Object Detection Using Solely Virtual World Data icavss16_8.pdf*1673632*1497013634","Vehicle Tracking by Simultaneous Detection and Viewpoint Estimation iwinac13.pdf*3430264*1518832867",100134430,"36*37*38*39*42*45*46*47*48"])
D.p(["Z:/UofA/PhD/Literature/datasets/agro*0*1698254465","Perception Datasets for Anomaly Detection in Autonomous Driving A Survey 2302.02790.pdf*5909377*1698253637",5909377,""])
D.p(["Z:/UofA/PhD/Literature/datasets/animal*0*1656263235","The iNaturalist Species Classification and Detection Dataset ax1804.pdf*8356534*1548260556","The INaturalist Species Classification and Detection Dataset_cvpr18.pdf*3251557*1557682141","The INaturalist Species Classification and Detection Dataset_cvpr18-supp.pdf*173648*1557682140",11781739,""])
D.p(["Z:/UofA/PhD/Literature/datasets/detection*0*1656263235","DOTA A Large-Scale Dataset for Object Detection in Aerial Images_cvpr18.pdf*1269248*1557595881","Performance Evaluation of Object Detection and Tracking in Video TR2006-041.pdf*134460*1518832867","Performance Evaluation of Object Detection and Tracking in Video.pdf*434068*1518832867","Performance measures for object detection evaluation prl10_7.pdf*2128582*1518832867","The PASCAL Visual Object Classes (VOC) Challenge ijcv_voc09.pdf*8104906*1560573085",12071264,""])
D.p(["Z:/UofA/PhD/Literature/datasets/multi_object_tracking*0*1656263237","CityFlow A City-Scale Benchmark for Multi-Target Multi-Camera Vehicle Tracking and Re-Identification 1903.09254 cvpr19.pdf*6798614*1578846026","Fully Automatic, Real-Time Vehicle Tracking for Surveillance Video crv17.pdf*2778089*1499368999","MOT16 A Benchmark for Multi-Object Tracking ax16_5.pdf*1670119*1518832866","MOTChallenge 2015 Towards a Benchmark for Multi-Target Tracking ax15_8.pdf*3209673*1610780817","PathTrack Fast Trajectory Annotation with Path Supervision iccv17 supplementary.pdf*555261*1577731478","PathTrack Fast Trajectory Annotation with Path Supervision iccv17.pdf*1446424*1577731477","TAO A Large-Scale Benchmark for Tracking Any Object 2005.10356 eccv20.pdf*5169537*1610780817","The Unmanned Aerial Vehicle Benchmark Object Detection and Tracking ax1804.00518 eccv18.pdf*4738992*1587415099","Tracking and Detection Challenge How crowded can it get 1906.04567 cvpr19.pdf*4252165*1574194009","Training a Convolutional Neural Network for Multi-Class Object Detection Using Solely Virtual World Data avss16.pdf*1673632*1594501261","Virtual Worlds as Proxy for Multi-Object Tracking Analysis 1605.06457 cvpr16.pdf*5617009*1594497362","WILDTRACK A Multi-camera HD Dataset for Dense Unscripted Pedestrian Detection_cvpr18.pdf*1256536*1537337989",39166051,"40*41"])
D.p(["Z:/UofA/PhD/Literature/datasets/multi_object_tracking/cell tracking*0*1656263237","A benchmark for comparison of cell tracking algorithms bio_informatics14.pdf*353261*1612203074","An objective comparison of cell-tracking algorithms nature methods 17.pdf*2029185*1612147841","Cell Tracking with Mitosis Detection Dataset Challenge_CVPRW20.pdf*813624*1617135693",3196070,""])
D.p(["Z:/UofA/PhD/Literature/datasets/multi_object_tracking/uav*0*1656263237","Vision Meets Drones Past, Present and Future 2001.06303v2.pdf*4384749*1623090364",4384749,""])
D.p(["Z:/UofA/PhD/Literature/datasets/perception*0*1698778602","Argoverse 2 Next Generation Datasets for Self-Driving Perception and Forecasting nips23.pdf*7667031*1698778679","Argoverse 3D Tracking and Forecasting with Rich Maps cvpr19.pdf*8219499*1698701249","Lyft One Thousand and One Hours Self-driving Motion Prediction Dataset houston21a.pdf*3858586*1698267534","nuScenes A multimodal dataset for autonomous driving cvpr20.pdf*4639282*1698182266","OpenOccupancy A Large Scale Benchmark for Surrounding Semantic Occupancy Perception iccv23.pdf*4922923*1698686885","Scalability in Perception for Autonomous Driving Waymo Open Dataset CVPR20.pdf*1953599*1698779779","TractorEYE Vision-based Real-time Detection for Autonomous Vehicles in Agriculture phd thesis 2017.pdf*8427071*1698266015",39687991,"43*44"])
D.p(["Z:/UofA/PhD/Literature/datasets/perception/planning*0*1698778524","Large scale interactive motion forecasting for autonomous driving  The waymo open motion dataset iccv21.pdf*2324483*1698778254","SHIFTS 2.0 EXTENDING THE DATASET OF REAL DISTRIBUTIONAL SHIFTS.pdf*510924*1698702463",2835407,""])
D.p(["Z:/UofA/PhD/Literature/datasets/perception/rgbd*0*1698691282","SceneNN a Scene Meshes Dataset with aNNotations_3dv16.pdf*3891408*1698683626",3891408,""])
D.p(["Z:/UofA/PhD/Literature/datasets/segmentation*0*1656263238","A Benchmark Dataset and Evaluation Methodology for Video Object Segmentation cvpr16.pdf*2152156*1585357264","The SYNTHIA Dataset A Large Collection of Synthetic Images for Semantic Segmentation of Urban Scenes cvpr16.pdf*8735986*1565473659",10888142,""])
D.p(["Z:/UofA/PhD/Literature/datasets/single_object_tracking*0*1656263239","CDTB A Color and Depth Visual Object Tracking Dataset and Benchmark iccv19.pdf*1789874*1587408581","LaSOT A High-quality Benchmark for Large-scale Single Object Tracking ax1809.07845.pdf*6037359*1538068410","LaSOT A High-quality Benchmark for Large-scale Single Object Tracking ax190327 cvpr19.pdf*8203046*1564093486","Long-term Tracking in the Wild A Benchmark ax180810_eccv18.pdf*1107891*1534166090","Need for Speed A Benchmark for Higher Frame Rate Object Tracking_iccv17.pdf*4329320*1538140552","TrackingNet A Large-Scale Dataset and Benchmark for Object Tracking in the Wild ax1803.10794 eccv18.pdf*4641748*1564092333","TrackingNet A Large-Scale Dataset and Benchmark for Object Tracking in the Wild_eccv18.pdf*1807595*1538354768","UAV123 A Benchmark and Simulator for UAV Tracking eccv16 supp.pdf*2804914*1564148041","UAV123 A Benchmark and Simulator for UAV Tracking eccv16.pdf*8750857*1564148400",39472604,""])
D.p(["Z:/UofA/PhD/Literature/datasets/video_captioning*0*1696294475","ActivityNet A Large-Scale Video Benchmark for Human Activity Understanding cvpr15.pdf*5193608*1596309642","Neural Script Knowledge through Vision and Language and Sound cvpr22.pdf*2009296*1691964251","Towards automatic learning of procedures from web instructional videos aaai18 1703.09788.pdf*2212392*1696294420","Visual genome Connecting language 1602.07332 ijcv17.pdf*8105806*1596315017",17521102,""])
D.p(["Z:/UofA/PhD/Literature/datasets/video_detection*0*1656263240","YouTube-BoundingBoxes A Large High-Precision Human-Annotated Data Set for Object Detection in Video ax170324.pdf*7551779*1540237648",7551779,""])
D.p(["Z:/UofA/PhD/Literature/deblurring*0*1656263241","Blind Image Deblurring Using Dark Channel Prior  cvpr16.pdf*1569361*1535610434","DeblurGAN Blind Motion Deblurring Using Conditional Adversarial Networks ax1804_cvpr18.pdf*5945963*1535610245","DeblurGAN Blind Motion Deblurring Using Conditional Adversarial Networks cvpr18.pdf*2593552*1535610048","Deblurring Images via Dark Channel Prior  tpami1709.pdf*8518481*1535610397","Image Deblurring via Extreme Channels Prior cvpr17.pdf*915760*1535609986",19543117,""])
D.p(["Z:/UofA/PhD/Literature/deep_learning*0*1698499424",".gitignore*59*1601744535","Adaptable Hamiltonian neural networks 2102.13235.pdf*3291507*1615035149","Differentiable Patch Selection for Image Recognition 2104.03059 cvpr21.pdf*10496431*1618670349","DiffusionNet Accelerating the solution of Time-Dependent partial differential equations using deep learning 2011.10015v1.pdf*4818124*1606574546","Federated Quantum Machine Learning 2103.12010.pdf*1436173*1617457831","Fourier Features Let Networks Learn High Frequency Functions in Low Dimensional Domains nips20 2006.10739.pdf*9744803*1698498983","Group Equivariant Convolutional Networks 1602.07576 icml16.pdf*204081*1647877893","Neural message passing for quantum chemistry 1704.01212.pdf*523413*1648586534","Non-local Neural Networks 1711.07971 cvpr18.pdf*2853537*1618951048","Siamese Neural Networks for One-shot Image Recognition.pdf*766340*1651879768",34134468,"51*52*53*54*55*56*57*58*59*60*61*62*63*64*65*66*67*68*69*70*71*72*73*74*75*76*77*78*79*80*81*82*83*84*85*86*87*88*92*93*98*99*106*107"])
D.p(["Z:/UofA/PhD/Literature/deep_learning/adversarial*0*1656263241","The Elephant in the Room 1808.03305.pdf*4589656*1589303137",4589656,""])
D.p(["Z:/UofA/PhD/Literature/deep_learning/atrous*0*1656263242","Fast Image Scanning with Deep Max-Pooling Convolutional Neural Networks icip13 ax1302.1700.pdf*947426*1545668421","Multi-Scale Context Aggregation by Dilated Convolutions iclr16 ax1511.07122.pdf*3000738*1545668466",3948164,""])
D.p(["Z:/UofA/PhD/Literature/deep_learning/augmentation*0*1656263243","Simple Copy-Paste is a Strong Data Augmentation Method for Instance Segmentation 2012.07177.pdf*1836728*1636770312",1836728,""])
D.p(["Z:/UofA/PhD/Literature/deep_learning/batch_normalization*0*1656263243","Batch Normalization Accelerating Deep Network Training by Reducing Internal Covariate Shift ax1503.pdf*189391*1546051611",189391,""])
D.p(["Z:/UofA/PhD/Literature/deep_learning/biological*0*1656263243","Towards an integration of deep learning and neuroscience ax1606.03813.pdf*1089238*1541998148","Towards Biologically Plausible Deep Learning ax1502.04156.pdf*689451*1541970822",1778689,""])
D.p(["Z:/UofA/PhD/Literature/deep_learning/class_imbalance*0*1656263245","A Review on Ensembles for the Class Imbalance Problem Bagging-, Boosting-, and Hybrid-Based Approaches TSMC1108.pdf*1523145*1597520031","A Survey of Predictive Modelling under Imbalanced Distributions 1505.01658.pdf*1021477*1578923336","A survey on addressing high-class imbalance in big data jbd_sl1811.pdf*1166551*1597519806","Class Imbalance Problem in Data Mining Review 1305.1707.pdf*130503*1597519841","Classification with class imbalance problem A review jsoco1511.pdf*765655*1597519924","Learning from imbalanced data open challenges and future directions pAI_sl1604.pdf*320128*1597519591","Learning from Imbalanced Data tkde0906.pdf*1566415*1597421912","On the combined effect of class imbalance and concept complexity in deep learning 2107.14194.pdf*1582580*1627920545","Survey on deep learning with class imbalance jbd_sl1903.pdf*1987912*1597552937","Training Deep Neural Networks on  Imbalanced Data Sets IJCNN15l.pdf*192398*1578923453",10256764,""])
D.p(["Z:/UofA/PhD/Literature/deep_learning/compression*0*1656263246","A Gift from Knowledge Distillation Fast Optimization, Network Minimization and Transfer Learning CVPR17.pdf*564739*1554235003","Compression of Deep Neural Networks by combining pruning and low rank decomposition nips18.pdf*326649*1554235836","Domain-adaptive deep network compression ax1709.01041.pdf*551056*1554235046","Domain-Adaptive Deep Network Compression iccv17.pdf*1522795*1562103410","FitNets Hints for Thin Deep Nets ax1505.pdf*266757*1554234949","Learning Efficient Convolutional Networks through Network Slimming ax1708.06519 iccv17.pdf*941739*1554235444","Paying More Attention to Attention Improving the Performance of Convolutional Neural Networks via Attention Transfer ax1702.pdf*1233383*1554235481","Pelee A Real-Time Object Detection System on Mobile Devices ax190118.pdf*364772*1554234858","Pruning Convolutional Neural Networks for Resource Efficient Inference ax1707.pdf*2058685*1554235386","Pruning Filters for Efficient ConvNets ax1608.08710.pdf*4425745*1554235229","ThiNet A Filter Level Pruning Method for Deep Neural Network Compression ICCV17.pdf*1141222*1554235323",13397542,""])
D.p(["Z:/UofA/PhD/Literature/deep_learning/curriculum*0*1656263246","A Survey on Curriculum Learning 2010.13166 tpami21.pdf*4186125*1654701232",4186125,""])
D.p(["Z:/UofA/PhD/Literature/deep_learning/deformable*0*1656263246","Deformable Convolutional Networks 1703.06211 iccv17.pdf*6845294*1603920731",6845294,""])
D.p(["Z:/UofA/PhD/Literature/deep_learning/densenet*0*1656263246","CondenseNet An Efficient DenseNet using Learned Group Convolutions ax1806.pdf*875221*1567975330","Densely Connected Convolutional Networks ax1801 cvpr17.pdf*942387*1538888634",1817608,""])
D.p(["Z:/UofA/PhD/Literature/deep_learning/distillation*0*1659585149","Mean teachers are better role models Weight-averaged consistency targets improve semi-supervised deep learning results 1703.01780.pdf*863822*1659545753",863822,""])
D.p(["Z:/UofA/PhD/Literature/deep_learning/domain_adaptation*0*1656263246","Deep visual domain adaptation A survey neurocomputing1810_sd.pdf*4112515*1562102832","DINE Domain Adaptation from Single and Multiple Black-box Predictors cvpr22.pdf*1429632*1655929353","Invariant Risk Minimization 1907.02893.pdf*945276*1655922618","Unsupervised Domain Adaptation by Backpropagation icml15.pdf*3378554*1589299885",9865977,""])
D.p(["Z:/UofA/PhD/Literature/deep_learning/dropout*0*1656263246","Dropout A Simple Way to Prevent Neural Networks from Overﬁtting jmlr14.pdf*2887464*1518832864","Dropout as a Bayesian Approximation Appendix ax1605.pdf*459664*1540237645","Dropout as a Bayesian Approximation Representing Model Uncertainty in Deep Learning ax1610.pdf*1098118*1540237645","Improving neural networks by preventing co-adaptation of feature detectors ax1207.pdf*1668895*1540237645","Uncertainty in Deep Learning (PhD Thesis) cambridge1705.pdf*9271160*1540237645",15385301,""])
D.p(["Z:/UofA/PhD/Literature/deep_learning/efficient*0*1656263247","Abandoning the Dark Arts Scientific Approaches to Efficient Deep. Learning nipsw19.pdf*26002462*1588694744","An Energy and GPU-Computation Efficient Backbone Network for Real-Time Object Detection AX1904.09730 CVPRW19.pdf*1511627*1577043167","Be Your Own Teacher Improve the Performance of Convolutional Neural Networks via Self Distillation ax1905.08094 iccv19.pdf*1586406*1588694868","EfficientNet_Rethinking model scaling for CNNs.pdf*1170007*1601747683","MobileNets Efficient Convolutional Neural Networks for Mobile Vision Applications ax1704.04861.pdf*941241*1568148161","MobileNetV2 inax Inverted Residuals and Linear Bottlenecks 1801.04381.pdf*1539146*1568148860","Searching for MobileNetV3 ax1905.02244.pdf*538322*1568148904",33289211,""])
D.p(["Z:/UofA/PhD/Literature/deep_learning/ensemble*0*1656263247","Distilling the Knowledge in a Neural Network ax1503.02531.pdf*106630*1550671676",106630,""])
D.p(["Z:/UofA/PhD/Literature/deep_learning/fourier*0*1656263248","Fast Fourier Transformation for Optimizing Convolutional Neural Networks in Object Recognition 2010.04257v1.pdf*833839*1603551464","Fourier Neural Operator for Parametric Partial Differential Equations 2010.08895v1.pdf*2509681*1603551489",3343520,""])
D.p(["Z:/UofA/PhD/Literature/deep_learning/fully_convolutional*0*1656263248","Striving for Simplicity The All Convolutional Net ax1504 iclrw15.pdf*4164494*1546997147",4164494,""])
D.p(["Z:/UofA/PhD/Literature/deep_learning/graph*0*1656263248","Convolutional Neural Networks on Graphs with Fast Localized Spectral Filtering nips18.pdf*468496*1551329675","Hierarchical graph neural nets can capture long-range interactions 2107.07432v1.pdf*4564830*1627144317","Relational inductive biases, deep learning, and graph networks ax1810.pdf*9421943*1551219620","Semi-Supervised Classification with Graph Convolutional Networks 1609.02907 iclr17.pdf*764647*1611947754",15219916,""])
D.p(["Z:/UofA/PhD/Literature/deep_learning/hardware*0*1656263248","11 TeraFLOPs per second photonic convolutional accelerator for deep learning optical neural networks 2011.07393.pdf*2087635*1605968389","ZeRO-Infinity Breaking the GPU Memory Wall for Extreme Scale Deep Learning 2104.07857 Microsoft.pdf*1322978*1619264270",3410613,""])
D.p(["Z:/UofA/PhD/Literature/deep_learning/hybrid_hand_crafted*0*1656263249","Combining ConvNets with Hand-Crafted Features for Action Recognition Based on an HMM-SVM Classifier ax1602.00749.pdf*200870*1552873435","Combining Deep and Handcrafted Image Features for Presentation Attack Detection in Face Recognition Systems Using Visible-Light Camera Sensors. sensors-18-00699-v2.pdf*4473975*1552873423","Combining deep learning and hand-crafted features for skin lesion classification ipta06.pdf*999995*1552872945","Evaluating the Utility of Hand-crafted Features in Sequence Labelling ax1808.pdf*361850*1552873413","Object Classification using Ensemble of Local and Deep Features ax1712.04926.pdf*842301*1552873082","Skin Lesion Classification Via Combining Deep Learning Features and Clinical Criteria Representations bax1808.pdf*1175982*1552872972","The Impact of Replacing Complex Hand-Crafted Features with Standard Features for Melanoma Classification Using Both Hand-Crafted and Deep Features intellisys18_spr.pdf*620134*1552873357",8675107,""])
D.p(["Z:/UofA/PhD/Literature/deep_learning/hyper_parameters*0*1656263249","A disciplined approach to neural network hyper-parameters Part 1 -- learning rate, batch size, momentum, and weight decay ax1803.09820.pdf*3509947*1566654794","Algorithms for Hyper-Parameter Optimization nips11.pdf*605790*1520875211",4115737,""])
D.p(["Z:/UofA/PhD/Literature/deep_learning/inception*0*1656263250","Convolution in Convolution for Network in Network tnnls1805.pdf*2553424*1526046444","Deformable Convolutional Networks ax1706 iccv17.pdf*6956769*1526674833","Going Deeper with Convolutions ax1409 cvpr15.pdf*1216229*1540237645","Inception-v4, Inception-ResNet and the Impact of Residual Connections on Learning ax1608 aaai17.pdf*870354*1546921152","Network In Network ax1403.pdf*598203*1540237646","Rethinking the Inception Architecture for Computer Vision ax1512 cvpr16.pdf*520164*1540237646","Xception Deep Learning with Depthwise Separable Convolutions ax170404.pdf*804466*1536681863",13519609,""])
D.p(["Z:/UofA/PhD/Literature/deep_learning/large_models*0*1656263251","Designing Network Design Spaces 2003.13678 cvpr20 facebook.pdf*1459822*1619836750","GPipe Efﬁcient Training of Giant Neural Networks using Pipeline Parallelism 181212.pdf*660405*1551924938","Lingvo a Modular and Scalable Framework for Sequence-to-Sequence Modeling ax190221.pdf*491897*1551925132",2612124,""])
D.p(["Z:/UofA/PhD/Literature/deep_learning/libraries*0*1691179156","DoubleML -- An Object-Oriented Implementation of Double Machine Learning in Python 2104.03220.pdf*321651*1618066585","Einops Clear and Reliable Tensor Manipulations with Einstein-like Notation iclr22.pdf*237577*1691178706","Kornia an Open Source Differentiable Computer Vision Library for PyTorch 1910.02190.pdf*5457534*1616279863","Technical Report on the CleverHans v2.1.0 Adversarial Examples Library 1610.00768.pdf*170158*1571671354",6186920,""])
D.p(["Z:/UofA/PhD/Literature/deep_learning/mixed_precision*0*1656263251","Mixed Precision Training ax1802 iclr18.pdf*1404641*1562516191",1404641,""])
D.p(["Z:/UofA/PhD/Literature/deep_learning/nas*0*1656263251","Can weight sharing outperform random architecture search An investigation with TuNAS cvpr20.pdf*743268*1631204802","DARTS Differentiable Architecture Search ax180624.pdf*638432*1540237646","Efﬁcient Neural Architecture Search via Parameter Sharing ax1802.03268.pdf*437408*1527104596","Efficient Neural Architecture Search with Network Morphism ax1806.pdf*429891*1540237646","Learning Transferable Architectures for Scalable Image Recognition ax1804.pdf*8127002*1540237646","MnasNet Platform-Aware Neural Architecture Search for Mobile ax180731.pdf*636236*1536372455","Neural Architect A Multi-objective Neural Architecture Search with Performance Prediction.pdf*497360*1540237646","Neural Architecture Search A Survey.pdf*275714*1536694384","Neural Architecture Search with Reinforcement Learning ax170215.pdf*735601*1540237646","Progressive Neural Architecture Search ax1807 eccv18.pdf*1202372*1540237646","Simple And Efficient Architecture Search for Convolutional Neural Networks ax1711.pdf*1298332*1540237646",15021616,""])
D.p(["Z:/UofA/PhD/Literature/deep_learning/notes*0*1656263251","Decoupled Neural Interfaces using Synthetic Gradients ax1608.05343.pdf*8289*1546016243","Do Deep Nets Really Need to be Deep ax1410 nips14.pdf*7216*1546016382","EfficientNet_ Rethinking Model Scaling for Convolutional Neural Networks.pdf*74562*1601747683","Understanding Synthetic Gradients and Decoupled Neural Interfaces ax1703.00522.pdf*8199*1546016353",98266,""])
D.p(["Z:/UofA/PhD/Literature/deep_learning/old*0*1656263251","Learning representations by back-propagating errors nature86.pdf*574094*1453831455",574094,""])
D.p(["Z:/UofA/PhD/Literature/deep_learning/optimization*0*1699748860","Adam A Method for Stochastic Optimization ax17_1.pdf*584641*1498520660","Adaptive subgradient methods for online learning and stochastic optimization jmlr11.pdf*307882*1498605287","An overview of gradient descent optimization algorithms ax1609.04747.pdf*659026*1547094561","Backpropagation through time what it does and how to do it ieee90.pdf*1143344*1455210772","Categorical Reparameterization with Gumbel-Softmax 1611.01144.pdf*1403159*1574903493","Cockpit A Practical Debugging Tool for Training Deep Neural Networks 2102.06604.pdf*2003189*1613833306","Deep Convolutional Neural Networks with Unitary Weights 2102.11855.pdf*880674*1615035392","Deep learning via Hessian-free optimization.pdf*109241*1459871692","Delving Deep into Rectifiers Surpassing Human-Level Performance on ImageNet Classification ax1502.01852.pdf*2290070*1573057159","Don't Decay the Learning Rate, Increase the Batch Size iclr18.pdf*604169*1541188732","Gradients without Backpropagation 2202.08587.pdf*4389532*1699748804","On the Variance of the Adaptive Learning Rate and Beyond ax1908.03265.pdf*1504984*1569855027","You Only Train Once Loss-Conditional Training of Deep Networks iclr20.pdf*9202449*1591740925",25082360,""])
D.p(["Z:/UofA/PhD/Literature/deep_learning/ordinal regression*0*1656263252","Ordinal Regression with Multiple Output CNN for Age Estimation cvpr16.pdf*1068781*1568353569",1068781,""])
D.p(["Z:/UofA/PhD/Literature/deep_learning/perception*0*1691863218","Delving into the Devils of Bird's-eye-view Perception A Review, Evaluation and Recipe 2209.05324.pdf*2218216*1692222549","Geometric-aware Pretraining for Vision-centric 3D Object Detection 2304.03105.pdf*4101405*1691863204","OccFormer Dual-path Transformer for Vision-based 3D Semantic Occupancy Prediction iccv23 2304.05316.pdf*13716645*1691862314","Tri-Perspective View for Vision-Based 3D Semantic Occupancy Prediction cvpr23 2302.07817.pdf*32752917*1691862202",52789183,""])
D.p(["Z:/UofA/PhD/Literature/deep_learning/regnet*0*1656263252","Designing Network Design Spaces 2003.13678v1.pdf*1459822*1636395620",1459822,""])
D.p(["Z:/UofA/PhD/Literature/deep_learning/relation_net*0*1656263252","A simple neural network module for relational reasoning 1706.01427.pdf*1438944*1574210364",1438944,""])
D.p(["Z:/UofA/PhD/Literature/deep_learning/resnet*0*1656263253","Aggregated Residual Transformations for Deep Neural Networks ax170411 cvpr17.pdf*1334606*1536341154","Deep Residual Learning for Image Recognition ax1512.pdf*819383*1516912535","Identity Mappings in Deep Residual Networks ax1607_eccv16.pdf*1166414*1535925101","Wider or Deeper Revisiting the ResNet Model for Visual Recognition ax1611.pdf*5734511*1539750986",9054914,""])
D.p(["Z:/UofA/PhD/Literature/deep_learning/review*0*1698091180","A Survey of Inductive Biases for Factorial Representation-Learning ax1612.05299.pdf*7307006*1557840114","Deep Learning for Computer Vision A Brief Review cin_hindawi18.pdf*2593812*1525993327","Deep Learning for Computer Vision A Brief Review cin1802 hindawi.pdf*2593812*1579917315","Deep Learning in Neural Networks An Overview.pdf*1169624*1540237644","Deep learning nature1505.pdf*2083627*1494604584","Learning deep architectures for AI tr09.pdf*665021*1557769024","On the opportunities and risks of foundation models ax2108..pdf*13130255*1698091131",29543157,""])
D.p(["Z:/UofA/PhD/Literature/deep_learning/stereo_matching*0*1656263253","Efficient Deep Learning for Stereo Matching cvpr16.pdf*10424856*1498581661","MatchNet Unifying feature and metric learning for patch-based matching cvpr15.pdf*751777*1498581744","Stereo Matching by Training a Convolutional Neural Network to Compare Image Patches ax16_5.pdf*3397935*1518832865",14574568,""])
D.p(["Z:/UofA/PhD/Literature/deep_learning/synthetic_gradients*0*1656263254","Decoupled Neural Interfaces using Synthetic Gradients ax1608.05343.pdf*5685763*1541969146","Decoupled Parallel Backpropagation with Convergence Guarantee ax1804.10574.pdf*1109667*1542400115","Deep supervised learning using local errors ax1711.06756.pdf*597504*1542400115","Estimating or Propagating Gradients Through Stochastic Neurons for Conditional Computation ax1308.3432.pdf*403557*1554235581","Understanding Straight-Through Estimator in Training Activation Quantized Neural Nets iclr19_review.pdf*1148035*1554235710","Understanding Synthetic Gradients and Decoupled Neural Interfaces ax1703.00522.pdf*1927436*1542122940",10871962,""])
D.p(["Z:/UofA/PhD/Literature/deep_learning/theory*0*1698498419","Building Machines That Learn and Think Like People ax1611.pdf*3751940*1557931053","Counterfactual Explanations for Machine Learning A Review 2010.10596v1.pdf*713989*1603551435","Deep Learning and the Information Bottleneck Principle ax1503.02406 ite15.pdf*370205*1561510052","Do Deep Nets Really Need to be Deep ax1410 nips14.pdf*271689*1546017916","Do Wide and Deep Networks Learn the Same Things Uncovering How Neural Network Representations Vary with Width and Depth 2010.15327v1.pdf*23200298*1604185876","How Neural Networks Extrapolate From Feedforward to Graph Neural Networks 2009.11848.pdf*5298535*1651682137","Interpretable Machine Learning – A Brief History, State-of-the-Art and Challenges 2010.09337v1.pdf*492866*1603551385","Neural Tangent Kernel Convergence and generalization in neural networks nips18.pdf*419058*1698498273","On the Expressive Power of Deep Neural Networks ax1706.pdf*1736710*1548884410","On the Number of Linear Regions of Deep Neural Networks ax1406 nips14.pdf*4846825*1540237643","Opening the black box of Deep Neural Networks via Information ax1703.00810.pdf*3921623*1561509970","Provable Beneﬁts of Overparameterization in Model Compression From Double Descent to Pruning Neural Networks 2012.08749.pdf*893776*1652286898","Provable Bounds for Learning Some Deep Representations icml14.pdf*344333*1540237644","Sensitivity and Generalization in Neural Networks An Empirical Study iclr18.pdf*8520763*1548813249","Shapley Explanation Networks 2104.02297 iclr21.pdf*9619766*1618670003","Underspecification Presents Challenges for Credibility in Modern Machine Learning 2011.03395.pdf*4906403*1606868972","Understanding Deep Neural Networks with Rectified Linear Units ax1707.pdf*1152958*1540237643","Visualizing and understanding convolutional neural networks ECCV2014.pdf*2282352*1544329670",72744089,"89*90*91"])
D.p(["Z:/UofA/PhD/Literature/deep_learning/theory/#old*0*1698498419","Saliency maps and attention selection in scale and spatial coordinates an information theoretic approach iccv95.pdf*552648*1560548075","Understanding the difﬁculty of training deep feedforward neural networks icas10.pdf*1647622*1520362245",2200270,""])
D.p(["Z:/UofA/PhD/Literature/deep_learning/theory/adversarial*0*1698498380","Adversarial examples in the physical world ax1702.pdf*6437171*1571668249","Boosting Adversarial Attacks with Momentum} ax1710.06081 cvpr18.pdf*1789356*1571675665","DeepFool a simple and accurate method to fool deep neural networks 1511.04599.pdf*4918509*1571674234","Defense against Adversarial Attacks Using High-Level Representation Guided Denoiser ax1803.pdf*1256577*1571675479","Distillation as a Defense to Adversarial Perturbations against Deep Neural Networks ax1511.04508.pdf*3204836*1571671764","Ensemble Adversarial Training Attacks and Defenses ax1807.pdf*1133428*1571675306","Explaining and Harnessing Adversarial Examples ax1503.pdf*1036360*1571671896","Intriguing properties of neural networks ax1312.6199.pdf*6565323*1550669965","Practical Black-Box Attacks against Machine Learning ax1703.pdf*6829953*1571670970","Towards Evaluating the Robustness of Neural Networks ax1703.pdf*1257598*1571674312",34429111,""])
D.p(["Z:/UofA/PhD/Literature/deep_learning/theory/explainable*0*1698498356","Evaluating Explainable Artificial Intelligence Methods for Multi-label Deep Learning Classification Tasks in Remote Sensing 2104.01375.pdf*3565777*1618669910","Explainable AI current status and future directions 2107.07045v1.pdf*4254012*1627143752","Explainable AI Interpreting, Explaining and Visualizing Deep Learning lncs19_sl.pdf*61134684*1573852521","Grad-CAM Visual Explanations from Deep Networks via Gradient-based Localization ijcv19.pdf*7262053*1578433075",76216526,""])
D.p(["Z:/UofA/PhD/Literature/deep_learning/transfer*0*1656263259","Big Transfer (BiT) General Visual Representation Learning ax2005.pdf*3422323*1591883769","Bringing Impressionism to Life with Neural Style Transfer in Come Swim arxiv17.pdf*5603928*1484934457","Domain Adaptive Neural Networks for Object Recognition ax1409.6041.pdf*2837538*1554235109","How transferable are features in deep neural networks nips14.pdf*496016*1518832895","Transfer Learning handbook09.pdf*180577*1565638460","Unsupervised Image-to-Image Translation Networks ax180215.pdf*5367639*1540237684",17908021,""])
D.p(["Z:/UofA/PhD/Literature/deep_learning/transformer*0*1700249302","An Image is Worth 16x16 Words Transformers for Image Recognition at Scale 2010.11929.pdf*3557626*1691285113","Attention is All you Need nips17.pdf*576757*1691285113","Axial Attention in Multidimensional Transformers 1912.12180.pdf*1648508*1697911434","Emerging Properties in Self-Supervised Vision Transformers 2104.14294 facebook.pdf*30927117*1619835658","Exploring Self-attention for Image Recognition 2004.13621 cvpr20.pdf*243035*1598728379","On the relationship between self- attention and convolutional layers 1911.03584 iclr20.pdf*1460818*1691182319","Pervasive Attention 2D Convolutional Neural Networks for Sequence-to-Sequence Prediction 1808.03867 conll18.pdf*1882046*1594416196","Quantifying Attention Flow in Transformers 2005.00928.pdf*3973255*1658336060","Scaling Vision Transformers to Gigapixel Images via Hierarchical Self-Supervised Learning 2206.02647.pdf*21565961*1655652086","Semi-Supervised Learning of Visual Features by Non-Parametrically Predicting View Assignments with Support Samples 2104.13963 facebook.pdf*635757*1619834083","Swin Transformer Hierarchical Vision Transformer using Shifted Windows 2103.14030.pdf*1239729*1691261896","Transformer visualization via dictionary learning contextualized embedding as a linear superposition of transformer factors 2103.15949.pdf*2821852*1617458049",70532461,"94*95*96*97"])
D.p(["Z:/UofA/PhD/Literature/deep_learning/transformer/#tutorials*0*1700268963","a-PyTorch-Tutorial-to-Image-Captioning.html*71968*1700249430","a-PyTorch-Tutorial-to-Image-Captioning.md*34310*1591156056","a-PyTorch-Tutorial-to-Machine-Translation.html*163378*1700249334","a-PyTorch-Tutorial-to-Machine-Translation.md*101339*1699719573","Relative Positional Encoding - Jake Tae (11_17_2023 11_57_34 AM).html*707101*1700247454",1078096,""])
D.p(["Z:/UofA/PhD/Literature/deep_learning/transformer/graph*0*1696523847","Relational Attention Generalizing Transformers for Graph-Structured Tasks iclr23.pdf*663982*1696522842",663982,""])
D.p(["Z:/UofA/PhD/Literature/deep_learning/transformer/review*0*1699506119","An Introduction to Transformers 2304.10557.pdf*731406*1699497368","Transformers in Vision A Survey 2101.01169.pdf*7655745*1679689553",8387151,""])
D.p(["Z:/UofA/PhD/Literature/deep_learning/transformer/video*0*1698514610","TimeSformer Is Space-Time Attention All You Need for Video Understanding icml21.pdf*8708681*1698359244","Video Swin Transformer cvpr22.pdf*1523363*1698699177","Vivit A video vision transformer iccv21.pdf*4608852*1698682455",14840896,""])
D.p(["Z:/UofA/PhD/Literature/deep_learning/unsorted*0*1656263259","Adaptive deconvolutional networks for mid and high level feature learning iccv11.pdf*4299716*1544329670","Convolutional neural networks on graphs with fast localized spectral filtering nips16.pdf*496290*1518832864","Deep Learning A Critical Appraisal ax1801.00631.pdf*264408*1545427524","Deep Networks with Stochastic Depth arxiv16.pdf*989025*1483422266","End-To-End Memory Networks nips15.pdf*657504*1540237644","Evaluating the Robustness of Neural Networks An Extreme Value Theory Approach ax180131 iclr18.pdf*1208772*1540237643","Geometric deep learning going beyond Euclidean data ax1705.pdf*5517877*1518832865","Learning Explanatory Rules from Noisy Data ax1711.04574.pdf*928306*1545428220","Neural GPUs Learn Algorithms iclr16.pdf*140029*1540237644","Neural Machine Translation by Jointly Learning to Align and Translate iclr15.pdf*449756*1540237644","Sequence to Sequence Learning with Neural Networks nips14.pdf*112084*1456419739","Squeeze-and-Excitation Networks ax1804 cvpr18.pdf*1411924*1536683774","SqueezeNext Hardware-Aware Neural Network Design ax180827.pdf*947384*1536536886","Weight Uncertainty in Neural Networks ax1505 icml15.pdf*628773*1520716938",18051848,""])
D.p(["Z:/UofA/PhD/Literature/deep_learning/unsupervised*0*1656263262",".gitignore*29*1546018754","Classifier Crafting Turn Your ConvNet into a Zero-Shot Learner! 2103.11112.pdf*13961887*1617458076","Emerging Properties in Self-Supervised Vision Transformers 2104.14294.pdf*30740507*1646950059","Self-supervised Pretraining of Visual Features in the Wild 2103.01988 facebook.pdf*461796*1646411825","Unsupervised Learning of Visual Features by Contrasting Cluster Assignments 2006.09882 nips20.pdf*702914*1647007527",45867133,"100*101*102*103*104*105"])
D.p(["Z:/UofA/PhD/Literature/deep_learning/unsupervised/motion_prediction*0*1656263260","Unsupervised Learning of Long-Term Motion Dynamics for Videos ax1704.pdf*7763986*1546018677",7763986,""])
D.p(["Z:/UofA/PhD/Literature/deep_learning/unsupervised/notes*0*1656263260","Learning Features by Watching Objects Move ax170412 cvpr17.pdf*7931*1546016548",7931,""])
D.p(["Z:/UofA/PhD/Literature/deep_learning/unsupervised/pixel_prediction*0*1656263260","Context Encoders Feature Learning by Inpainting ax1604.07379.pdf*9820362*1546089344",9820362,""])
D.p(["Z:/UofA/PhD/Literature/deep_learning/unsupervised/review*0*1656263261","Representation Learning A Review and New Perspectives ax1404 tpami13.pdf*1540338*1546018721",1540338,""])
D.p(["Z:/UofA/PhD/Literature/deep_learning/unsupervised/segmentation*0*1656263261","Learning Features by Watching Objects Move ax170412 cvpr17.pdf*9384513*1540237664",9384513,""])
D.p(["Z:/UofA/PhD/Literature/deep_learning/unsupervised/time_series*0*1656263262","Deep Temporal Clustering  Fully Unsupervised Learning of Time-Domain Features ax1802.01059.pdf*2841066*1540237685","Unsupervised Feature Learning from Time Series ijcai.pdf*691092*1528330076",3532158,""])
D.p(["Z:/UofA/PhD/Literature/deep_learning/vgg*0*1656263262","Very Deep Convolutional Networks for Large-Scale Image Recognition ax1409.1556.pdf*200010*1585353564",200010,""])
D.p(["Z:/UofA/PhD/Literature/deep_learning/weak_supervision*0*1656263263","Self-Training with Weak Supervision 2104.05514.pdf*1621708*1618670074",1621708,""])
D.p(["Z:/UofA/PhD/Literature/deep_reinforcement_learning*0*1656263264","A Deep Reinforcement Learning Library for Fast Prototyping and Benchmarking 2011.07537v1.pdf*3401839*1606574642","Active Object Localization With Deep Reinforcement Learning iccv15.pdf*2259343*1453229553","Asynchronous Methods for Deep Reinforcement Learning ax16_6.pdf*2302720*1498575648","Benchmarking Deep Reinforcement Learning for Continuous Control icml16.pdf*1228584*1485847237","Continuous Adaptation via Meta-Learning in Nonstationary and Competitive Environments ax180223 iclr18.pdf*2357094*1540237604","Continuous control with deep reinforcement learning iclr16 ax1602.pdf*626230*1520117470","Continuous Deep Q-Learning with Model-based Acceleration ax1603.pdf*1708226*1517439972","Deep Reinforcement Learning An Overview ax17_1.pdf*428068*1518832877","DEEP REINFORCEMENT LEARNING AN OVERVIEW ax1709.pdf*1117257*1518832877","Deep Reinforcement Learning that Matters ax1711.pdf*9471156*1517442315","Deep Reinforcement Learning with Double Q-learning corr15 ax15_12.pdf*789062*1499650788","Deterministic Policy Gradient Algorithms icml14.pdf*411675*1540237605","Dueling Network Architectures for Deep Reinforcement Learning ax16_5.pdf*688509*1499650837","End-to-End Training of Deep Visuomotor Policies arxiv16_4.pdf*6263022*1518832872","Human-level control through deep reinforcement learning nature1502.pdf*4400586*1517450062","Imagination-Augmented Agents for Deep Reinforcement Learning ax180214.pdf*1210028*1540237606","Kickstarting Deep Reinforcement Learning  ax1803.03835.pdf*1652104*1541963401","Mastering the game of Go with deep neural networks and tree search nature16_1.pdf*2690748*1518832877","Neural Network Dynamics for Model-Based Deep Reinforcement Learning with Model-Free Fine-Tuning ax1712.pdf*2527582*1518832878","Playing Atari with Deep Reinforcement Learning nips13 ax13_9.pdf*485528*1518832878","Proximal Policy Optimization Algorithms ax1708.pdf*2923532*1517442357","Rainbow Combining Improvements in Deep Reinforcement Learning ax1710.pdf*1536440*1517442367","Reinforcement and Deep Reinforcement Machine Learning sl rhml17.pdf*934404*1518832878","Stable reinforcement learning with recurrent neural networks SL jcta11.pdf*383523*1494438631","Temporal Difference Models Model-Free Deep RL for Model-Based Control iclr18_ur.pdf*1667564*1518832879","Three DeepRL Seminars - asingh1@ualberta.ca - University of Alberta Mail.mht*1193604*1517450432","Training Larger Networks for Deep Reinforcement Learning 2102.07920.pdf*5740398*1614429152","Trust Region Policy Optimization ax17_4.pdf*1030008*1518832879",61428834,""])
D.p(["Z:/UofA/PhD/Literature/denoising*0*1656263264","Patch-based video denoising with optical flow estimation tip16.pdf*491086*1516853279","Polyview Fusion A Strategy to Enhance Video-Denoising Algorithms tip12.pdf*4976515*1516854030",5467601,""])
D.p(["Z:/UofA/PhD/Literature/document_recognition*0*1656263264","A Meaningful Information Extraction System for Interactive Analysis of Documents icdar19.pdf*915342*1610507807","Attend, Copy, Parse End-to-end information extraction from documents icdar19.pdf*182488*1610507970","Graphical Object Detection in Document Images icdar19.pdf*1695515*1610507704","Table Detection in Invoice Documents by Graph Neural Networks icdar19.pdf*377530*1610507861",3170875,""])
D.p(["Z:/UofA/PhD/Literature/dynamic_programming*0*1656263264","Automatic differentiation in machine learning a survey ax1802.pdf*608106*1540237647","Demystifying Differentiable Programming ShiftReset the Penultimate Backpropagator 180327.pdf*1211562*1537367755","Differentiable Programming for Image Processing and Deep Learning in Halide siggraph18.pdf*6777250*1540237647",8596918,""])
D.p(["Z:/UofA/PhD/Literature/event_camera*0*1656263265","Dynamic Vision Sensors for Human Activity Recognition ax1803.04667 acpr17.pdf*2204726*1550233855","Event-based Vision meets Deep Learning on Steering Prediction for Self-driving Cars ax1804.01310 cvpr18.pdf*3192495*1550233091","PRED18 Dataset and Further Experiments with DAVIS Event Camera in Predator-Prey Robot Chasing 1807.03128.pdf*598746*1550233221",5995967,""])
D.p(["Z:/UofA/PhD/Literature/evolution_strategies*0*1656263265","Deep Neuroevolution Genetic Algorithms Are a Competitive Alternative for Training Deep Neural Networks for Reinforcement Learning ax180420.pdf*1560016*1538073776",1560016,""])
D.p(["Z:/UofA/PhD/Literature/few_shot_learning*0*1656263265","Low-Shot Learning with Imprinted Weights ax1804 cvpr18.pdf*876240*1554169654","Matching Networks for One Shot Learning ax171229.pdf*2917198*1534903572","Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks 1703.03400 icml17.pdf*3979868*1588195218","Prototypical Networks for Few-shot Learning ax1707.pdf*587621*1540237648","Webly Supervised Learning Meets Zero-shot Learning A Hybrid Approach for Fine-grained Classiﬁcation cvpr18.pdf*886045*1565711254",9246972,""])
D.p(["Z:/UofA/PhD/Literature/general_value_functions*0*1656263268","horde1.pdf*2849222*1476937604","HSR12_Abeyruwan.pdf*1525990*1518832868","Sherstan_2014_AIROBOT.pdf*1596485*1476937614","Sherstan_2016_AGI_preprint.pdf*255170*1476937609",6226867,""])
D.p(["Z:/UofA/PhD/Literature/generative*0*1700678015","#Group meeting Wed Jun 6 1pm Daniel on generative models.pdf*17139*1528057259","A Note on the Inception Score icmlw18 1801.01973.pdf*4603953*1604076061","Neural distribution estimation as a two-part problem phd 2023.pdf*15370067*1687637038","SEDS a Framework to Generate Stable, Adaptive, Reactive, and Human-Like Robot Reaching Motions 13_1.pdf*3176015*1518832869",23167174,"117*118*119*120"])
D.p(["Z:/UofA/PhD/Literature/generative/3d*0*1700677984","Learning a Probabilistic Latent Space of Object Shapes via 3D Generative-Adversarial Modeling.pdf*8061912*1480463785","pi-gan periodic implicit generative adversarial networks for 3d-aware image synthesis CVPR 2021.pdf*8274670*1659547035","Render for CNN Viewpoint Estimation in Images Using CNNs Trained with Rendered 3D Model Views iccv.pdf*7708027*1465506612",24044609,""])
D.p(["Z:/UofA/PhD/Literature/generative/diffusion*0*1700678057","Denoising Diffusion Implicit Models iclr21.pdf*10857218*1699898967","Denoising Diffusion Probabilistic Models nips20.pdf*10267274*1686251488","Diffusion Models Beat GANs on Image Synthesis 2105.05233.pdf*39795106*1700529039","Diffusion Models in Vision A Survey 2209.04747.pdf*14686075*1700586736","Generative Modeling by Estimating Gradients of the Data Distribution 1907.05600 nips19.pdf*8113050*1686251611","High-Resolution Image Synthesis with Latent Diffusion Models cvpr22 2112.10752.pdf*40842586*1686251441","Improved Denoising Diffusion Probabilistic Models icml21.pdf*12442086*1699990035","Understanding Diﬀusion Models A Uniﬁed Perspective 2208.11970.pdf*5033664*1700534651",142037059,""])
D.p(["Z:/UofA/PhD/Literature/generative/GAN*0*1700678015","An empirical study on evaluation metrics of generative adversarial networks 1806.07755.pdf*879163*1604166455","Are GANs Created Equal A Large-Scale Study nips18 1711.10337.pdf*4634371*1604076151","Generative Adversarial Nets arxiv14.pdf*530482*1493938254","Improved Techniques for Training GANs ax1606.pdf*2349963*1540237570","Infogan Interpretable representation learning by information maximizing generative adversarial nets ax1606.03657 nips16.pdf*3597069*1557933331","Pros and Cons of GAN Evaluation Measures 1802.03446.pdf*7792727*1604031667","Training Generative Adversarial Networks with Limited Data 2006.06676 nips20.pdf*43309687*1607477011","Tutorial Generative Adversarial Networks arxiv16 NIPS16.pdf*10913043*1518832868","UNROLLED GENERATIVE ADVERSARIAL NETWORKS iclr17 1611.02163.pdf*5542435*1604089133",79548940,""])
D.p(["Z:/UofA/PhD/Literature/generative/unpaired image translation*0*1656263267","Contrastive Learning for Unpaired Image-to-Image Translation 2007.15651.pdf*8753460*1647274322",8753460,""])
D.p(["Z:/UofA/PhD/Literature/graph_theory*0*1656263268","Algorithm 447 Efﬁcient algorithms for graph manipulation acm73.pdf*739684*1498408470","An eﬃcient heuristic procedure for partitioning graphs 1970.pdf*750239*1498947719","The Junction Tree Algorithm.pdf*60082*1498432469","The Junction Tree Algorithms.pdf*135561*1498432465","The partition problem mp93.pdf*1495236*1498675540",3180802,"122"])
D.p(["Z:/UofA/PhD/Literature/graph_theory/crf*0*1656263268","An Introduction to Conditional Random Fields.pdf*754681*1518832869","Conditional Random Fields An Introduction cambridge04.pdf*112257*1498408848","Integer Linear Programming Inference for Conditional Random Fields icml05.pdf*241426*1498408928","Tutorial on Conditional Random Fields for Sequence Prediction.pdf*1829121*1498408924",2937485,""])
D.p(["Z:/UofA/PhD/Literature/HMM*0*1656263268","The Forward-Backward Algorithm.pdf*133662*1484580163",133662,""])
D.p(["Z:/UofA/PhD/Literature/image_captioning*0*1699633944","Deep Visual-Semantic Alignments for Generating Image Descriptionsv cvpr15.pdf*5190227*1595476316","Neural Baby Talk 1803.09845 cvpr18.pdf*5697672*1596142695","Show and Tell A Neural Image Caption Generator 1411.4555.pdf*673479*1595476322","Show, Attend and Tell Neural Image Caption Generation with Visual Attention xuc15.pdf*3126761*1478118554",14688139,"125*126"])
D.p(["Z:/UofA/PhD/Literature/image_captioning/diffusion*0*1699381785","Analog Bits Generating Discrete Data using Diffusion Models with Self-Conditioning iclr23.pdf*2577381*1700149574",2577381,""])
D.p(["Z:/UofA/PhD/Literature/image_captioning/transformer*0*1699634331","Beyond a Pre-Trained Object Detector Cross-Modal Textual and Visual Context for Image Captioning cvprr22.pdf*1424750*1699381919","End-to-End Transformer Based Model for Image Captioning aaai22.pdf*1151587*1699380914","ExpansionNet v2 Block Static Expansion in fast end to end training for Image Captioning ax2208.pdf*15695654*1699381306","GIT A Generative Image-to-text Transformer for Vision and Language ax2212.pdf*16681745*1699382536","GRIT Faster and Better Image captioning Transformer Using Dual Visual Features eccv22.pdf*7867919*1699416751","Improving Image Captioning by Leveraging Intra- and Inter-layer Global Representation in Transformer Network aaai21.pdf*2538904*1699382399","Meshed-Memory Transformer for Image Captioning CVPR20.pdf*10121186*1699381393","mPLUG Effective and Efficient Vision-Language Learning by Cross-modal Skip-connections emnlp22.pdf*794012*1699382054","SeqTR A Simple yet Universal Network for Visual Grounding eccv22.pdf*11733791*1699715072","UniTAB Unifying Text and Box Outputs for Grounded Vision-Language Modeling eccv22.pdf*4650151*1699633899",72659699,""])
D.p(["Z:/UofA/PhD/Literature/image_matching*0*1656263269","AnchorNet A Weakly Supervised Network to Learn Geometry-sensitive Features For Semantic Matching ax1704.pdf*4889238*1521480236","Learning Image Matching by Simply Watching Video eccv16.pdf*10517938*1540237649","Local Convolutional Features With Unsupervised Training for Image Retrieval iccv15.pdf*3821370*1453229303",19228546,"128*129"])
D.p(["Z:/UofA/PhD/Literature/image_matching/siamese_networks_and_learned_similarity*0*1656263269","Deep metric learning using Triplet network.pdf*6360867*1518832886","Learning a Similarity Metric Discriminatively, with Application to Face Veriﬁcation 05.pdf*313804*1468333515","Siamese Neural Networks for One-Shot Image Recognition msc-thesis.pdf*1437286*1468333531","Siamese Neural Networks for One-shot Image Recognition.pdf*766340*1468333526",8878297,""])
D.p(["Z:/UofA/PhD/Literature/image_matching/similarity_metric*0*1656263269","Best-buddies similarity for robust template matching cvpr15.pdf*10909834*1518832886","Large scale online learning of image similarity through ranking jmlr10.pdf*1167567*1497294897",12077401,""])
D.p(["Z:/UofA/PhD/Literature/image_processing*0*1699380960","Relations between the statistics of natural images and the response properties of cortical cells 87.pdf*3903831*1544015443","Statistics of natural images Scaling in the woods 94.pdf*1357466*1544015471",5261297,""])
D.p(["Z:/UofA/PhD/Literature/interpolation*0*1656263269",".gitignore*13*1546019293","Context-aware Synthesis for Video Frame Interpolation cvpr18 ax1803.10967.pdf*1389250*1546018263","Phase-based frame interpolation for video cvpr15.pdf*18256714*1520137929","Video Frame Interpolation via Adaptive Convolution ax1703.pdf*1731401*1520542502","Video Frame Interpolation via Adaptive Separable Convolution iccv17.pdf*3594224*1520338751",24971602,"132"])
D.p(["Z:/UofA/PhD/Literature/interpolation/notes*0*1656263269","Video Frame Interpolation via Adaptive Convolution ax1703.pdf*3016362*1520565602",3016362,""])
D.p(["Z:/UofA/PhD/Literature/labeling*0*1656263270","Efficiently Scaling up Crowdsourced Video Annotation ijcv12.pdf*11532806*1548280549","LabelMe a database and web-based tool for image annotation. ijcv08.pdf*4194785*1548275339",15727591,""])
D.p(["Z:/UofA/PhD/Literature/machine_learning*0*1656263270","Online passive-aggressive algorithms jmlr06.pdf*372767*1497295210",372767,""])
D.p(["Z:/UofA/PhD/Literature/manifold embedding*0*1635623867",0,""])
D.p(["Z:/UofA/PhD/Literature/misc*0*1656263272","A simple method for fitting of bounding rectangle to closed regions pr07.pdf*736749*1518832870","Algorithms for the assignment and transportation problems jsiam57.pdf*732132*1495303669","Bronstein, Bronstein, Kimmel - Numerical Geometry of Nonrigid Shapes.pdf*7606287*1625019174","Google’s Hybrid Approach to Research.pdf*74118*1573533973","Hartley, Zisserman - Multiple View Geometry in Computer Vision.pdf*10734979*1625008855","Numerical Geometry of Images 2004.pdf*18933921*1625015246","The General Theory of General Intelligence A Pragmatic Patternist Perspective 2103.15100.pdf*2402958*1618066566","The Multiplicative Weights Update Method A Meta-Algorithm and Applications toc1205.pdf*391335*1540237649",41612479,"137*138*139*140"])
D.p(["Z:/UofA/PhD/Literature/misc/gpu_programming*0*1656263271","A GPU-Enabled Solver For Time-Constrained Linear Sum Assignment Problems.pdf*278169*1589042470","GPU-accelerated Hungarian algorithms for the Linear Assignment Problem pc1609.pdf*791307*1589042699","GPU-Based Heuristic Solver for Linear Sum Assignment Problems Under Real-time Constraints 1106.5694.pdf*310815*1589042366",1380291,""])
D.p(["Z:/UofA/PhD/Literature/misc/line_intersections*0*1656263271","python - Numpy and line intersections - Stack Overflow.mht*907037*1516517045","x06-sweepline.pdf*104636*1516508260",1011673,""])
D.p(["Z:/UofA/PhD/Literature/misc/math*0*1656263271","BODY and SOUL MATHEMATICAL SIMULATION TECHNOLOGY.pdf*26315558*1625008866","Computational Differential Equations.pdf*8619300*1625008867","Counting Binary Matrices with Given Row and Column Sums 1987.pdf*506802*1628175901",35441660,""])
D.p(["Z:/UofA/PhD/Literature/misc/radon_transform*0*1656263272","Reconstruction from projections.pdf*1373213*1544665784","The Finite Radon Transform - Ball State University.pdf*5184852*1544882769","The Radon Transform - Theory and Implementation PhD Thesis.pdf*6722715*1544665781","The Radon Transform report07.pdf*242912*1544665760","The Radon Transform.pdf*1310790*1544665871",14834482,""])
D.p(["Z:/UofA/PhD/Literature/MOT*0*1656263290",".gitignore*191*1611518918","Lifted Disjoint Paths with Application in Multiple Object Tracking 2006.14550 icml20 mot_all_winner.pdf*589267*1595089973","Multi-Object Tracking with Multiple Cues and Switcher-Aware Classification 1901.06129.pdf*1851763*1595162472","Quasi-Dense Similarity Learning for Multiple Object Tracking 2006.06664v3.pdf*9405182*1623089506","Rethinking the competition between detection and ReID in Multi-Object Tracking 2010.12138v2.pdf*4489912*1623089670",16336315,"142*143*144*145*146*147*148*149*150*151*152*153*154*155*156*157*158*159*160*161*162*163*164*165*166*167*168*169*170*172*173*174*175*176*177*178*179*180*181"])
D.p(["Z:/UofA/PhD/Literature/MOT/3d*0*1656263274","3D Multi-Object Tracking A Baseline and New Evaluation Metrics 1907.03961v5.pdf*1390174*1623088882","3D Trafﬁc Scene Understanding from Movable Platforms pami14.pdf*6232422*1558885421","End-to-end Learning of Multi-sensor 3D Tracking by Detection 1806.11534 icra18.pdf*7489014*1647197652","GNN3DMOT Graph Neural Network for 3D Multi-Object Tracking with Multi-Feature Learning 2006.07327v1.pdf*1604739*1623089225","JRMOT A Real-Time 3D Multi-Object Tracker and a New Large-Scale Dataset ax2002.08397.pdf*6780517*1594412493",23496866,""])
D.p(["Z:/UofA/PhD/Literature/MOT/approx_diff*0*1656263274","Deep Affinity Network for Multiple Object Tracking ax1810.11780 tpami19.pdf*6283068*1650172253","FAMNet Joint Learning of Feature, Affinity and Multi-Dimensional Assignment for Online Multiple Object Tracking iccv19.pdf*1150495*1650174911","How To Train Your Deep Multi-Object Tracker 1906.06618v3 cvpr20.pdf*3330568*1650226021",10764131,""])
D.p(["Z:/UofA/PhD/Literature/MOT/association*0*1656263275","Data Association for Multi-Object Tracking via Deep Neural Networks sensord1902.pdf*20025278*1579925543","Deep Learning for Bipartite Assignment Problems 1908_MPhil.pdf*717953*1579925358","Multi-target Tracking by Rank-1 Tensor Approximation cvpr13.pdf*947455*1575765800","Online Multi-Object Tracking based on Hierarchical Association Framework  cvprw16_7.pdf*1334055*1544538993","Online multi-object tracking by detection based on generative appearance models cviu16_11.pdf*2240222*1544539124","Rank-1 Tensor Approximation for High-Order Association in Multi-target Tracking ijcv19.pdf*2786045*1575764710","Towards Real-Time Multi-Object Tracking ax1909.12605v1.pdf*711993*1579926769",28763001,""])
D.p(["Z:/UofA/PhD/Literature/MOT/baseline*0*1656263275","Aerial multi-object tracking by detection using deep association networks ax1909.01547.pdf*2636116*1569163937","Deep SORT  Simple Online Realtime Tracking with a Deep Association Metric ax1703.07402 icip17.pdf*1195975*1558325991","High-Speed Tracking-by-Detection Without Using Image Information avss17.pdf*334051*1544408890","Simple Online and Realtime Tracking ax1707 icip16.pdf*142304*1567191987",4308446,""])
D.p(["Z:/UofA/PhD/Literature/MOT/batch*0*1656263275","A Multi-cut Formulation for Joint Segmentation and Tracking of Multiple Objects ax16_9 [best MT on MOT15].pdf*4676240*1540237668","Continuous energy minimization for multitarget tracking tpami14.pdf*2129705*1495372860","Learning an image-based motion context for multiple people tracking cvpr14.pdf*879673*1495372895","Multiple Object Tracking Using K-Shortest Paths Optimization  tpami11.pdf*1664693*1495372785","Multi-target tracking by lagrangian relaxation to min-cost network ﬂow cvpr13.pdf*1293184*1495372827","Multi-target Tracking by Rank-1 Tensor Approximation cvpr13.pdf*938301*1655266518",11581796,""])
D.p(["Z:/UofA/PhD/Literature/MOT/bayesian*0*1656263275","Multi-Class Multi-Object Tracking using Changing Point Detection ax16_8.pdf*5150963*1544538615",5150963,""])
D.p(["Z:/UofA/PhD/Literature/MOT/cell*0*1656263424","Accurate cell tracking and lineage construction in live-cell imaging experiments with deep learning bioax19.pdf*2207589*1614090929","An Objective Comparison of Cell Tracking Algorithms nature methods 2017.pdf*2016170*1621443752","DeLTA Automated cell segmentation, tracking, and lineage reconstruction using deep learning ploscb200413.pdf*1393326*1613493500","Global linking of cell tracks using the viterbi algorithm_tmi1504.pdf*2699203*1617135693","Robust single-particle tracking in live-cell time-lapse sequences. Nature methods, 2008.pdf*903004*1618692587",9219292,""])
D.p(["Z:/UofA/PhD/Literature/MOT/compressed*0*1656263276","MV-YOLO Motion Vector-aided Tracking by Semantic Object Detection ax1806.pdf*1624693*1544536748",1624693,""])
D.p(["Z:/UofA/PhD/Literature/MOT/context*0*1656263276","Learning an image-based motion context for multiple people tracking cvpr14.pdf*3848852*1494861036","Learning Optimal Parameters for Multi-target Tracking with Contextual Interactions ax1610 ijcv16.pdf*7708326*1537481253",11557178,""])
D.p(["Z:/UofA/PhD/Literature/MOT/deep_learning*0*1656263276","Deep Continuous Conditional Random Fields with Asymmetric Inter-object Constraints for Online Multi-object Tracking ax1806.01183.pdf*1397955*1540237675","Improving Online Multiple Object tracking with Deep Metric Learning  ax1806.07592.pdf*3728078*1540237675","Multi-Class Multi-Object Tracking using Changing Point Detection ax160830 eccv16.pdf*5198734*1526666525","Multi-Object Tracking with Multiple Cues and Switcher-Aware Classification ax1901.06129.pdf*1791822*1576503123","Online Multi-Object Tracking Using CNN-based Single Object Tracker with Spatial-Temporal Attention Mechanism 1708.02843 iccv17.pdf*763889*1574574170","Online multi-object tracking with dual matching attention networks 1902.00749 eccv18.pdf*2770454*1574818626","Real-time Multiple People Tracking with Deeply Learned Candidate Selection and Person Re-Identification  ax1809.04427.pdf*417953*1540237676","Tracking millions of humans Elsevier_17.pdf*6610749*1507064735","Tracking without bells and whistles ax1903.05625 iccv19.pdf*4105637*1647667737",26785271,""])
D.p(["Z:/UofA/PhD/Literature/MOT/detector_fusion*0*1656263276","A Novel Multi-Detector Fusion Framework for Multi-Object Tracking ax17_9.pdf*5158442*1540237673",5158442,""])
D.p(["Z:/UofA/PhD/Literature/MOT/dictionary_learning*0*1656263277","Spatiotemporal KSVD Dictionary Learning for Online Multi-target Tracking  ax1807.02143.pdf*814821*1544539398",814821,""])
D.p(["Z:/UofA/PhD/Literature/MOT/embedded*0*1656263277","Deep Learning-Based Multiple Object Visual Tracking on Embedded System for IoT and Mobile Edge Computing Applications  1808.01356.pdf*6247220*1540237676",6247220,""])
D.p(["Z:/UofA/PhD/Literature/MOT/end to end*0*1649706373",0,""])
D.p(["Z:/UofA/PhD/Literature/MOT/energy*0*1656263277","Continuous energy minimization for multitarget tracking tpami14_1.pdf*2110873*1544538103",2110873,""])
D.p(["Z:/UofA/PhD/Literature/MOT/ensemble*0*1656263277","A fast multi-object tracking system using an object detector ensemble ax1908.04349 ColCACI19.pdf*3518260*1569163776","To track or to detect an ensemble framework for optimal selection. eccv12.pdf*7445647*1574451024",10963907,""])
D.p(["Z:/UofA/PhD/Literature/MOT/graph*0*1656263279","A Graph Transduction Game for Multi-target Tracking  ax1806.07227.pdf*1410520*1540237673","GSM Graph Similarity Model for Multi-Object Tracking ijcai20.pdf*3384949*1595162535","Joint Object Detection and Multi-Object Tracking with Graph Neural Networks 2006.13164 icra21.pdf*733216*1623085851","Subgraph decomposition for multi-object tracking cvpr15.pdf*2887711*1498935881","TGCN Time Domain Graph Convolutional Network for Multiple Objects Tracking 2101.01861.pdf*718660*1612148833",9135056,""])
D.p(["Z:/UofA/PhD/Literature/MOT/joint_detection*0*1656263279","A Simple Baseline for Multi-Object Tracking 2004.01888.pdf*1772679*1606614375","DEFT Detection Embeddings for Tracking, 2102.02267.pdf*5398957*1650124327","Detect to Track and Track to Detect_iccv17.pdf*2483165*1595258567","End-to-End Multi-Object Tracking with Global Response Map 2007.06344.pdf*4257429*1649694628","FairMOT On the Fairness of Detection and Re-Identification in Multiple Object Tracking 2004.01888v5.pdf*7963756*1623085279","Integrated Object Detection and Tracking with Tracklet-Conditioned Detection 1811.11167.pdf*876087*1607893934","Joint Object Detection and Multi-Object Tracking with Graph Neural Networks 2006.13164.pdf*779988*1649049014","MOTS Multi-Object Tracking and Segmentation ax1904 cvpr19.pdf*8995239*1576371878","RetinaTrack Online Single Stage Joint Detection and Tracking 2003.13870 cvpr20.pdf*3822278*1648604357","Towards Real-Time Multi-Object Tracking ax1909.12605v1 1909.12605 eccv20.pdf*4820192*1648585254","Tracking Beyond Detection Learning a Global Response Map for End-to-End Multi-Object Tracking tip21.pdf*6728660*1649694634","Tracking Objects as Points 2004.01177 eccv20.pdf*3584489*1595258033",51482919,""])
D.p(["Z:/UofA/PhD/Literature/MOT/metrics*0*1656263280","Evaluating Multi-Object Tracking cvpr05.pdf*865382*1612311095","Evaluating multiple object tracking performance the clear mot metrics eurasip08.pdf*3747824*1609562170","HOTA A Higher Order Metric for Evaluating Multi-object Tracking sl_open_2010_ijcv2008.pdf*3686931*1652034606","Local Metrics for Multi-Object Tracking 2104.02631.pdf*1700697*1618951180","Multiple object tracking performance metrics and evaluation in a smart room environment eccvw06.pdf*2388304*1596125155","Performance Measures and a Data Set for Multi-Target, Multi-Camera Tracking 1609.01775 eccvw16.pdf*5970826*1623810128","The clear 2006 evaluation..pdf*9503976*1609562829",27863940,""])
D.p(["Z:/UofA/PhD/Literature/MOT/mht*0*1656263280","An Algorithm for Tracking Multiple Targets TAC1979.pdf*1198626*1655241033","An efﬁcient implementation of Reid’s multiple hypothesis tracking algorithm and its evaluation for the purpose of visual tracking pami96.pdf*2510915*1655241149","Forty Years of Multiple Hypothesis Tracking.pdf*535172*1655241550","Fundamentals and Advances in Multiple-Hypothesis Tracking .pdf*5698409*1655240651","Multiple hypothesis tracking revisited iccv15.pdf*1147488*1497618742","The Maximum Weight Independent Set Problem for Data Association in Multiple Hypothesis Tracking 2009.pdf*1025223*1655243533",12115833,""])
D.p(["Z:/UofA/PhD/Literature/MOT/misc*0*1656263281","Cyclist Detection, Tracking, and Trajectory Analysis in Urban Traffic Video Data msc_thes1708.pdf*2416990*1540237677","Measurement-wise Occlusion in Multi-object Tracking ax1805.08324.pdf*1689059*1544538533","Multiple object tracking with context awareness ax1411 1610 phd.pdf*10379233*1579916718","Multiple Object Tracking with Kernelized Correlation Filters in Urban Mixed Trafﬁc crv17.pdf*929943*1499368112","PoseTrack Joint Multi-Person Pose Estimation and Tracking_cvpr17.pdf*978226*1537338454",16393451,""])
D.p(["Z:/UofA/PhD/Literature/MOT/multi_camera*0*1656263281","Robust Multi-Modality Multi-Object Tracking 1909.03850 iccv19.pdf*8496826*1575335821",8496826,""])
D.p(["Z:/UofA/PhD/Literature/MOT/network_flow*0*1656263281","Deep Network Flow for Multi-Object Tracking cvpr17.pdf*2172722*1548566382","Deep Network Flow for Multi-Object Tracking cvpr17_supplemental.pdf*3105563*1537765914","FollowMe Efﬁcient Online Min-Cost Flow Tracking with Bounded Memory and Computation ax1412 iccv15.pdf*1016112*1537638414","Learning a Neural Solver for Multiple Object Tracking 1912.07515 cvpr20.pdf*10234001*1648603547","Multi-commodity network flow for tracking multiple people tpami14.pdf*1993964*1540237677","Near-online multi-target tracking with aggregated local ﬂow descriptor iccv15.pdf*1998269*1540237677","On Pairwise Costs for Network Flow Multi-Object Tracking cvpr15.pdf*2316053*1537710153","Target identity-aware network flow for online multiple target tracking cvpr15.pdf*2694321*1497615806",25531005,""])
D.p(["Z:/UofA/PhD/Literature/MOT/notes*0*1656263282","A Simple Baseline for Multi-Object Tracking 2004.01888.pdf*105213*1606614855","A_Multi-cut_Formulation_for_Joint_Segmentation_and_Tracking_of_Multiple_Objects.pdf*6910195*1499035014","Collaborative Deep Reinforcement Learning for Multi-Object Tracking_eccv18.pdf*205081*1575126914","Deep Affinity Network for Multiple Object Tracking ax1810.11780 tpami19.pdf*200218*1581991130","Deep Network Flow for Multi-Object Tracking cvpr17.pdf*10247*1548595649","Eliminating Exposure Bias and Metric Mismatch in Multiple Object Tracking cvpr19.pdf*191560*1578805107","Exploit the Connectivity Multi-Object Tracking with TrackletNet ax1811.07258 mm19.pdf*201736*1578164843","FAMNet Joint Learning of Feature, Affinity and Multi-Dimensional Assignment for Online Multiple Object Tracking iccv19.pdf*197975*1576502580","High-Speed Tracking-by-Detection Without Using Image Information avss17.pdf*2609*1558882477","HOTA A Higher Order Metric for Evaluating Multi-object Tracking sl_open_2010_ijcv2008.pdf*109630*1611518481","Integrated Object Detection and Tracking with Tracklet-Conditioned Detection 1811.11167.pdf*103687*1607893813","Learning a Neural Solver for Multiple Object Tracking 1912.07515 cvpr20.pdf*109651*1609102638","Learning_to_Track_Online_Multi-object_Tracking_by_Decision_Making__iccv15.pdf*21482*1498694653","mdp_tracking.pdf*1372027*1544472790","MOTS Multi-Object Tracking and Segmentation ax1904 cvpr19.pdf*193889*1576502614","Multi-object Tracking with Neural Gating Using Bilinear LSTM_eccv18.pdf*210986*1576502562","NOMT.pdf*11146093*1498691704","Online Multi-Object Tracking Using CNN-based Single Object Tracker with Spatial-Temporal Attention Mechanism 1708.02843 iccv17.pdf*199077*1574562858","Online multi-object tracking with dual matching attention networks 1902.00749 eccv18.pdf*195086*1574819635","Simple Online and Realtime Tracking ax1707 icip16.pdf*3501*1558887835","Simple Unsupervised Multi-Object Tracking 2006.02609.pdf*104296*1607191403","Towards Real-Time Multi-Object Tracking ax1909.12605v1.pdf*178627*1595259274","Tracking by Animation Unsupervised Learning of Multi-Object Attentive Trackers cvpr19 ax1809.03137.pdf*200735*1574993678","Tracking Objects as Points 2004.01177.pdf*113516*1595257717","Tracking without bells and whistles ax1903.05625 iccv19.pdf*193357*1580850000","Tracking_The_Untrackable_Learning_To_Track_Multiple_Cues_with_Long-Term_Dependencies.pdf*19745*1498694430","Unsupervised Person Re-identification by Deep Learning Tracklet Association 1809.02874 eccv18.pdf*93681*1607191218",22593900,""])
D.p(["Z:/UofA/PhD/Literature/MOT/old*0*1656263283","Global data association for multi-object tracking using network ﬂows cvpr08.pdf*5054627*1537677886","Learning to associate HybridBoosted multi-target tracker for crowded scene cvpr09.pdf*3383482*1495246133","Markov chain monte carlo data association for multi-target tracking tac09.pdf*1635789*1494861669","MCMC-based particle filtering for tracking a variable number of interacting targets  tpami05.pdf*448354*1494860918","Multiple Object Tracking using K-Shortest Paths pami11.pdf*5369000*1469726459","Multi-target tracking by online learned discriminative appearance models. cvpr10.pdf*1121726*1494860998","Online multi-target tracking by large margin structured learning accv12.pdf*1329027*1494860959","People-Tracking-by-Detection and People-Detection-by-Tracking_cvpr08.pdf*9314870*1579916520",27656875,""])
D.p(["Z:/UofA/PhD/Literature/MOT/PF*0*1656263283","Online Multi-target Tracking with Strong and Weak Detections eccv16.pdf*5080221*1544539312",5080221,""])
D.p(["Z:/UofA/PhD/Literature/MOT/reid*0*1656263284","Torchreid A Library for Deep Learning Person Re-Identification in Pytorch 1910.10093.pdf*494745*1607190626",494745,""])
D.p(["Z:/UofA/PhD/Literature/MOT/reidentification*0*1656263284","Attention A Big Surprise for Cross-Domain Person Re-Identiﬁcation ax1905.12830.pdf*2596615*1576800199","Unsupervised Person Re-identification by Deep Learning Tracklet Association 1809.02874 eccv18.pdf*3096825*1582486574",5693440,""])
D.p(["Z:/UofA/PhD/Literature/MOT/review*0*1656263285","A Survey on Leveraging Deep Neural Networks for Object Tracking itsc17.pdf*227707*1579917040","A Survey on Leveraging Deep Neural Networks for Object Tracking ppt.pdf*2910803*1537712873","Deep Learning in Video Multi-Object Tracking A Survey ax1907.12740.pdf*2655730*1609548881","Machine Learning Methods for Solving Assignment Problems in Multi-Target Tracking ax1802.06897.pdf*2178864*1577732481","Multiple Object Tracking A Literature Review 1409.7618 ax220211 AI21.pdf*1424901*1647195491","Real-Time Multiple Object Tracking - A Study on the Importance of Speed ax17_10 thesis.pdf*2364329*1507064885","The State of the Art in Multiple Object Tracking Under Occlusion in Video Sequences 2003-ACIVS.pdf*735827*1580057740","Tracking the Trackers An Analysis of the State of the Art in Multiple Object Tracking ax17_4.pdf*2385073*1574310549",14883234,"171"])
D.p(["Z:/UofA/PhD/Literature/MOT/review/dubious*0*1656263285","A Review of Detection and Tracking of Object from Image and Video Sequences ijcirv13n5_07.pdf*474546*1588887154","A Uniﬁed Pipeline for Multiple Object Tracking proj report.pdf*40368911*1588887138","Multiple Object Detection and Tracking A Survey  1802.pdf*1279615*1588887119",42123072,""])
D.p(["Z:/UofA/PhD/Literature/MOT/RL*0*1656263285","Collaborative Deep Reinforcement Learning for Multi-Object Tracking_eccv18.pdf*9721276*1575077709","Learning to Track Online Multi-object Tracking by Decision Making  iccv15.pdf*859671*1573257143","Learning to Track Online Multi-Object Tracking by Decision Making_iccv15 supplementary.pdf*152137*1495245809","Multi-Agent_Deep_Reinforcement_Learning_for_Multi-Object_Tracker.pdf*11112397*1655655255","Multiobject Tracking in Videos Based on LSTM and Deep Reinforcement Learning hindawi1803.pdf*40049858*1655662429",61895339,""])
D.p(["Z:/UofA/PhD/Literature/MOT/rnn*0*1656263287","Deep tracking in the wild End-to-end tracking using recurrent neural networks ijrr17.pdf*5748068*1583003643","Eliminating Exposure Bias and Metric Mismatch in Multiple Object Tracking cvpr19.pdf*2383416*1578804804","End-to-End Tracking and Semantic Segmentation Using Recurrent Neural Networks 1604.05091.pdf*4332452*1583003677","Multi-object Tracking with Neural Gating Using Bilinear LSTM_eccv18.pdf*547898*1576438520","Multiple Object Tracking in Videos Based on LSTM  hindawi.pdf*4048530*1537710152","Online Multi-Target Tracking Using Recurrent Neural Networks 1604.03635 aaai17.pdf*2094954*1575336828","Tracking of Humans in Video Stream Using LSTM Recurrent Neural Network mml_thes1708.pdf*18597651*1525991734","Tracking The Untrackable Learning To Track Multiple Cues with Long-Term Dependencies ax17_4_iccv17.pdf*1021234*1596133604",38774203,""])
D.p(["Z:/UofA/PhD/Literature/MOT/segmentation*0*1656263287","Joint tracking and segmentation of multiple targets cvpr15.pdf*3864998*1649696809","Learning Multi-Object Tracking and Segmentation from Automatic Annotations cvpr20.pdf*7213731*1649792815","MOTS Multi-Object Tracking and Segmentation CVPR19.pdf*2135639*1569134792","Segment as points for efficient online multi-object tracking and segmentation eccv20.pdf*3038021*1649795763","Track To Detect and Segment An Online Multi-Object Tracker cvpr21.pdf*4097264*1649711575","Track, then Decide Category-Agnostic Vision-based Multi-Object Tracking 1712.07920 icra18.pdf*8779466*1569162941",29129119,""])
D.p(["Z:/UofA/PhD/Literature/MOT/siamese*0*1656263287","Learning by tracking Siamese CNN for robust target association ax1608 cvprw16.pdf*1228763*1576520874","Multi-Object Tracking with Quadruplet Convolutional Neural Networks cvpr17.pdf*736332*1531923371","Online Multi-Object Tracking with Historical Appearance Matching and Scene Adaptive Detection Filtering  ax1805.10916 avss18.pdf*615782*1576520718","SiamMOT Siamese Multi-Object Tracking 2105.11595v1.pdf*6411090*1623090276",8991967,""])
D.p(["Z:/UofA/PhD/Literature/MOT/tracklet*0*1656263287","Exploit the Connectivity Multi-Object Tracking with TrackletNet ax1811.07258 mm19.pdf*4503297*1578164449","Long-term Tracking with Deep Tracklet Association yip2005.pdf*5040562*1608926497","Non-Markovian Globally Consistent Multi-Object Tracking_iccv17.pdf*1415034*1538358794","SMOT Single-Shot Multi Object Tracking 2010.16031v1.pdf*6813089*1650121267","Spatial-Temporal Relation Networks for Multi-Object Tracking 1904.11489.pdf*4248348*1574214247","The way they move Tracking multiple targets with similar appearance iccv13.pdf*898360*1544405090","Tracking multi-object using tracklet and Faster R-CNN icdsc16_9.pdf*865438*1540237678","Tracklet association by online target-speciﬁc metric learning and coherent dynamics estimation tpami17.pdf*695154*1497618124","Tracklet Association Tracker An End-to-End Learning-based Association Approach for Multi-Object Tracking ax1808.01562.pdf*1965061*1609275185",26444343,""])
D.p(["Z:/UofA/PhD/Literature/MOT/traffic*0*1656263288","Multiple Object Tracking in Urban Traffic Scenes with a Multiclass Object Detector  ax1809.02073.pdf*1708176*1544538701",1708176,""])
D.p(["Z:/UofA/PhD/Literature/MOT/transformers*0*1698246357","Global Tracking Transformers cvpr22 2203.13250.pdf*3115730*1698328894","Looking Beyond Two Frames End-to-End Multi-Object Tracking Using Spatial and Temporal Transformers 2103.14829.pdf*4339402*1650064262","MOTR End-to-End Multiple-Object Tracking with Transformer ax220309.pdf*2303029*1650000770","TrackFormer Multi-Object Tracking with Transformers 2101.02702.pdf*1589456*1649811353","TransTrack Multiple Object Tracking with Transformer 2012.15460.pdf*12373428*1649709275","Unified Transformer Tracker for Object Tracking 2203.15175 cvpr22.pdf*23485255*1649870821","ViTT Vision Transformer Tracker sensors-21 mdpi.pdf*1274480*1649876879",48480780,""])
D.p(["Z:/UofA/PhD/Literature/MOT/tubes*0*1656263290","Chained-Tracker Chaining Paired Attentive Regression Results for End-to-End Joint Multiple-Object Detection and Tracking 2007.14557 eccv20.pdf*12024430*1649006598","Simultaneous Detection and Tracking with Motion Modelling for Multiple Object Tracking 2008.08826 eccv20.pdf*6632232*1649646105","TrackNet Simultaneous Object Detection and Tracking and Its Application in Traffic Video Analysis 1902.01466.pdf*8707437*1649138323","TubeTK Adopting Tubes to Track Multi-Object in a One-Step Training Model 2006.05683 cvpr20.pdf*2746990*1649049014",30111089,""])
D.p(["Z:/UofA/PhD/Literature/MOT/uav*0*1656263290","Aerial multi-object tracking by detection using deep association networks ax1909.01547.pdf*2636116*1569164636",2636116,""])
D.p(["Z:/UofA/PhD/Literature/MOT/unsupervised*0*1656263290","Self-Supervised Multi-Object Tracking with Cross-Input Consistency nips21.pdf*1095913*1647723682","Simple Unsupervised Multi-Object Tracking 2006.02609.pdf*501867*1647725067","Tracking by Animation Unsupervised Learning of Multi-Object Attentive Trackers cvpr19 ax1809.03137.pdf*8888504*1575003966","Unsupervised Person Re-identification by Deep Learning Tracklet Association 1809.02874 eccv18.pdf*1199050*1538354852",11685334,""])
D.p(["Z:/UofA/PhD/Literature/motion_prediction*0*1656263273","MOTION ESTIMATION USING CONVOLUTIONAL NEURAL NETWORKS.pdf*3854751*1590854529","Towards Natural and Accurate Future Motion Prediction of Humans and Animals CVPR19.pdf*1920422*1590854506","Transformer Networks for Trajectory Forecasting ax2003.08111.pdf*1130481*1590868192",6905654,""])
D.p(["Z:/UofA/PhD/Literature/neuro_dynamic_programming*0*1656263290","Comparing neuro-dynamic programming algorithms for the vehicle routing problem with stochastic demands cor00.pdf*541254*1494183803","Neuro-Dynamic Programming An Overview 1995 Slides.pdf*343050*1494183708","Neuro-Dynamic Programming An Overview 1995.pdf*342481*1494183715",1226785,""])
D.p(["Z:/UofA/PhD/Literature/Neurosymbolic Programming*0*1656263290","Learning Differentiable Programs with Admissible Neural Heuristics nips20 2007.12101.pdf*686267*1650479763","Neurosymbolic Programming.pdf*5422402*1650469765","Task Programming Learning Data Efficient Behavior Representations cvpr21.pdf*1733550*1650480261",7842219,""])
D.p(["Z:/UofA/PhD/Literature/NLP*0*1700152364","A Generalist Agent TMLR22.pdf*7338692*1652714979","A Survey of Deep Learning Techniques for Neural Machine Translation 2002.07526.pdf*2263779*1595860533","Neural Machine Translation in Linear Time ax1610.10099.pdf*2160032*1590930534","Opinion _ Noam Chomsky_ The False Promise of ChatGPT - The New York Times (3_8_2023 9_38_45 PM).html*1773914*1678336726","Training language models to follow instructions with human feedback 2203.02155.pdf*1797405*1678337764",15333822,""])
D.p(["Z:/UofA/PhD/Literature/optical_flow*0*1656263292","Beyond Pixels Exploring New Representations and Applications for Motion Analysis phd_mit09.pdf*23837300*1540237649","Deep discrete ﬂow accv16.pdf*8333569*1520342071","Deep End2End Voxel2Voxel Prediction ax1511 cvprw16.pdf*9041306*1520342192","DeepFlow Large Displacement Optical Flow with Deep Matching iccv13.pdf*3848135*1498860426","DeepMatching Hierarchical Deformable Dense Matching ijcv16.pdf*10247759*1520342424","Dense Optical Flow Prediction From a Static Image iccv15.pdf*2218368*1520447432","FlowNet 2.0 Evolution of Optical Flow Estimation with Deep Networks cvpr17.pdf*7544342*1590760348","FlowNet Learning Optical Flow With Convolutional Networks iccv15.pdf*16721955*1590520990","Optical Flow Estimation using a Spatial Pyramid Network ax161121.pdf*6028066*1540237650","PWC-Net CNNs for Optical Flow Using Pyramid, Warping, and Cost Volume ax1709.02371 cvpr18.pdf*5190013*1556845229",93010813,"187*188"])
D.p(["Z:/UofA/PhD/Literature/optical_flow/evaluation*0*1656263292","A Database and Evaluation Methodology for Optical Flow iccv07.pdf*1658759*1520464846","A database and evaluation methodology for optical flow ijcv11.pdf*5148345*1518832888","A naturalistic open source movie for optical ﬂow evaluation eccv12.pdf*3930176*1540237650",10737280,""])
D.p(["Z:/UofA/PhD/Literature/optical_flow/non_dl*0*1656263293","A Duality Based Approach for Realtime TV-L1 Optical Flow dagm07.pdf*851025*1520449619","A Filter Formulation for Computing Real Time Optical Flow ral16.pdf*1222504*1502860251","An Efficient Event-Based Optical Flow Implementation in CC++ and CUDA report2015_7.pdf*6121909*1518832888","An Improved Algorithm for TV-L1 Optical Flow sgavmn09.pdf*4320955*1520448112","EpicFlow Edge-Preserving Interpolation of Correspondences for Optical Flow ax1505 cvpr15.pdf*2870595*1526673623","Fast Optical Flow using Dense Inverse Search eccv16.pdf*1358018*1520458208","Flow Fields Dense Correspondence Fields for Highly Accurate Large Displacement Optical Flow Estimation iccv15.pdf*867751*1520458274","High accuracy optical ﬂow estimation based on a theory for warping eccv04.pdf*295416*1520447500","Large displacement optical flow cvpr09.pdf*3877727*1498860433","Large displacement optical ﬂow descriptor matching in variational motion estimation tpami11.pdf*3273625*1520447687","Learning to Extract Motion from Videos in Convolutional Neural Networks ax1601.pdf*6058224*1540237651","Motion Detail Preserving Optical Flow Estimation tpami12.pdf*2692684*1520447080","Motion detail preserving optical ﬂow estimation. cvpr10.pdf*3154946*1520445713","Parallel Implementation of a Robust Optical Flow Technique techreport CTIM_1_2012.pdf*5693232*1496179335","PatchBatch a Batch Augmented Loss for Optical Flow ax1604 cvpr16.pdf*352995*1520341934","SimpleFlow A non-iterative, sublinear optical ﬂow algorithm cgf12.pdf*9649568*1520444502","TV-L1 Optical Flow Estimation ipol13.pdf*881244*1540237652",53542418,""])
D.p(["Z:/UofA/PhD/Literature/optimization*0*1656263294","A Review on Bilevel Optimization From Classical to Evolutionary Approaches and Applications ax1705.pdf*3789392*1540237652","An overview of bilevel optimization AOR2007.pdf*483335*1540237652","Bilevel Optimization with Nonsmooth Lower Level Problems ssvm2015.pdf*684092*1537582190","ConstrainedAssignment.pdf*518499*1628086844","Evolution Strategies as a Scalable Alternative to Reinforcement Learning ax1709.pdf*277340*1508861668","Linear Programming.pdf*1643286*1537481290",7395944,""])
D.p(["Z:/UofA/PhD/Literature/outlier detection*0*1656263294","Snake Validation A PCA-Based Outlier Detection Method spl09.pdf*1502340*1634762619",1502340,""])
D.p(["Z:/UofA/PhD/Literature/perception*0*1699548763","ImVoxelNet Image to Voxels Projection for Monocular and Multi-View General-Purpose 3D Object Detection wacv22 2106.01178.pdf*26554436*1693338114","Reimagining_an_autonomous_vehicle ax2108 wayve.pdf*286816*1698962508","Robust Self-Supervised Extrinsic Self-Calibration 2308.02153 iros23.pdf*2123013*1691614861","TractorEYE Vision-based Real-time Detection for Autonomous Vehicles in Agriculture PhD Thesis 2017.pdf*8375347*1699128883",37339612,"192*193*194*195*196*197"])
D.p(["Z:/UofA/PhD/Literature/perception/fusion*0*1699212833","Benchmarking the Robustness of LiDAR-Camera Fusion for 3D Object Detection cvprw23 2205.14951.pdf*14551704*1698337288","BEVFusion A Simple and Robust LiDAR-Camera Fusion Framework nips22 2205.13790.pdf*2438324*1698334785","BEVFusion Multi-Task Multi-Sensor Fusion with Unified Bird's-Eye View Representation icra23 2205.13542.pdf*10711876*1698283921","LiDAR-as-Camera_for_End-to-End_Driving mdpi sensors Mar 2023.pdf*4216857*1699124798","TransFuser Imitation with Transformer-Based Sensor Fusion for Autonomous Driving cvpr21 pami23.pdf*54001344*1699288563","TransFusion Robust LiDAR-Camera Fusion for 3D Object Detection with Transformers cvpr22 2203.11496.pdf*6121557*1698503994",92041662,""])
D.p(["Z:/UofA/PhD/Literature/perception/lidar*0*1699123361","PointPillars Fast Encoders for Object Detection from Point Clouds cvpr19 1812.05784.pdf*5374398*1698353299",5374398,""])
D.p(["Z:/UofA/PhD/Literature/perception/multri camera*0*1698962574","BEVDet High-performance Multi-camera 3D Object Detection in Bird-Eye-View 2112.11790.pdf*500324*1698596815","BEVFormer Learning Bird's-Eye-View Representation from Multi-Camera Images via Spatiotemporal Transformers eccv22.pdf*4626609*1698620629","Lift, Splat, Shoot Encoding Images From Arbitrary Camera Rigs by Implicitly Unprojecting to 3D.eccv20 2008.05711.pdf*5266919*1698872137","M2BEV Multi-Camera Joint 3D Detection and Segmentation with Unified Birds-Eye View Representation 2204.05088.pdf*15716237*1698521734","PETR Position Embedding Transformation for Multi-View 3D Object Detection eccv22 .pdf*4264013*1698871073","PETRv2 A Unified Framework for 3D Perception from Multi-Camera Images iccv23.pdf*1051830*1699212388","TBP-Former Learning Temporal Bird's-Eye-View Pyramid for Joint Perception and Prediction in Vision-Centric Autonomous Driving cvpr23.pdf*4356269*1698854350",35782201,""])
D.p(["Z:/UofA/PhD/Literature/perception/path planning*0*1699548765","GPT-Driver Learning to Drive with GPT ax2310.01415.pdf*1586246*1699663155",1586246,""])
D.p(["Z:/UofA/PhD/Literature/perception/radar fusion*0*1698850797","A Simple Baseline for BEV Perception Without LiDAR 2206.07959v1.pdf*1192709*1698850723",1192709,""])
D.p(["Z:/UofA/PhD/Literature/perception/review*0*1698691232","3D Object Detection for Autonomous Driving A Survey 2106.10823.pdf*4200088*1698599252","Computer Vision in Self-Steering Tractors machines-10-00129.pdf*8550786*1698267224","Delving into the Devils of Bird's-eye-view Perception A Review, Evaluation and Recipe.pdf*2223200*1693605148",14974074,""])
D.p(["Z:/UofA/PhD/Literature/preprocessing*0*1656263294","Scale-space and edge detection using anisotropic diffusion tpami90.pdf*1302293*1497480776",1302293,""])
D.p(["Z:/UofA/PhD/Literature/pruning*0*1656263296","A comprehensive survey on model compression and acceleration aireview20.pdf*2431973*1590445953","A Survey of Model Compression and Acceleration for Deep Neural Networks ax1710.09282.pdf*771546*1590446014","ECC Platform-Independent Energy-Constrained Deep Neural Network Compression via a Bilinear Regression Model cvpr19.pdf*474373*1581432503","Importance Estimation for Neural Network Pruning_CVPR19.pdf*482618*1580746677","Learning Efficient Convolutional Networks through Network Slimming iccv17.pdf*556728*1581888808","Rethinking the Value of Network Pruning 1810.05270 iclr19.pdf*1810376*1581512205","Shallowing deep networks layer-wise pruning based on feature representations tpami18.pdf*1365365*1590437624","Structured Pruning of Neural Networks with Budget-Aware Regularization 1811.09332.pdf*3336864*1581483076","to_prune_or_not_to_prune_exploring_the_efficacy_of_pruning_for_model_compression.pdf*261390*1582747342",11491233,""])
D.p(["Z:/UofA/PhD/Literature/radar*0*1656263296","Real-Time Detection and Filtering of Chaff Clutter from Single-Polarization Doppler Radar Data  ams1305.pdf*7017241*1534966755",7017241,""])
D.p(["Z:/UofA/PhD/Literature/readings*0*1544472730",0,""])
D.p(["Z:/UofA/PhD/Literature/reconstruction*0*1656263296","69nR11VulTxwVYL1qfOjF.zip*20810489*1561420589","A Theory of Fermat Paths for Non-Line-Of-Sight Shape Reconstruction cvpr19.pdf*1043738*1561439204",21854227,""])
D.p(["Z:/UofA/PhD/Literature/registration*0*1666286513","A training-free recursive multiresolution framework for diffeomorphic deformable image registration 2202.00675 AI22.pdf*8687617*1644856256","An Unsupervised Learning Model for Deformable Medical Image Registration cvpr18.pdf*1265021*1536253478","Deep Image Homography Estimation ax1606.pdf*8611171*1518832871","Deformable Convolutional Networks iccv17.pdf*1629218*1536253477","DRMIME Differentiable Mutual Information and Matrix Exponential for Multi-Resolution Image Registration ax2001.09865.pdf*656575*1586884661","End-to-end weakly-supervised semantic alignment ax1712 cvpr18.pdf*6359779*1536340026","Homography Estimation from Image Pairs with Hierarchical Convolutional Networks iccv17.pdf*2176165*1651684508","Homography Estimation using  Deep Learning for Registering All- 22 Football Video Frames thesis17.pdf*1039636*1518832871","Inverse Compositional Spatial Transformer Networks ax1612.pdf*1049267*1523467135","MINE Mutual Information Neural Estimation ax1801.04062 icml18.pdf*1982601*1586886045","Robust Projective Template Matching tis1610.pdf*7887009*1518829910","SRHEN Stepwise-Refining Homography Estimation Network via Parsing Geometric Correspondences in Deep Latent Space 201012.pdf*2620881*1651684585","Unsupervised Deep Homography A Fast and Robust Homography Estimation Model ax171229.pdf*1163512*1518832871","Unsupervised Deformable Image Registration with Fully Connected Generative Neural Network midl18.pdf*1515487*1588108396","Unsupervised deformable image registration with fully connected generative neural network.pdf*1500626*1545427882","Unsupervised diﬀeomorphic cardiac image registration using parameterization of the deformation ﬁeld 2208.13275 bibm22.pdf*7187465*1666277542","WILDCAT Weakly Supervised Learning of Deep ConvNets for Image Classiﬁcation, Pointwise Localization and Segmentation cvpr17.pdf*2411495*1521479953",57743525,"204*205"])
D.p(["Z:/UofA/PhD/Literature/registration/3d*0*1656263297","DeepI2P Image-to-Point Cloud Registration via Deep Classiﬁcation 2104.03501.pdf*1839216*1639284015",1839216,""])
D.p(["Z:/UofA/PhD/Literature/registration/camera_motion_estimation*0*1656263298","Estimating Camera Tilt from Motion without Tracking crv17.pdf*616750*1499364260","Motion from 2D Image Sequences ch9.pdf*447037*1551037332","ROBUST CAMERA MOTION ESTIMATION IN VIDEO SEQUENCES.pdf*2274737*1551037336","Unsupervised Camera Motion Estimation and Moving Object Detection in Videos RzDimvip06.pdf*908609*1551037340",4247133,""])
D.p(["Z:/UofA/PhD/Literature/regression*0*1656263298","A mixed-scale dense convolutional neural network for image analysis pnas1901.pdf*1139300*1546907090","DenseReg Fully Convolutional Dense Shape Regression In-the-Wild ax1803.02188.pdf*7775310*1546907341","Half-CNN A General Framework for Whole-Image Regression .pdf*939242*1546921149",9853852,""])
D.p(["Z:/UofA/PhD/Literature/reinforcement_learning*0*1656263300",0,"208*209*210*211*212*213*214*215*216*217"])
D.p(["Z:/UofA/PhD/Literature/reinforcement_learning/actor-critic*0*1656263298","Linear off-policy actor-critic icml12.pdf*2280910*1520129868","Off-Policy Actor-Critic ax1306.pdf*1613027*1540237659",3893937,""])
D.p(["Z:/UofA/PhD/Literature/reinforcement_learning/bqn*0*1656263298","Bayesian Q-learning aaai98.pdf*119474*1520463283","Bayesian Q-learning with Assumed Density Filtering ax1712 nipsw17.pdf*4786835*1540237659",4906309,""])
D.p(["Z:/UofA/PhD/Literature/reinforcement_learning/control*0*1656263298","A combined reactive and reinforcement learning controller for an autonomous tracked vehicle sd ras12.pdf*1941804*1518832875","Coordinated learning based on time-sharing tracking framework and Gaussian regression for continuous multi-agent systems sd eaai15.pdf*821843*1518832876","Model-Based Reinforcement Learning for Infinite-Horizon Approximate Optimal Tracking  tnnls17.pdf*461637*1494339410","Model-based reinforcement learning in differential graphical games ax17_2.pdf*3169938*1518832876","Model-free linear quadratic tracking control for unmanned helicopters using reinforcement learning icara11.pdf*368247*1494339172","Optimal control of eye-movements during visual search ax17_4.pdf*8560944*1518832876",15324413,""])
D.p(["Z:/UofA/PhD/Literature/reinforcement_learning/imperfect_models*0*1656263299","Reinforcement Learning with Misspeciﬁed Model Classes icra13_mit.pdf*745946*1523479176",745946,""])
D.p(["Z:/UofA/PhD/Literature/reinforcement_learning/misc*0*1656263299","A new reinforcement learning vehicle control architecture for vision-based road following  tvt00.pdf*449397*1494424245","A Tutorial on Thompson Sampling ax1711.pdf*2161763*1540237659","Combining Deep Reinforcement Learning and Safety Based Control for Autonomous Driving ax16_12.pdf*508134*1494526774","Cross-entropy method - Wikipedia.mht*316866*1485847210","Deep reinforcement learning with visual attention for vehicle classification  tcds16.pdf*3269141*1494365996","Deep spatial autoencoders for visuomotor learning  icra16.pdf*3250827*1494366194","Deep Spatial Autoencoders for Visuomotor Learning ax16_3.pdf*3092643*1518832880","Ensemble Learning for Object Recognition and Tracking sl 11.pdf*613013*1518832880","Online Evolution of Deep Convolutional Network for Vision-Based Reinforcement Learning sl sab14.pdf*1460327*1518832880","Predicting Future Agent Motions for Dynamic Environments  icmla16.pdf*1166192*1494365853","Reinforcement learning for hierarchical and modular neural network in autonomous robot navigation  jcnn03.pdf*414309*1494424801","Self-learning navigation algorithm for vision-based mobile robots using machine learning algorithms jmst11.pdf*891383*1494439276","The Linear Quadratic Tracking Problem.pdf*1649651*1494339017",19243646,""])
D.p(["Z:/UofA/PhD/Literature/reinforcement_learning/navigation*0*1656263299","DeepTraffic Crowdsourced Hyperparameter Tuning of Deep Reinforcement Learning Systems for Multi-Agent Dense Traffic Navigation ax190103.pdf*2266651*1552448911",2266651,""])
D.p(["Z:/UofA/PhD/Literature/reinforcement_learning/notes*0*1656263300","Classification-based Policy Iteration with a Critic icml11.pdf*9465*1546016489","Learning the Reward Function for a Misspecified Model ax1802.pdf*7705*1546016522","Model Regularization for Stable Sample Rollouts.uai2014.pdf*11416*1546016629",28586,""])
D.p(["Z:/UofA/PhD/Literature/reinforcement_learning/survey*0*1656263300","A Short Tutorial on Reinforcement Learning iip05.pdf*367310*1494425016","New Trends in Robotic Reinforcement Learning Single and Multi-robot Case SL 09.pdf*1267289*1518832874","Reinforcement learning in feedback control ml11.pdf*1740047*1540237660","Reinforcement Learning in Robotics A Survey sl 12.pdf*1704215*1518832874","Reinforcement Learning in Robotics A Survey SL 14.pdf*1772154*1518832874","Reinforcement learning, conditioning, and the brain Successes and challenges sl cabn12_09.pdf*260360*1494515655","Survey of Model-Based Reinforcement Learning Applications on Robotics sl jirs17.pdf*1474164*1518832875",8585539,""])
D.p(["Z:/UofA/PhD/Literature/reinforcement_learning/target_following*0*1656263300","Robotic Target Tracking with Approximation Space-Based Feedback During Reinforcement Learning SL 07.pdf*601177*1518832881","Target following for an autonomous underwater vehicle using regularized ELM-based reinforcement learning  oceans15.pdf*707335*1494366488",1308512,""])
D.p(["Z:/UofA/PhD/Literature/reinforcement_learning/unsorted*0*1656263303","A self-organizing neural architecture integrating desire, intention and reinforcement learning sd nc10.pdf*594315*1518832871","Algorithms for inverse reinforcement learning icml00.pdf*233304*1494859968","APPRENTICESHIP LEARNING AND REINFORCEMENT LEARNING WITH APPLICATION TO ROBOTIC CONTROL thesis08.pdf*26248628*1485847319","Apprenticeship Learning via Inverse Reinforcement Learning icml04.pdf*213808*1494859977","Bayesian Nonparametric Inverse Reinforcement Learning sl ecmlpkdd12.pdf*339194*1518832872","Behavior Adaptation by Means of Reinforcement Learning SL12.pdf*1950092*1518832872","Building Machines That Learn and Think Like People arxiv16_11.pdf*3756091*1518832872","Control policy with autocorrelated noise in reinforcement learning for robotics ijmlc15.pdf*2045293*1520117425","Density Matching Reward Learning ax16_8.pdf*1259749*1518832872","Effective learning in dynamic environments by explicit context tracking sl ecml93.pdf*1043198*1494439005","Evolution and Learning in an Intrinsically Motivated Reinforcement Learning Robot sl ecal07.pdf*411718*1518832873","Fast gradient-descent methods for temporal-difference learning with linear function approximation icml09.pdf*387319*1520132000","Fuzzy Policy Reinforcement Learning in Cooperative Multi-robot Systems sl jirs07.pdf*732926*1518832873","Gradient Estimation Using Stochastic Computation Graphs arxiv16_1.pdf*446967*1518832873","High-Dimensional Continuous Control Using Generalized Advantage Estimation arxiv 16_9.pdf*1709119*1518832873","Hindsight Experience Replay ax180223.pdf*2464277*1521385633","Incorporating Expert Advice into Reinforcement Learning Using Constructive Neural Networks sl cnn09.pdf*399226*1518832873","Learning and Querying Fast Generative Models for Reinforcement Learning 1802.pdf*1628393*1519953097","Learning Grammars for Architecture-Specific Facade Parsing.IJCV-2016-Gadde-et-al.pdf*22589530*1517333240","Learning to Navigate in Complex Environments ax170113.pdf*4826749*1540237658","Learning What Data to Learn ax17_2.pdf*599254*1494527831","Model-free reinforcement learning with continuous action in practice acc12.pdf*1247927*1520129825","Multi-agent Reinforcement Learning An Overview SL 10.pdf*531782*1518832873","Neural Turing Machines arxiv14_12.pdf*1361497*1518832874","Online Learning of a Memory for Learning Rates ax1710.pdf*938166*1540237658","Online Q-Learning using Connectionist Systems 94.pdf*310002*1495923637","Policy gradient methods for reinforcement learning with function approximation nips99.pdf*1541309*1498518199","Reinforcement Learning Neural Turing Machines - Revised arxiv16_1.pdf*970380*1518832874","Reinforcement Learning with Neural Networks Tricks of the Trade sl13.pdf*470015*1518832874","Reinforcement Learning with Self-Modifying Policies sl ltl98.pdf*0*1494516766","Reinforcement Learning with Unsupervised Auxiliary Tasks ax1611.pdf*7734643*1540237659","Reluctant Reinforcement Learning sl rdis14.pdf*2064487*1518832875","Self-organizing Neural Architecture for Reinforcement Learning sl isnn06.pdf*402007*1518832875","Simple statistical gradient-following algorithms for connectionist reinforcement learning ml92.pdf*318332*1494591646","Toward off-policy learning control with function approximation icml10.pdf*358731*1520132184","Trust Region Policy Optimization arxiv16_6.pdf*1028171*1518832875","Using Advice to Transfer Knowledge Acquired in One Reinforcement Learning Task to Another sl ecml05.pdf*445300*1518832875",93601899,""])
D.p(["Z:/UofA/PhD/Literature/research_data*0*1700678139","global_options.tjglobal*115722*1700589636","phd_literature_readings.tjexp*34525184*1700589619","user_settings.juser*486628*1700589630",35127534,""])
D.p(["Z:/UofA/PhD/Literature/RNN*0*1656263306","A Clockwork RNN ax1402.pdf*743435*1538244709","A Critical Review of Recurrent Neural Networks for Sequence Learning.pdf*926228*1455212192","A Recurrent Latent Variable Model for Sequential Data ax1506.pdf*950165*1540237660","A Theoretically Grounded Application of Dropout in Recurrent Neural Networks ax1610.pdf*1649698*1540237642","Adaptive Computation Time for Recurrent Neural Networks ax1603.08983.pdf*6585104*1540237660","An Empirical Exploration of Recurrent Network Architectures icml15.pdf*217041*1494602385","Conditional Random Fields as Recurrent Neural Networks  iccv15.pdf*1816850*1453229464","Generalization without systematicity On the compositional skills of sequence-to-sequence recurrent networks ax1802121.pdf*318326*1519933723","Grid Long Short-Term Memory ax1507.pdf*805738*1540237660","Learning Fast Approximations of Sparse Coding-icml-10.pdf*226490*1455208944","Learning long-term dependencies with gradient descent is difficult tnn94.pdf*1029583*1494598035","LEARNING STOCHASTIC RECURRENT NETWORKS x1503.pdf*2164344*1540237660","Long-term recurrent convolutional networks for visual recognition and description cvpr15.pdf*1632669*1494591377","neural machine translation by jointly learning to align and translate 1409.0473.pdf*444482*1655168172","Neural Programmer Inducing Latent Programs with Gradient Descent  ax1511.04834.pdf*580638*1540237661","Neural Turing Machines ax1410.5401.pdf*1361503*1540237661","Recurrent nets that time and count IJCNN2000.pdf*206047*1494599546","Recurrent Network Models for Human Dynamics  iccv15.pdf*2840636*1498656256","Still not systematic after all these years On the compositional skills of sequence-to-sequence recurrent networks 1710.pdf*358819*1540237643","Structural-RNN Deep Learning on Spatio-Temporal Graphs cvpr16 ax16_4.pdf*1641627*1495483296","Training Recurrent Neural Networks phd_thesis13.pdf*3400650*1541901818","Visualizing and Understanding Recurrent Networks ax15_11.pdf*2989155*1518832884",32889228,"220*221*222*223*224*225"])
D.p(["Z:/UofA/PhD/Literature/RNN/attention*0*1656263304","Recurrent Models of Visual Attention arxiv14_6.pdf*710013*1518832883","Show, Attend and Tell Neural Image Caption Generation with Visual Attention ax15_2.pdf*9582524*1494602451",10292537,""])
D.p(["Z:/UofA/PhD/Literature/RNN/BRNN*0*1656263304","Bidirectional Recurrent Neural Networks TSP97.pdf*230139*1624809375",230139,""])
D.p(["Z:/UofA/PhD/Literature/RNN/ConvLSTM*0*1656263305","Convolutional LSTM Network A Machine Learning Approach for Precipitation Nowcasting nips15.pdf*422057*1571882409",422057,""])
D.p(["Z:/UofA/PhD/Literature/RNN/generative*0*1656263305","DRAW A Recurrent Neural Network For Image Generation 1505.pdf*1929840*1538244799","Show, Attend and Tell Neural Image Caption Generation with Visual Attention ax1502.pdf*9582524*1538244816",11512364,""])
D.p(["Z:/UofA/PhD/Literature/RNN/GRU*0*1656263306","Depth-Gated Recurrent Neural Networks ax1508.pdf*196245*1540237661","Empirical Evaluation of Gated Recurrent Neural Networks on Sequence Modeling ax1412 nips14.pdf*686132*1540237661","Empirical Evaluation of Gated Recurrent Neural Networks on Sequence Modeling.pdf*686133*1540237661","Gated Feedback Recurrent Neural Networks.pdf*1644287*1540237661","Learning Phrase Representations using RNN Encoder-Decoder ax14_9 (GRU).pdf*1145965*1518832882","Learning Phrase Representations using RNN Encoder-Decoder for Statistical Machine Translation emnlp14.pdf*1145962*1540237662","On the Properties of Neural Machine Translation Encoder-Decoder Approaches ax1410 ssst8.pdf*364541*1538188694",5869265,""])
D.p(["Z:/UofA/PhD/Literature/RNN/LSTM*0*1656263306","Convolutional LSTM Network A Machine Learning Approach for Precipitation Nowcasting nips15.pdf*430304*1573704768","Grid Long Short-Term Memory ax15_7.pdf*805738*1518832882","LONG SHORT-TERM MEMORY jnc97.pdf*396938*1494598140","LSTM A Search Space Odyssey ax15_3.pdf*1509329*1494602378","LSTM A Search Space Odyssey ax1710.pdf*2667990*1540237662","Propagating LSTM 3D Pose Estimation based on Joint Interdependency_eccv18.pdf*1204723*1538354722","Recurrent Batch Normalization ax1603.09025.pdf*618075*1540237662","Sequence to sequence learning with neural networks nips14.pdf*112084*1553143565","Unsupervised Learning of Video Representations using LSTMs ax1502.04681 icml15.pdf*2294111*1553143754","Video (language) modeling a baseline for generative models of natural videos ax1412.6604.pdf*652053*1553143830",10691345,""])
D.p(["Z:/UofA/PhD/Literature/sensor_fusion*0*1656263307","Automatic registration of lidar and optical images of urban scenes cvpr09.pdf*5479515*1527740606","AVM  LiDAR sensor based lane marking detection method for automated driving on complex urban roads  ivs17.pdf*759902*1527611663","Deep Learning for Person Detection in Multi-Spectral Videos mscthes17.pdf*14169574*1540237616","Deep Multi-Sensor Lane Detection 1905.01555.pdf*8943503*1631201553","Fusion of color images and LiDAR data for lane classification acm2015.pdf*444002*1540237666","FusionLane Multi-Sensor Fusion for Lane Marking Semantic Segmentation Using Deep Neural Networks 2003.04404.pdf*6022213*1631198270","Multi-channel lidar processing for lane detection and estimation  its09.pdf*1557231*1527611704","Object Detection from a Vehicle using Deep Learning Network  and Future Integration with Multi-Sensor Fusion Algorithm 17.pdf*660591*1525993694",38036531,""])
D.p(["Z:/UofA/PhD/Literature/SLAM*0*1656263320","DeepTAM Deep Tracking and Mapping  1808.01900.pdf*9451724*1540237666","Efficient ConvNet Feature Extraction with Multiple RoI Pooling for Landmark-based Visual Localization of Autonomous Vehicles mis17.pdf*4516564*1532727302","gradSLAM Dense SLAM meets Automatic Differentiation 1910.10672 icra20.pdf*4272901*1591305798",18241189,""])
D.p(["Z:/UofA/PhD/Literature/SOT*0*1656263320",".gitignore*248*1589314829","Bridging the Gap Between Detection and Tracking A Unified Approach iccv19.pdf*1390690*1588189453","Deep Meta Learning for Real-Time Target-Aware Visual Tracking iccv19.pdf*2124498*1589954148","Joint Group Feature Selection and Discriminative Filter Learning for Robust Visual Object Tracking iccv19.pdf*1716260*1587416969","Ocean Object-aware Anchor-free Tracking 2006.10721 eccv20.pdf*2885437*1623089784","Patch-Based Tracking.png*26242*1533012634","Physical Adversarial Textures That Fool Visual Object Tracking iccv19.pdf*1498762*1587408592","recent_Tracker_development.png*497561*1587356637","Skimming-Perusal Tracking A Framework for Real-Time and Robust Long-Term Tracking iccv19.pdf*1635082*1587417366",11774780,"229*230*231*232*233*234*235*241*242*243*244*245*246*247*248*250*251*252*253*254*255*256*257*258"])
D.p(["Z:/UofA/PhD/Literature/SOT/3d*0*1656263307","3D Pose Tracking Using a Recovered 3D Model jcsc18_ws.pdf*5129841*1540237667","A Direct 3D Object Tracking Method Based on Dynamic Textured Model Rendering and Extended Dense Feature Fields tcsvt1707.pdf*2008527*1523551148","Fast and Furious Real Time End-to-End 3D Detection, Tracking and Motion Forecasting with a Single Convolutional Net_cvpr18.pdf*1586823*1537337926",8725191,""])
D.p(["Z:/UofA/PhD/Literature/SOT/adversarial*0*1656263308","Adversarial Feature Sampling Learning for Efficient Visual Tracking ax1809.04741.pdf*1871552*1538068478","SINT++ Robust Visual Tracking via Adversarial Positive Instance Generation _cvpr18.pdf*1370789*1537337967","VITAL VIsual Tracking via Adversarial Learning_cvpr18.pdf*1638992*1537338035",4881333,""])
D.p(["Z:/UofA/PhD/Literature/SOT/attention*0*1656263308","Learning Attentional Policies for Tracking and Recognition in Video icml11.pdf*1830380*1525991662",1830380,""])
D.p(["Z:/UofA/PhD/Literature/SOT/camera*0*1656263308","End-to-end Active Object Tracking and Its Real-world Deployment via Reinforcement Learning 1808.03405 icml18.pdf*8027046*1540237668",8027046,""])
D.p(["Z:/UofA/PhD/Literature/SOT/color*0*1656263308","In Defense of Color-based Model-free Tracking cvpr15.pdf*3170373*1558295400",3170373,""])
D.p(["Z:/UofA/PhD/Literature/SOT/correlation*0*1656263311",".gitignore*243*1589396414","ATOM Accurate Tracking by Overlap Maximization ax1811.07628 cvpr19.pdf*3696739*1564689656","Beyond Correlation Filters Learning Continuous Convolution Operators for Visual Tracking eccv16 ax16_8.pdf*1850661*1499649149","Context-Aware Correlation Filter Tracking_cvpr17.pdf*1240598*1537338439","Convolutional features for correlation ﬁlter based visual tracking iccvw15.pdf*1453232*1499649358","Correlation Filters with Limited Boundaries cvpr15 ax1403.7876.pdf*1382701*1586665510","Correlation Tracking via Joint Discrimination and Reliability Learning_cvpr18.pdf*1097904*1537338054","Correlation Tracking via Robust Region Proposals  ax1806.06418 iet18.pdf*1142550*1538103668","D3S – A Discriminative Single Shot Segmentation Tracker 1911.08862v1 cvpr20.pdf*8876878*1589395493","DCFNet Discriminant Correlation Filters Network for Visual Tracking ax1704.04057.pdf*361970*1655355847","DiMP Learning Discriminative Model Prediction for Tracking ax1904.07220 iccv19.pdf*1423285*1589142655","Discriminative Correlation Filter with Channel and Spatial Reliability 1611.08461 ijcv17.pdf*13068271*1655246446","ECO Efficient Convolution Operators for Tracking cvpr17 ax17_4.pdf*2542308*1655355847","ECO Efﬁcient Convolution Operators for Tracking_cvpr17.pdf*1654155*1538357038","End-to-end Flow Correlation Tracking with Spatial-temporal Attention _cvpr18.pdf*1357797*1537337903","High-speed Tracking with Multi-kernel Correlation Filters  ax1806.05530 cvpr18.pdf*396821*1538103772","High-speed Tracking with Multi-kernel Correlation Filters_cvpr18.pdf*1496511*1537337973","Joint Representation and Truncated Inference Learning for Correlation Filter based Tracking  ax1807.11071.pdf*898142*1540237669","Joint Representation and Truncated Inference Learning for Correlation Filter based Tracking_eccv18.pdf*1252792*1538354803","Learning Aberrance Repressed Correlation Filters for Real-Time UAV Tracking iccv19.pdf*2195059*1587414863","Learning Adaptive Discriminative Correlation Filters via Temporal Consistency Preserving Spatial Feature Selection for Robust Visual Tracking  ax1807.11348.pdf*7730490*1540237669","Learning Background-Aware Correlation Filters for Visual Tracking_iccv17.pdf*1865147*1538067285","Learning Spatially Regularized Correlation Filters for Visual Tracking iccv16.pdf*2752733*1586718963","Learning Spatial-Temporal Regularized Correlation Filters for Visual Tracking_cvpr18.pdf*1575031*1587098843","Long-term Correlation Tracking cvpr15.pdf*3310140*1495374447","Multi-Cue Correlation Filters for Robust Visual Tracking_cvpr18.pdf*1587269*1537337951","Multi-task Correlation Particle Filter for Robust Object Tracking cvpr17.pdf*1668028*1531923357","Overview and methods of correlation filter algorithms in object tracking sl2021.pdf*6329697*1655245207","Part-based Visual Tracking via Structural Support Correlation Filter  ax1805.09971.pdf*7862240*1540237669","PrDiMP Probabilistic Regression for Visual Tracking ax2003.12565 cvpr20.pdf*8845266*1587415893","Robust visual tracking using joint scale-spatial correlation filters icip15.pdf*770222*1478589263","State-aware Anti-drift Robust Correlation Tracking  ax1806.10759.pdf*723448*1540237669","Visual Object Tracking using Adaptive Correlation Filters cvpr10.pdf*3685632*1655247656","Visual Tracking via Spatially Aligned Correlation Filters Network_eccv18.pdf*1170620*1538354807",97264580,""])
D.p(["Z:/UofA/PhD/Literature/SOT/deep_learning*0*1656263313","CNNTracker Online discriminative object tracking via deep convolutional neural network ASC16.pdf*5165285*1540237669","Context-aware Deep Feature Compression for High-speed Visual Tracking_cvpr18.pdf*1407664*1537338047","CREST Convolutional Residual Learning for Visual Tracking_iccv17.pdf*1675046*1538067320","Deep Learning of Appearance Models for Online Object Tracking ax16_7.pdf*841309*1495243205","Deep Metric Learning for Visual Tracking tcsvt16_11.pdf*4746723*1478589289","Fast Dynamic Convolutional Neural Networks for Visual Tracking  ax1807.03132.pdf*3903605*1540237670","Learning a deep compact image representation for visual tracking nips13.pdf*1775704*1540237670","LEARNING A REAL-TIME GENERIC TRACKER USING CONVOLUTIONAL NEURAL NETWORKS ICME2017.pdf*1248621*1494605244","Learning Dynamic Memory Networks for Object Tracking_eccv18.pdf*710552*1538354759","Learning Multi-Domain Convolutional Neural Networks for Visual Tracking cvpr16 ax16_1.pdf*2856679*1494591085","Learning Policies for Adaptive Tracking With Deep Feature Cascades_iccv17.pdf*1613795*1538067241","Learning Policies for Adaptive Tracking With Deep Feature Cascades_supplemental_iccv17.zip*4706119*1538067247","Learning regression and verification networks for long-term visual tracking ax1809.04320.pdf*398030*1538068506","Learning Spatial-Aware Regressions for Visual Tracking_cvpr18.pdf*916583*1537338025","Localization-based Visual Tracking with Convolutional Neural Networks icee16.pdf*563998*1478589316","Meta-Tracker Fast and Robust Online Adaptation for Visual Object Trackers 1801.03049 eccv18.pdf*6361450*1587184626","Meta-Tracker Fast and Robust Online Adaptation for Visual Object Trackers_eccv18.pdf*1456015*1538354820","Modeling and Propagating CNNs in a Tree Structure for Visual Tracking arxiv16 (vot16 winner).pdf*8702156*1484168848","Once for All a Two-flow Convolutional Neural Network for Visual Tracking ax16_4.pdf*815694*1540237670","Online Object Tracking Based on CNN with Metropolis-Hasting Re-Sampling acm mm15_9.pdf*519492*1495243865","Online video tracking using collaborative convolutional networks  icme16_7.pdf*831981*1478589364","Robust Object Tracking Based on Temporal and Spatial Deep Networks_iccv17.pdf*837503*1538067296","Robust Visual Tracking via Convolutional Networks ax15_8.pdf*4341064*1494605180","Robust Visual Tracking via Convolutional Networks Without Training  tip16_4.pdf*6313757*1494605138","Stochastic Channel Decorrelation Network and Its Application to Visual Tracking  ax1807.01103.pdf*1036939*1538071775","Unveiling the Power of Deep Tracking ax1804.06833 eccv18.pdf*1318540*1579917076","Visual tracking with VG-RAM Weightless Neural Networks sd nc16_3.pdf*6720887*1540237671",71785191,"236*237*238*239*240"])
D.p(["Z:/UofA/PhD/Literature/SOT/deep_learning/laser*0*1656263312","Deep tracking in the wild End-to-end tracking using recurrent neural networks IJRR1702.pdf*5731190*1531435531",5731190,""])
D.p(["Z:/UofA/PhD/Literature/SOT/deep_learning/old*0*1656263312","Design-and-Implementation-of-a-Neural-Network-for-Real-Time-Object-Tracking 2007.pdf*640270*1465508389",640270,""])
D.p(["Z:/UofA/PhD/Literature/SOT/deep_learning/point_cloud*0*1656263312","Deconvolutional Networks for Point-Cloud Vehicle Detection and Tracking in Driving Scenarios  1808.07935.pdf*7015718*1540237671",7015718,""])
D.p(["Z:/UofA/PhD/Literature/SOT/deep_learning/review*0*1656263313","A Review of Visual Tracking with Deep Learning aiie16.pdf*1700060*1525990541",1700060,""])
D.p(["Z:/UofA/PhD/Literature/SOT/deep_learning/transfer*0*1656263313","Online tracking by learning discriminative saliency map with convolutional neural network icml15 ax15.pdf*3777263*1540237671","Transfer learning based visual tracking with Gaussian processes regression eccv14.pdf*730719*1540237671","Transferring Rich Feature Hierarchies for Robust Visual Tracking ax15_4.pdf*2084996*1540237671",6592978,""])
D.p(["Z:/UofA/PhD/Literature/SOT/gaze*0*1656263313","Monocular Free-Head 3D Gaze Tracking With Deep Learning and Geometry Constraints_iccv17.pdf*1473025*1538067838","Real Time Eye Gaze Tracking With 3D Deformable Eye-Face Model_iccv17.pdf*1428449*1538067805",2901474,""])
D.p(["Z:/UofA/PhD/Literature/SOT/misc*0*1656263313","An enhanced adaptive coupled-layer LGTracker ++ iccv13.pdf*643543*1465514035","Combined Image- and World-Space Tracking in Traffic Scenes ax1809.07357.pdf*10852029*1538068438","Compressive perceptual hashing tracking sd nc17_5.pdf*8234544*1518832887","Learning to Update for Object Tracking ax1806.07078.pdf*1368054*1540237672","Non-Rigid Object Tracking via Deformable Patches Using Shape-Preserved KCF and Level Sets_iccv17.pdf*998595*1538067379","One-Class Multiple Instance Learning and Applications to Target Tracking sdl accv12.pdf*2234696*1518832887","Parallel Tracking and Verifying A Framework for Real-Time and High Accuracy Visual Tracking_iccv17.pdf*1661986*1538356495","Robust Tracking via Weighted Online Extreme Learning Machine 1807.10211.pdf*669101*1540237673","Staple Complementary Learners for Real-Time Tracking ax16_4.pdf*1572203*1518832887","Tracking millions of humans in crowded spaces.pdf*6610749*1537337521","Tracking with General Regression mva2008.pdf*609481*1465501741","Tracking-by-Segmentation with Online Gradient Boosting Decision Tree iccv15.pdf*2874709*1494605793","Understanding and Diagnosing Visual Tracking Systems arxiv15.pdf*730315*1518832888","Visual Object Tracking The Initialisation Problem  ax1805.01146 crv18.pdf*1006456*1538104887","Visual tracking with sparse correlation filters  icip16.pdf*474308*1518832888",40540769,""])
D.p(["Z:/UofA/PhD/Literature/SOT/motion*0*1656263314","Detection free tracking Exploiting motion and topology for segmenting and tracking under entanglement cvpr11.pdf*2816576*1498656037","Two-granularity tracking Mediating trajectory and detection graphs for tracking under occlusions eccv12.pdf*4993497*1498656037",7810073,""])
D.p(["Z:/UofA/PhD/Literature/SOT/notes*0*1656263314","Action-Decision_Networks_for_Visual_Tracking_with_Deep_Reinforcement_Learning_cvpr17.pdf*10483774*1499809338","ATOM Accurate Tracking by Overlap Maximization ax1811.07628 cvpr19.pdf*3174*1564684101","Bridging the Gap Between Detection and Tracking A Unified Approach iccv19.pdf*196896*1588710188","D3S – A Discriminative Single Shot Segmentation Tracker 1911.08862v1 cvpr20.pdf*193913*1589395834","Deep_Reinforcement_Learning_for_Visual_Object_Tracking_in_Videos.pdf*8915143*1498691792","DiMP Learning Discriminative Model Prediction for Tracking ax1904.07220 iccv19.pdf*196094*1589314938","High Performance Visual Tracking with Siamese Region Proposal Network_cvpr18.pdf*187139*1558301496","Siam R-CNN Visual Tracking by Re-Detection 1911.12836 cvpr20.pdf*195926*1588710208","SiameseFC.pdf*3242*1561473661","Visual_Tracking_by_Reinforced_Decision_Making_ax17.pdf*6244734*1498691818",26620035,""])
D.p(["Z:/UofA/PhD/Literature/SOT/particle_filter*0*1656263314","Learning to track on-the-fly using a particle filter with annealed- weighted QPSO modeled after a singular Dirac delta potential  1806.01396.pdf*1478456*1538104639",1478456,""])
D.p(["Z:/UofA/PhD/Literature/SOT/recurrent_neural_networks*0*1656263314","Deep Tracking on the Move Learning to Track the World from a Moving Vehicle using Recurrent Neural Networks ax1704.pdf*801624*1540237681","Deep Tracking Seeing Beyond Seeing Using Recurrent Neural Networks ax16_3 aaai16_2.pdf*440840*1496896484","Deep Tracking Seeing Beyond Seeing Using Recurrent Neural Networks ax1602 aaai16.pdf*440840*1531435598","First Step toward Model-Free, Anonymous Object Tracking with Recurrent Neural Networks ax15_11.pdf*876794*1540237681","RATM Recurrent Attentive Tracking Model ax16_4.pdf*6642530*1540237681","Re3 Real-Time Recurrent Regression Networks for Object Tracking ax17_3.pdf*5200945*1540237682","Spatially Supervised Recurrent Convolutional Neural Networks for Visual Object Tracking ax1607.05781 iscas17.pdf*3998165*1552960125",18401738,""])
D.p(["Z:/UofA/PhD/Literature/SOT/registration*0*1656263315","[27] Scale-space and edge detection using anisotropic diffusion tpami90.lnk*2226*1497555866","Deep 6-DOF Tracking ax1708 tvcg17.pdf*8201637*1540237678","Illumination Insensitive Efficient Second-order Minimization for Planar Object Tracking icra17.pdf*6110225*1518832890","Robust Tracking of Planar Objects in Low Light and Sudden Illumination Changes 3dv16.pdf*9600527*1497483461","Subpixel-Precise Tracking of Rigid Objects in Real-time  1807.01952.pdf*9606075*1538071689",33520690,""])
D.p(["Z:/UofA/PhD/Literature/SOT/reinforcement_learning*0*1656263315","Action-Decision Networks for Visual Tracking with Deep Reinforcement Learning  cvpr17 supplementary.pdf*1566786*1499648231","Action-Decision Networks for Visual Tracking with Deep Reinforcement Learning  cvpr17.pdf*1980233*1540237679","Action-Driven Visual Object Tracking With Deep Reinforcement Learning tnnls1806.pdf*3603443*1533012631","Deep Reinforcement Learning for Visual Object Tracking in Videos ax17_4.pdf*2457632*1540237679","Deep Reinforcement Learning with Iterative Shift for Visual Tracking_eccv18.pdf*1382624*1538354833","Dual-Agent Deep Reinforcement Learning for Deformable Face Tracking_eccv18.pdf*3870816*1538354832","End-to-end Active Object Tracking via Reinforcement Learning ax17_5.pdf*973171*1498695233","Hyperparameter Optimization for Tracking with Continuous Deep Q-Learning_cvpr18.pdf*1941928*1537337891","Real-time 'Actor-Critic' Tracking_eccv18.pdf*1225261*1538354797","Reinforcement Learning for Robust and Efficient Real-World Tracking icpr10.pdf*704122*1494339240","Tracking as Online Decision-Making Learning a Policy From Streaming Videos With Reinforcement Learning_iccv17.pdf*871675*1538356780","Visual Tracking by Reinforced Decision Making ax17_2.pdf*4717085*1540237680",25294776,"249"])
D.p(["Z:/UofA/PhD/Literature/SOT/reinforcement_learning/misc*0*1656263315","Active tracking and pursuit under different levels of occlusion a two-layer approach sl mva14.pdf*1310686*1540237680","Cooperative target searching and tracking via UCT with probability distribution model  dsp16.pdf*357118*1494365746","Design and implementation of multi-robot cooperative tracking  cscwd10.pdf*192223*1494423142","Experimenting WNN support in object tracking systems sd nc16_3.pdf*4756430*1540237680","Policy gradient based Reinforcement Learning for real autonomous underwater cable tracking iros08.pdf*1094452*1494339375","Policy learning for autonomous feature tracking sl ar13.pdf*4597254*1540237680","Reinforcement learning of cooperative behaviors for multi-robot tracking of multiple moving targets  iros05.pdf*152260*1494364442","Reinforcement learning-based feature learning for object tracking  icpr04.pdf*437083*1494364500","Tracking strategy based on reinforcement learning and intention inference ccc14.pdf*517687*1494364081","Two steps natural actor critic learning for underwater cable tracking  icra10.pdf*796789*1494423047",14211982,""])
D.p(["Z:/UofA/PhD/Literature/SOT/review*0*1656263316","Advances in Deep Learning Methods for Visual Tracking Literature Review and Fundamentals IJAC21 sl.pdf*1426483*1651521697","Deep Learning for Visual Tracking A Comprehensive Survey 1912.00535 tits210128.pdf*7094992*1651521819","Deep Learning in Visual Tracking A Review TNLS211230.pdf*5024239*1651522955","Siamese Visual Object Tracking A Survey ieee2108.pdf*2253243*1652318051","Single Object Tracking A Survey of Methods, Datasets, and Evaluation Metrics 2201.13066.pdf*1466742*1651521917","The Seventh Visual Object Tracking VOT2019 Challenge Results iccvw19.pdf*3188068*1587356498",20453767,""])
D.p(["Z:/UofA/PhD/Literature/SOT/rgb-d*0*1656263316","A Comparative Study of Registration Methods for RGB-D Video of Static Scenes sensors-14-08547.pdf*16711056*1540237678","Real-Time Hand Tracking Under Occlusion From an Egocentric RGB-D Sensor_iccv17.pdf*1370775*1538067304","Real-time Joint Tracking of a Hand Manipulating an Object from RGB-D Input eccv16.pdf*5208946*1516837066","Real-time RGB- D Tracking with Depth Scaling Kernelised Correlation Filters and Occlusion Handling bmvc15.pdf*546554*1516837032","RealtimeHO_ECCV2016_SM.pdf*2215845*1516837066","Robust Odometry Estimation for RGB-D Cameras icra13.pdf*968072*1540237679",27021248,""])
D.p(["Z:/UofA/PhD/Literature/SOT/segmentation*0*1656263316","Superpixel-based Tracking-by-Segmentation using Markov Chains_cvpr17.pdf*946758*1538357131",946758,""])
D.p(["Z:/UofA/PhD/Literature/SOT/sensor_fusion*0*1656263316","Cross-Modal Ranking with Soft Consistency and Noisy Labels for Robust RGB-T Tracking_eccv18.pdf*1183908*1538355823","End-to-end Learning of Multi-sensor 3D Tracking by Detection  1806.11534.pdf*7466812*1540237672","Real Time Lidar and Radar High-Level Fusion for Obstacle Detection and Tracking with evaluation on a ground truth  1807.11264.pdf*2353270*1540237672",11003990,""])
D.p(["Z:/UofA/PhD/Literature/SOT/siamese*0*1656263319",".gitignore*225*1588714763","A Twofold Siamese Network for Real-Time Object Tracking_cvpr18.pdf*2009104*1537337945","Deeper and Wider Siamese Networks for Real-Time Visual Tracking ax1901.01660 cvpr19.pdf*2835274*1578611238","DensSiam End-to-End Densely-Siamese Network with Self-Attention Model for Object Tracking  ax1809.02714.pdf*412130*1540237682","Distractor-aware Siamese Networks for Visual Object Tracking ax1808.06048 eccv18.pdf*2871033*1540237682","End-To-End Representation Learning for Correlation Filter Based Tracking cvpr17.pdf*543364*1516307469","Fast Online Object Tracking and Segmentation A Unifying Approach ax1812.05050 cvpr19.pdf*8182298*1558126637","Fully-Convolutional Siamese Networks for Object Tracking eccv16_9.pdf*1746918*1562301034","High Performance Visual Tracking with Siamese Region Proposal Network_cvpr18.pdf*819440*1558300539","Learning Attentions Residual Attentional Siamese Network for High Performance Online Visual Tracking _cvpr18.pdf*2674821*1537337960","Learning by tracking Siamese CNN for robust target association ax16_8.pdf*1230069*1540237682","Learning Dynamic Siamese Network for Visual Object Tracking_iccv17.pdf*4276223*1538067313","Learning the Model Update for Siamese Trackers iccv19.pdf*2173551*1590261190","Learning to Track at 100 FPS with Deep Regression Networks arxiv16.pdf*3108360*1540237670","Multi-Branch Siamese Networks with Online Selection for Object Tracking  ax1808.07349.pdf*2330828*1540237683","Once for All a Two-flow Convolutional Neural Network for Visual Tracking ax1604.07507.pdf*813302*1561242231","Siam R-CNN Visual Tracking by Re-Detection 1911.12836 cvpr20.pdf*6289335*1588445722","Siamese Instance Search for Tracking cvpr16 ax16_5.pdf*3985930*1494604921","siamrcnn-supp.zip*20252096*1588449151","SiamRPN++ Evolution of Siamese Visual Tracking with Very Deep Networks ax1812.11703 cvpr19.pdf*2060144*1564544533","SiamVGG Visual Tracking using Deeper Siamese Networks ax1902.02804.pdf*2531846*1578611227","Structured Siamese Network for Real-Time Visual Tracking_eccv18.pdf*1174651*1538354782","Triplet Loss in Siamese Network for Object Tracking_eccv18.pdf*2127691*1538354794","Understanding Siamese Networks for Visual Object Tracking msc thes 20.pdf*5117911*1655244485",79566544,""])
D.p(["Z:/UofA/PhD/Literature/SOT/trajectory*0*1656263319","Learning Social Etiquette Human Trajectory Prediction In Crowded Scenes eccv16.pdf*11901359*1495244803","PathTrack Fast Trajectory Annotation With Path Supervision_iccv17.pdf*1446424*1538067253","Social LSTM Human Trajectory Prediction in Crowded Spaces cvpr16.pdf*1868879*1495244752","Who are you with and where are you going cvpr11.pdf*931475*1518832890",16148137,""])
D.p(["Z:/UofA/PhD/Literature/SOT/transformers*0*1699661320","MMTrack Towards Unified Token Learning for Vision-Language Tracking tcsvt2308 2308.14103.pdf*2374545*1699993205","SeqTrack Sequence to Sequence Learning for Visual Object Tracking cvpr23.pdf*1312598*1699748422","Transformer Tracking cvpr21.pdf*1145000*1649875775",4832143,""])
D.p(["Z:/UofA/PhD/Literature/SOT/unsorted*0*1538358291",0,""])
D.p(["Z:/UofA/PhD/Literature/SOT/unsupervised*0*1656263320","Tracking Emerges by Colorizing Videos ax1806.09594 eccv18.pdf*1886196*1589573988","Unsupervised Deep Tracking ax1904.01828 cvpr19.pdf*2225755*1579409046",4111951,""])
D.p(["Z:/UofA/PhD/Literature/static_detection*0*1661454749",".gitignore*151*1577562793","EfficientDet_Scalable and efficient object detection.pdf*936364*1601747683","Generalized Intersection over Union A Metric and A Loss for Bounding Box Regression 1902.09630 cvpr19.pdf*4826377*1605897046","Objects as Points ax1904.07850.pdf*9113835*1596308857","Spatially Invariant Unsupervised Object Detection with Convolutional Neural Networks aaai19.pdf*698126*1591969146","SpineNet Learning Scale-Permuted Backbone for Recognition and Localization 1912.05027 cvpr20.pdf*2198445*1631193158","Towards Deeper Understanding of Camouﬂaged Object Detection 2205.11333 cvpr21.pdf*12466453*1653754538","Training Region-based Object Detectors with Online Hard Example Mining 1604.03540 cvpr16.pdf*965877*1651936190",31205628,"260*261*267*268*269*270*271*272*273*274*275*276*277*278*279*280*281*282*283*284*285*286*287*288*289*290*291*292*293*294*295*296*297*298*299*300*301*302"])
D.p(["Z:/UofA/PhD/Literature/static_detection/anchor_free*0*1656263322","Bottom-up object detection by grouping extreme and center points 1901.08043.pdf*10001679*1605160151","Bridging the Gap Between Anchor-based and Anchor-free Detection via Adaptive Training Sample Selection 1912.02424 cvpr20.pdf*1201473*1605900221","CornerNet Detecting Objects as Paired Keypoints ax1903 ijcv19.pdf*6980315*1576904948","End-to-End Object Detection with Transformers ax200528.pdf*7553519*1591935573","FCOS Fully Convolutional One-Stage Object Detection ax1908 iccv19.pdf*3348058*1577303638","Feature Selective Anchor-Free Module for Single-Shot Object Detection ax1903.00621 cvpr19.pdf*7895233*1577392417","FoveaBox Beyond Anchor-based Object Detector ax1904.03797.pdf*3101013*1576298466","Objects as Points ax1904.07850.pdf*9186306*1614603088","RepPoints Point Set Representation for Object Detection 1904.11490 iccv19.pdf*7477820*1603919176",56745416,""])
D.p(["Z:/UofA/PhD/Literature/static_detection/animal*0*1656263324","An Animal Detection Pipeline for Identification wacv18.pdf*2248154*1566017057","Animal Recognition and Identification with Deep Convolutional Neural Networks for Automated Wildlife Monitoring  DSAA17.pdf*864408*1540237610","Animal Recognition System Based  on Convolutional Neural Network aeee17.pdf*1777790*1540237610","Automated Detection and Recognition of Wildlife Using Thermal Cameras sensors14.pdf*9808853*1540237611","Automated Detection of Animals in Context to Indian Scenario isms14 .pdf*514684*1565212157","Automatic Detection and Recognition of Individuals in Patterned Species ecmlpkdd17_iiitd.pdf*9826862*1526069403","Automatically identifying, counting, and describing wild animals in camera-trap images with deep learning ax171115.pdf*6681306*1540237611","From Tiger to Panda Animal Head Detection tip1106.pdf*2650652*1565280956","Night vision animal detection ivsp14.pdf*3942717*1565325524","Semantic Part Segmentation using Compositional Model combining Shape and Appearance 1412.6124.pdf*6989594*1565273391","Synthetic Examples Improve Generalization for Rare Classes ax1904.05916.pdf*6632155*1575984271","Where's the Bear - Automating Wildlife Image Processing Using IoT and Edge Cloud Systems  ioTDI17.pdf*6296101*1525990289",58233276,"262*263*264*265*266"])
D.p(["Z:/UofA/PhD/Literature/static_detection/animal/aerial*0*1656263323","Adapting astronomical source detection software to help detect animals in thermal images obtained by unmanned aerial systems ax1701.01611 ijrs.pdf*5796649*1565272837","Background Categorization for Automatic Animal Detection in Aerial Videos Using Neural Networks annpr16_sl.pdf*8690735*1565273719","Best Practices to Train Deep Models on Imbalanced Datasets—A Case Study on Animal Detection in Aerial Imagery.pdf*231569*1565211870","Detecting animals in African Savanna with UAVs and the crowds ax1710 rse1710_sd.pdf*1591262*1565214448","Detecting mammals in UAV images Best practices to address a substantially imbalanced dataset with deep learning rse18_sd.pdf*3682884*1565212920","Fast animal detection in UAV images using convolutional neural networks igarrs17.pdf*1105919*1565275167","Half a Percent of Labels is Enough Efficient Animal Detection in UAV Imagery using Deep CNNs and Active Learning tgrs19 ax1907.07319.pdf*6928963*1565215248","Motion Based Animal Detection in Aerial Videos pcs16_sd.pdf*505693*1565212869",28533674,""])
D.p(["Z:/UofA/PhD/Literature/static_detection/animal/camera_trap*0*1656263324","A novel system for automatic detection and classification of animal elektro14.pdf*1551320*1565280033","A Support Vector Machine with Gabor Features for Animal Intrusion Detection in Agriculture Fields pcs18_sd.pdf*1119832*1565214190","Animal Detection From Highly Cluttered Natural Scenes Using Spatiotemporal Object Region Proposals and Patch Verification tim1610.pdf*1211568*1565274561","AnimalFinder A semi-automated system for animal detection in time-lapse camera trap images ei1611_sd.pdf*396924*1565213406","Automatic Recognition of Mammal Genera on Camera-Trap Images using Multi-Layer Robust Principal Component Analysis and Mixture Neural Networks ax1705.02727.pdf*1411938*1565215133","Automatically identifying, counting, and describing wild animals in camera-trap images with deep learning pnas18.pdf*2946556*1565964501","Camera-trap images segmentation using multi-layer robust principal component analysis ax1701.08180.pdf*543094*1565214967","Deep convolutional neural network based species recognition for wild animal monitoring icip14.pdf*457412*1565966814","Deep Learning Object Detection Methods for Ecological Camera Trap Data ax1803.10842.pdf*9231186*1548462598","Fast human-animal detection from highly cluttered camera-trap images using joint background modeling and deep learning classification iscas17.pdf*1128219*1565279699","Identifying animal species in camera trap images using deep learning and citizen science 2019-Methods_in_Ecology_and_Evolution.pdf*1125973*1565713956","Object detection from dynamic scene using joint background modeling and fast deep learning classification jvcir1808_sd.pdf*6632131*1565214821","Omni-supervised joint detection and pose estimation for wild animals orl1811_sd.pdf*3026288*1565212323","Past, Present, and Future Approaches Using Computer Vision for Animal Re-Identification from Camera Trap Data ax1811.07749.pdf*305412*1565965862","Recognition in Terra Incognita ax1807.04975 eccv178.pdf*7717899*1565710047","Towards Automatic Wild Animal Detection in Low Quality Camera-Trap Images Using Two-Channeled Perceiving Residual Pyramid Networks iccvw17.pdf*1183157*1565275392","Wild Animal Detection from Highly Cluttered Forest Images Using Deep Residual Networks ihci18_sl.pdf*1284565*1565203585","Wild Animal Detection Using Deep Convolutional Neural Network cvip17_sl.pdf*373782*1565211536",41647256,""])
D.p(["Z:/UofA/PhD/Literature/static_detection/animal/datasets*0*1565212005",0,""])
D.p(["Z:/UofA/PhD/Literature/static_detection/animal/no_vision*0*1656263324","A standardised framework for analysing animal detections from automated tracking arrays an_bio1812_sl.pdf*2399725*1565273567","Animal intrusion detection based on convolutional neural network iscit17.pdf*1078262*1566017057","Animal-vehicle collisions in Texas How to protect travelers and animals on roadways aap1910_sd.pdf*14784450*1565213244","How do amplitude spectra influence rapid animal detection vr0910_sd.pdf*896625*1565214095","Internet of Things Applications Animal Monitoring with Unmanned Aerial Vehicle ax1610.05287.pdf*4710310*1565273161","Reducing the threat of wildlife-vehicle collisions during peak tourism periods using a Roadside Animal Detection System aap1712_sd.pdf*635999*1565213783",24505371,""])
D.p(["Z:/UofA/PhD/Literature/static_detection/animal/video*0*1656263324","Amur Tiger Re-identification in the Wild ax1906.05586.pdf*7650925*1565983821","Analysing animal behaviour in wildlife videos using face detection and tracking visp06_iet.pdf*712652*1565275839","BioSense Real-Time Object Tracking for Animal Movement and Behavior Research aipr18.pdf*4388549*1565274840","BioTracker An Open-Source Computer Vision Framework for Visual Animal Tracking ax1803.07985.pdf*999280*1565268216","Building models of animals from video tpami0608.pdf*5551292*1565282117","idtracker.ai Tracking all individuals in large collectives of unmarked animals ax1803.04351.pdf*10126638*1565269431","MARGO (Massively Automated Real-time GUI for Object-tracking), a platform for high-throughput ethology bioax190330.pdf*8576264*1565268471","Tracktor Image‐based automated tracking of animal movement and behaviour 190215.pdf*3324444*1565268250",41330044,""])
D.p(["Z:/UofA/PhD/Literature/static_detection/anomaly*0*1557794013",0,""])
D.p(["Z:/UofA/PhD/Literature/static_detection/augmentation*0*1656263325","Learning Data Augmentation Strategies for Object Detection ax1906.11172.pdf*3353881*1562085463",3353881,""])
D.p(["Z:/UofA/PhD/Literature/static_detection/background_subtraction*0*1656263325","ANOMALY DETECTION IN SURVEILLANCE VIDEOS USING DEEP RESIDUAL NETWORKS mscthes1702.pdf*4763860*1526069355",4763860,""])
D.p(["Z:/UofA/PhD/Literature/static_detection/boundary*0*1656263325","Contour Detection and Hierarchical Image Segmentation tpami1105.pdf*10767108*1553006962","ContourGAN Image Contour Detection with Generative Adversarial Encoder-Decoder Networks kbs190115_sd.pdf*1962233*1553046598","Convolutional Oriented Boundaries eccv16.pdf*5297092*1544461101","Convolutional Oriented Boundaries From Image Segmentation to High-Level Tasks tpami18 ax1704.pdf*9710123*1544461196","Crisp Boundary Detection Using Pointwise Mutual Information eccv14.pdf*5904098*1553006672","High-for-Low and Low-for-High Efficient Boundary Detection From Deep Object Features and its Applications to High-Level Vision  iccv15.pdf*5649690*1453229384","Holistically-Nested Edge Detection ax1510 iccv15.pdf*2450318*1551715932",41740662,""])
D.p(["Z:/UofA/PhD/Literature/static_detection/cell*0*1656263325","Output Encoding by Compressed Sensing for Cell Detection with Deep Convnet aaai19.pdf*4198905*1655302668","Training Convolutional Neural Networks and Compressed Sensing End-to-End for Microscopy Cell Detection ax1810.03075.pdf*1080144*1547159671",5279049,""])
D.p(["Z:/UofA/PhD/Literature/static_detection/classic*0*1656263326","dpm-slides-ross-girshick.pdf*19302192*1517515577","Object Detection with Discriminatively Trained Part Based Models tpami10.pdf*2672613*1517515584","Regionlets for Generic Object Detection iccv13.pdf*496037*1517516207",22470842,""])
D.p(["Z:/UofA/PhD/Literature/static_detection/crop*0*1656263326","Towards Inﬁeld Navigation leveraging simulated data for crop row detection 2204.01811.pdf*13232603*1650339837",13232603,""])
D.p(["Z:/UofA/PhD/Literature/static_detection/deep_learning*0*1656263327","Acquisition of Localization Confidence for Accurate Object Detection 1807.11590 eccv18.pdf*1574314*1567128995","Bag of Freebies for Training Object Detection Neural Networks ax190412.pdf*3868174*1557319599","Beyond Skip Connections Top-Down Modulation for Object Detection ax1612.06851.pdf*12486695*1544041629","Deep Neural Networks for Object Detection nips13.pdf*1219595*1565730275","Deep Regionlets for Object Detection ax1712.pdf*706688*1517516224","Enriching object detection with 2D-3D registration and continuous viewpoint estimation cvpr15.pdf*1322083*1496895212","Learning Region Features for Object Detection ax180319.pdf*1767152*1540237608","LSDA Large scale detection through adaptation nips14 ax14_11.pdf*1380973*1544405463","Object Detection Networks on Convolutional Feature Maps ax1608 tpami16.pdf*2111653*1544301231","OverFeat Integrated Recognition, Localization and Detection using Convolutional Networks ax1402 iclr14.pdf*971988*1544405466","Relation Networks for Object Detection ax171130 cvpr18.pdf*1347946*1574214252","Scale-Transferrable Object Detection cvpr18.pdf*1678962*1557584677","Spatial Pyramid Pooling in Deep Convolutional Networks for Visual Recognition ax150423 tpami15.pdf*4072260*1544453427","Subcategory-aware Convolutional Neural Networks for Object Proposals and Detection wacv17 ax17_3.pdf*4859259*1495339941",39367742,""])
D.p(["Z:/UofA/PhD/Literature/static_detection/domain_adaptation*0*1656263327","Adapting Object Detectors via Selective Cross-Domain Alignment cvpr19.pdf*643237*1562102456","Diversify and Match A Domain Adaptive Representation Learning Paradigm for Object Detection cvpr19.pdf*1291428*1562102425","Domain Adaptive Faster R-CNN for Object Detection in the Wild cvpr18.pdf*621690*1562102997","Strong-Weak Distribution Alignment for Adaptive Object Detection cvpr19.pdf*3486814*1562084898","Unsupervised Domain adaptation in object detection.pdf*5525970*1603658178",11569139,""])
D.p(["Z:/UofA/PhD/Literature/static_detection/fence*0*1656263328","Automatic Fence Segmentation in Videos of Dynamic Scenes  cvpr16.pdf*9444181*1526081099","Automatic inpainting by removing fence-like structures in RGBD images mva1410_springer.pdf*19879004*1540237612","Deep learning based fence segmentation and removal from an image using a video sequence ax161021.pdf*9339759*1540237612","Fence-like Quasi-periodic Texture Detection in Images 14.pdf*2749223*1540237613","Image De-fencing Revisited accv12.pdf*3391564*1526077921","Image de-fencing using histograms of oriented gradients sivp1803_springer.pdf*1641407*1540237613","My camera can see through fences A deep learning approach for image de-fencing acpr15.pdf*611505*1526079443",47056643,""])
D.p(["Z:/UofA/PhD/Literature/static_detection/grasp*0*1656263329","deep learning for detecting robotic grasps ijrr15.pdf*5283630*1456248779","deep learning for detecting robotic grasps rss09.pdf*678775*1540237644",5962405,""])
D.p(["Z:/UofA/PhD/Literature/static_detection/hard_negative_mining*0*1656263329","Bootstrapping Face Detection with Hard Negative Examples ax1608.pdf*287964*1540237607","Training Region-based Object Detectors with Online Hard Example Mining ax1604.03540 cvpr16.pdf*965877*1544041304",1253841,""])
D.p(["Z:/UofA/PhD/Literature/static_detection/human*0*1656263329","Deep Learning for Human Part Discovery in Images icra16.pdf*6133667*1540237607",6133667,""])
D.p(["Z:/UofA/PhD/Literature/static_detection/instance_segmentation*0*1656263329","Mask R-CNN ax17_4 iccv17.pdf*7490218*1544561225","Mask R-CNN ax180124.pdf*7723886*1544558768","MaskLab Instance Segmentation by Refining Object Detection With Semantic and Direction Features_cvpr18.pdf*1381030*1557595973","Pseudo Mask Augmented Object Detection cvpr18.pdf*1356278*1557596214",17951412,""])
D.p(["Z:/UofA/PhD/Literature/static_detection/medical*0*1661454750","Retinal Glaucoma Detection Using Deep Learning Algorithm Tanu.pdf*904724*1661401877",904724,""])
D.p(["Z:/UofA/PhD/Literature/static_detection/mobile*0*1656263330","EfficientDet Scalable and Efficient Object Detection 1911.09070 cvpr20.pdf*751604*1631193030","MnasFPN Learning Latency-aware Pyramid Architecture for Object Detection on Mobile Devices 1912.01106.pdf*844420*1631193321","MobileDets Searching for Object Detection Architectures for Mobile Accelerators 2004.14525 cvpr21.pdf*752715*1631158021","MobileNetV2 Inverted Residuals and Linear Bottlenecks ax180402.pdf*1539161*1529256805","Squeezedet Uniﬁed, small, low power fully convolutional neural net- works for real-time object detection for autonomous driving cvprw17.pdf*1657230*1540237614",5545130,""])
D.p(["Z:/UofA/PhD/Literature/static_detection/notes*0*1656263331","Bottom-up object detection by grouping extreme and center points 1901.08043.pdf*100100*1605900602","Bridging the Gap Between Anchor-based and Anchor-free Detection via Adaptive Training Sample Selection 1912.02424 cvpr20.pdf*106526*1605900924","CornerNet Detecting Objects as Paired Keypoints ax1903 ijcv19.pdf*203409*1576961378","DSSD.pdf*7064*1544457704","End-to-end object detection with Transformers ax200528.pdf*105457*1614602643","Faster_R-CNN.pdf*9191*1544456862","FCOS Fully Convolutional One-Stage Object Detection ax1908 iccv19.pdf*194792*1577304934","Feature Selective Anchor-Free Module for Single-Shot Object Detection ax1903.00621 cvpr19.pdf*209495*1577392773","focal_loss.pdf*7725*1544459698","FoveaBox Beyond Anchor-based Object Detector ax1904.03797.pdf*191837*1576961150","FPN.pdf*55018*1544459578","Generalized Intersection over Union A Metric and A Loss for Bounding Box Regression 1902.09630 cvpr19.pdf*102168*1606334272","IOU-Net.pdf*2272*1565125005","LSDA Large scale detection through adaptation nips14 ax14_11.pdf*7365*1544546372","Mask R-CNN ax17_4 iccv17.pdf*7466*1546018890","Objects as Points ax1904.07850.pdf*103181*1614602993","OverFeat Integrated Recognition, Localization and Detection using Convolutional Networks ax1402 iclr14.pdf*7608*1544546294","RepPoints Point Set Representation for Object Detection 1904.11490 iccv19.pdf*105244*1614603169","RFCN.pdf*5360*1558027237","Scalable Object Detection Using Deep Neural Networks cvpr14.pdf*7164*1544495320","Selective Search for Object Recognition ijcv2013.pdf*7452*1544495368","SNIPER Efficient Multi-Scale Training ax181213 nips18.pdf*194917*1577562355","SSD.pdf*7495*1544711757","TCNN.pdf*9681*1536761861","YOLO9000 Better, Faster, Stronger ax16_12.pdf*8256*1544495297","YOLOv3 An Incremental Improvement ax180408.pdf*7478*1544495288","YOLOV4_Optimal Speed and Accuracy of Object Detection ax200423.pdf*101134*1601842064","You Only Look Once Unified, Real-Time Object Detection ax1605.pdf*7318*1544495306",1882173,""])
D.p(["Z:/UofA/PhD/Literature/static_detection/post_processing*0*1656263331","Assessing post-detection ﬁlters for a generic pedestrian detector in a tracking-by-detection scheme avss17.pdf*529289*1544460289","Soft-NMS -- Improving Object Detection With One Line of Code 1704.04503 iccv17.pdf*2089763*1564625693",2619052,""])
D.p(["Z:/UofA/PhD/Literature/static_detection/rare*0*1656263331","Meta-Learning to Detect Rare Objects iccv19.pdf*2577839*1647567204","Training Rare Object Detection in Satellite Imagery with Synthetic GAN Images  cvprw21.pdf*1247865*1647566672",3825704,""])
D.p(["Z:/UofA/PhD/Literature/static_detection/RCNN*0*1698325219","A MultiPath Network for Object Detection ax1604.02135 facebook.pdf*3442440*1568166224","An Analysis of Scale Invariance in Object Detection ­ SNIP cvpr18.pdf*1135257*1557595561","Cascade R-CNN Delving into High Quality Object Detection cvpr18 1712.00726.pdf*1879416*1650481904","Cascade R-CNN High Quality Object Detection and Instance Segmentation tpami21 1906.09756.pdf*2110100*1650484204","Context R-CNN Long Term Temporal Context for Per-Camera Object Detection 1912.03538 cvpr20.pdf*16914091*1631193481","Fast R-CNN ax1509 iccv15.pdf*673315*1548218752","Faster R-CNN Towards Real-Time Object Detection with Region Proposal Networks nips15 arxiv15.pdf*766890*1525101176","Faster R-CNN Towards Real-Time Object Detection with Region Proposal Networks tpami17 ax16_1.pdf*6826059*1548218753","Light-Head R-CNN In Defense of Two-Stage Object Detector cvpr18 1711.07264.pdf*2200670*1544459936","Multi-Scale Location-Aware Kernel Representation for Object Detection_cvpr18.pdf*1655469*1557590612","Object Detection Networks on Convolutional Feature Maps ax1608 tpami17.pdf*2111653*1544460108","PVANet Lightweight Deep Neural Networks for Real-time Object Detection ax1612 nipsw16.pdf*181254*1544719862","Region-Based Convolutional Networks for Accurate Object Detection and Segmentation  tpami16_1.pdf*1688910*1497398498","R-FCN-3000 at 30fps Decoupling Detection and Classification cvpr18.pdf*1256563*1557587053","RFCN-Object Detection via Region-based Fully Convolutional Networks nips16.pdf*653414*1558027443","Rich feature hierarchies for accurate object detection and semantic segmentation ax141022 cvpr14.pdf*6537772*1525541345","SNIPER Efficient Multi-Scale Training ax181213 nips18.pdf*2295006*1577480794","Sparse R-CNN End-to-End Object Detection with Learnable Proposals cvpr21 2011.12450.pdf*7094385*1698344637",59422664,""])
D.p(["Z:/UofA/PhD/Literature/static_detection/region_proposal*0*1656263332","Deep Reinforcement Learning of Region Proposal Networks for Object Detection_cvpr18.pdf*677988*1557689772","Deep Reinforcement Learning of Region Proposal Networks for Object Detection_cvpr18-supp.zip*14586811*1557689782","Edge boxes Locating object proposals from edges eccv14.pdf*2783192*1544459928","Multiscale Combinatorial Grouping cvpr14.pdf*2386514*1544459155","Multiscale Combinatorial Grouping for Image Segmentation and Object Proposal Generation ax2015_v3 tpami16.pdf*8073879*1544459234","Scalable Object Detection Using Deep Neural Networks cvpr14.pdf*588066*1544370488","Scalable, High-Quality Object Detection ax1512.pdf*358172*1548192808","Selective Search for Object Recognition ijcv2013.pdf*5972370*1540237609","Selective Search for Object Recognition ppt ijcv12.pdf*12754144*1525926260",48181136,""])
D.p(["Z:/UofA/PhD/Literature/static_detection/retinanet*0*1656263333","Consecutive Feature Network for Object Detection icma18.pdf*464214*1544200202","Fast Feature pyramid for object detection tpami14.pdf*3679689*1544052352","Feature Pyramid Networks for Object Detection ax170419.pdf*723635*1544114886","Focal Loss for Dense Object Detection ax180207 iccv17.pdf*1229779*1557376042",6097317,""])
D.p(["Z:/UofA/PhD/Literature/static_detection/review*0*1656263333","Application of Deep Learning for Object Detection pcs18_sd_kiit.pdf*757958*1535919716","Deep learning for class-generic object detection 1312.6885.pdf*939250*1579918000","Deep Learning for Generic Object Detection A Survey ax1809.02165 ijcv19.pdf*4307408*1544454737","Speed accuracy trade-offs for modern convolutional object detectors ax1704 cvpr17.pdf*8213513*1560573190",14218129,""])
D.p(["Z:/UofA/PhD/Literature/static_detection/RNN*0*1656263333","Inside-Outside Net Detecting Objects in Context with Skip Pooling and Recurrent Neural Networks 1512.04143 cvpr16.pdf*1763412*1544196498",1763412,""])
D.p(["Z:/UofA/PhD/Literature/static_detection/road*0*1656263335","A New Performance Measure and Evaluation Benchmark for Road Detection Algorithms ITSC2013l.pdf*2464892*1637766237","Deep Learning for Robust Road Object Detection msc_thes17.pdf*15931160*1540237608","Real-time Kinematic Ground Truth for the Oxford RobotCar Dataset.pdf*3532616*1637768867","ROAD The ROad event Awareness Dataset for Autonomous Driving 2102.11585.pdf*1609804*1637767532",23538472,""])
D.p(["Z:/UofA/PhD/Literature/static_detection/sensor_fusion*0*1631282659",0,""])
D.p(["Z:/UofA/PhD/Literature/static_detection/single_stage*0*1656263335","DeNet Scalable Real-time Object Detection with Directed Sparse Sampling iccv17 ax1703.10295.pdf*186379*1544456232",186379,""])
D.p(["Z:/UofA/PhD/Literature/static_detection/skeleton*0*1656263335","DeepSkeleton Learning Multi-task Scale-associated Deep Side Outputs for Object Skeleton Extraction in Natural Images ax1707 tpami17.pdf*5483119*1553389872","Hi-Fi Hierarchical Feature Integration for Skeleton Detection ijcai18.pdf*5600829*1553389855","Object Skeleton Extraction in Natural Images by Fusing Scale-associated Deep Side Outputs ax1604 cvpr16.pdf*7652591*1553389891",18736539,""])
D.p(["Z:/UofA/PhD/Literature/static_detection/small*0*1656263335","An Evaluation of Deep Learning Methods for Small Object Detection hindawi20.pdf*7109351*1631222603",7109351,""])
D.p(["Z:/UofA/PhD/Literature/static_detection/SSD*0*1656263336","Context-Aware Single-Shot Detector 1707.08682 wacv18.pdf*1978564*1544197850","Deep Feature Pyramid Reconfiguration for Object Detection 1808.07993 eccv18.pdf*3955980*1544713118","DSSD Deconvolutional Single Shot Detector ax1701.06659.pdf*5416744*1544329669","Enhancement of SSD by concatenating feature maps for object detection 1705.09587.pdf*2562819*1544199046","Extend the shallow part of Single Shot MultiBox Detector via Convolutional Neural Network 1801.05918.pdf*2253860*1544199095","FSSD Feature Fusion Single Shot Multibox Detector 1712.00960.pdf*1086122*1544197807","MDSSD Multi-scale Deconvolutional Single Shot Detector for Small Objects ax1805.07009.pdf*6338211*1544195983","Single-Shot Object Detection With Enriched Semantics_cvpr18.pdf*865262*1557587197","Single-Shot Refinement Neural Network for Object Detection_cvpr18.pdf*579210*1557596602","SSD Single Shot MultiBox Detector eccv16_ax16_12.pdf*2344085*1548192180",27380857,""])
D.p(["Z:/UofA/PhD/Literature/static_detection/text*0*1656263336","An Anchor-Free Region Proposal Network for Faster R-CNN based Text Detection Approaches 1804.09003.pdf*878077*1610507226","Unknown-box Approximation to Improve Optical Character Recognition Performance _202105_MSc thesis.pdf*10769194*1644859196","Unknown-box Approximation to Improve Optical Character Recognition Performance 2105.07983 icdar21.pdf*3189876*1644855301",14837147,""])
D.p(["Z:/UofA/PhD/Literature/static_detection/transformers*0*1700094640","Deformable DETR Deformable Transformers for End-to-End Object Detection 2010.04159 iclr21.pdf*4466767*1692568236","Efficient DETR Improving End-to-End Object Detector with Dense Prior 2104.01318.pdf*1617328*1698501922","End-to-End Object Detection with Transformers ax200528.pdf*7553519*1591935573","Label2Label A Language Modeling Framework for Multi-Attribute Learning eccv22.pdf*1188083*1699633587","OFA Unifying Architectures, Tasks, and Modalities Through a Simple Sequence-to-Sequence Learning Framework icml22.pdf*35991652*1699557550","Pix2seq A Language Modeling Framework for Object Detection iclr22.pdf*12614238*1700162984","Rethinking transformer-based set prediction for object detection iccv21 2011.10881.pdf*3323351*1698325003",66754938,""])
D.p(["Z:/UofA/PhD/Literature/static_detection/vehicle*0*1656263336","Evolving Boxes for Fast Vehicle Detection icme13.pdf*3367848*1544407737",3367848,""])
D.p(["Z:/UofA/PhD/Literature/static_detection/weak_supervision*0*1656263337","End-to-End Semi-Supervised Object Detection with Soft Teacher 2106.09018v2.pdf*2329781*1648404522","W2F A Weakly-Supervised to Fully-Supervised Framework for Object Detection cvpr18.pdf*1458246*1557589810","W2F A Weakly-Supervised to Fully-Supervised Framework for Object Detection cvpr18-supp.pdf*95297*1557586044",3883324,""])
D.p(["Z:/UofA/PhD/Literature/static_detection/yolo*0*1656263337","Complex-YOLO An Euler-Region-Proposal for Real-time 3D Object Detection on Point Clouds ax1803.06199.pdf*1995218*1601842223","YOLO9000 Better, Faster, Stronger ax16_12.pdf*5243597*1560122583","YOLO-ReT Towards High Accuracy Real-time Object Detection on Edge GPUs 2110.13713 wacv22.pdf*1137890*1636572086","YOLOv3 An Incremental Improvement ax180408.pdf*2417623*1560143244","YOLOV4_Optimal Speed and Accuracy of Object Detection ax200423.pdf*3895852*1601839752","You Only Look at One Sequence Rethinking Transformer in Vision through Object Detection 2106.00666 nips21.pdf*24708484*1651720061","You Only Look Once Unified, Real-Time Object Detection ax1605.pdf*5249649*1560143244",44648313,""])
D.p(["Z:/UofA/PhD/Literature/static_detection/zero_shot*0*1656263337","Zero-Shot Detection ax1903 ax1803.07113 tcsvt.pdf*3788697*1577405961","Zero-Shot Object Detection ax1804.04340 eccv18.pdf*5622736*1577405970","Zero-Shot Object Detection by Hybrid Region Embedding bmvc18 ax1805.06157.pdf*4484377*1577405992","Zero-Shot Object Detection Learning to Simultaneously Recognize and Localize Novel Concepts ax1803.06049 accv18.pdf*3209814*1577405996",17105624,""])
D.p(["Z:/UofA/PhD/Literature/static_segmentation*0*1699506439","Efﬁcient Shallow Network for River Ice Segmentation remotesensing 220515.pdf*8775386*1658226345","Fast Large-Scale Spectral Clustering via Explicit Feature Mapping TC19 NR.pdf*1978268*1698159649","Fast-SCNN Fast Semantic Segmentation Network 1902.04502.pdf*5020472*1571709837","Fully Convolutional Networks for Semantic Segmentation ax1504 cvpr15.pdf*2755975*1540771198","ICENET A Semantic Segmentation Deep Network for River Ice by Fusing Positional and Channel-Wise Attentive Features remotesensing-12-00221.pdf*5567728*1588888691","ICNet for Real-Time Semantic Segmentation on High-Resolution Images ax1704.pdf*4031094*1522012470","Instance-aware Semantic Segmentation via Multi-task Network Cascades 1512.04412.pdf*4100815*1650429800","Interactive image segmentation by maximal similarity based region merging pr09.pdf*1933086*1518832885","Learning from Synthetic Data Addressing Domain Shift for Semantic Segmentation ax1711 cvpr18.pdf*1126077*1565472463","Multi-Scale Context Aggregation by Dilated Convolutions ax160430 iclr16.pdf*3002971*1540237663","ParseNet Looking Wider to See Better ax1511 iclr16.pdf*3502693*1544714445","PixelNet Representation of the pixels, by the pixels, and for the pixels.  17.pdf*4693472*1522012959","Segment Anything 2304.02643.pdf*15375127*1698499311","Two layer Ensemble of Deep Learning Models for Medical Image Segmentation 2104.04809.pdf*1406922*1618670619","What's the Point Semantic Segmentation with Point Supervision ax1607 eccv16.pdf*3992854*1540237663",67262940,"304*305*306*307*308*309*310*311*312*313*314"])
D.p(["Z:/UofA/PhD/Literature/static_segmentation/deeplab*0*1656263338","Auto-DeepLab Hierarchical Neural Architecture Search for Semantic Image Segmentation ax1904 cvpr19.pdf*595007*1566766300","DeepLab Semantic Image Segmentation with Deep Convolutional Nets, Atrous Convolution, and Fully Connected CRFs ax17_5.pdf*5944025*1546665844","DeepLab Semantic Image Segmentation with Deep Convolutional Nets, Atrous Convolution, and Fully Connected CRFs} ax16.pdf*5948299*1540237662","Encoder-Decoder with Atrous Separable Convolution for Semantic Image Segmentation ax180308.pdf*1900329*1524808877","Rethinking Atrous Convolution for Semantic Image Segmentation ax1706.05587.pdf*2855206*1545870277","Semantic Image Segmentation with Deep Convolutional Nets and Fully Connected CRFs ax16_6 iclr15.pdf*4724922*1518832885","Weakly- and Semi-Supervised Learning of a DCNN for Semantic Image Segmentation ax15_11.pdf*2615322*1498970247",24583110,""])
D.p(["Z:/UofA/PhD/Literature/static_segmentation/few_shot*0*1656263338","Few-Shot Segmentation Propagation with Guided Networks ax1806.07373.pdf*2887065*1566248656",2887065,""])
D.p(["Z:/UofA/PhD/Literature/static_segmentation/instance*0*1700094640","A Unified Sequence Interface for Vision Tasks nips22.pdf*5311442*1700109056","Deep Learning based Food Instance Segmentation using Synthetic Data 2107.07191v2.pdf*2197662*1627144145","FCOS Fully Convolutional One-Stage Object Detection 1904.01355.pdf*3411174*1568214748","Fully Convolutional Instance-aware Semantic Segmentation ax1704 cvpr17.pdf*5300769*1560559313","Instance-aware Semantic Segmentation via Multi-task Network Cascades ax1512.04412.pdf*4100815*1568213554","Instance-sensitive Fully Convolutional Networks ax1603.08678.pdf*6061066*1546996806","Large-scale interactive object segmentation with human annotators ax1903.10830 cvpr19.pdf*1796958*1565638307","Mask Scoring R-CNN 1903.00241.pdf*880875*1568214528","RetinaMask Learning to predict masks improves state-of-the-art single-shot detection for free 1901.03353.pdf*9841917*1568214730","Rock Instance Segmentation from Synthetic Images for Planetary Exploration Missions_asre21.pdf*3554398*1642191571","The surprising impact of mask-head architecture on novel class segmentation 2104.00613.pdf*12280710*1626892716",54737786,""])
D.p(["Z:/UofA/PhD/Literature/static_segmentation/medical_imaging*0*1656263339","Deep Fusion Net for Multi-Atlas Segmentation Application to Cardiac MR Images.pdf*1104717*1477949549","End-to-end learning of convolutional neural net and dynamic programming for left ventricle segmentation mlr20.pdf*1334229*1629915471",2438946,""])
D.p(["Z:/UofA/PhD/Literature/static_segmentation/misc*0*1664716686","Omnimatte Associating Objects and Their Effects in Video 2105.06993.pdf*33492938*1630547686",33492938,""])
D.p(["Z:/UofA/PhD/Literature/static_segmentation/panoptic*0*1699508248","Panoptic Segmentation 1801.00868 cvpr19.pdf*3382750*1629911562","Visual Recognition by Request cvpr23.pdf*2511291*1699663110",5894041,""])
D.p(["Z:/UofA/PhD/Literature/static_segmentation/proposal*0*1656263339","Learning to Refine Object Segments ax1608 eccv16.pdf*2934408*1548462598","Learning to Segment Object Candidates ax1509 nips15.pdf*2406820*1521931637",5341228,""])
D.p(["Z:/UofA/PhD/Literature/static_segmentation/road*0*1656263339","Superpixel clustering with deep features for unsupervised road segmentation ax1711.pdf*3560879*1521480121",3560879,""])
D.p(["Z:/UofA/PhD/Literature/static_segmentation/segnet*0*1656263343","SegNet A Deep Convolutional Encoder-Decoder Architecture for Image Segmentation pami17.pdf*2180488*1540237663","SegNet A Deep Convolutional Encoder-Decoder Architecture for Robust Semantic Pixel-Wise Labelling ax1505.pdf*6809805*1522011340",8990293,""])
D.p(["Z:/UofA/PhD/Literature/static_segmentation/tokens*0*1699508490","All in Tokens Unifying Output Space of Visual Tasks via Soft Token iccv23.pdf*8035342*1699506375","Obj2Seq Formatting Objects as Sequences with Class Prompt for Visual Tasks nips22.pdf*1317032*1699661524","Point2Seq Detecting 3D Objects As Sequences cvpr22.pdf*625034*1699507542","PolyFormer Referring Image Segmentation As Sequential Polygon Generation cvpr23.pdf*10000355*1699508410","Unified-IO A Unified Model for Vision, Language, and Multi-Modal Tasks 2206.08916.pdf*8009557*1699506868","UViM A Unified Modeling Approach for Vision with Learned Guiding Codes nips22.pdf*4803172*1699505917",32790492,""])
D.p(["Z:/UofA/PhD/Literature/static_segmentation/unet*0*1656263343","U-Net Convolutional Networks for Biomedical Image Segmentation ax1509 miccai15.pdf*1620903*1540237663",1620903,""])
D.p(["Z:/UofA/PhD/Literature/stereo*0*1656263344","Efﬁcient Deep Learning for Stereo Matching cvpr16.pdf*10380956*1528323812",10380956,""])
D.p(["Z:/UofA/PhD/Literature/tools*0*1656263344","A new approach towards implementing artiﬁcial neural networks.pdf*292212*1518832869","A Survey of Semantic Image and Video Annotation Tools 2011.pdf*1988363*1499314023","matconvnet-manual.pdf*1217029*1518832886","MXNet A Flexible and Efficient Machine Learning Library for Heterogeneous Distributed Systems nips15.pdf*266870*1540237649","TensorFlow 15_9.pdf*889994*1518832887",4654468,""])
D.p(["Z:/UofA/PhD/Literature/traffic_monitoring*0*1656263346","A computer vision system for the detection and classification of vehicles at urban road intersections paa05.pdf*566246*1473269742","A real-time computer vision system for vehicle tracking and traffic surveillance tret98.pdf*1422890*1518832890","A taxonomy and analysis of camera calibration methods for trafﬁc monitoring applications itst10.pdf*365935*1473356806","An Overview of Image processing for traffic applications iosr14.pdf*373317*1518832891","Automated Road Safety Analysis Using Video Sensors trb07.pdf*737277*1518832891","Biologically Inspired Composite Vision System for Multiple Depth-of-ﬁeld Vehicle Tracking and Speed Detection accvw14.pdf*10693844*1518832891","Biologically inspired composite vision system for traffic monitoring icca16.pdf*802026*1472834331","Biologically-Inspired Long-Range Traffic  Monitoring System with Basler ace USB 3.0 Camera.pdf*412151*1472833393","Camera calibration for urban trafﬁc scenes Practical issues and a robust approach trbam10.pdf*2313850*1473357839","Computer Vision on Embedded Sensors for Traffic Flow Monitoring itsc15.pdf*380867*1472840155","Learning, Modeling, and Understanding Vehicle Surround Using Multi-Modal Sensing dissertation.pdf*6699891*1473270747","Matching vehicles under large pose transformations using approximate 3D models and piecewise MRF model cvpr08.pdf*968443*1473437203","Real-time Vehicle Detection and Tracking Using Stereo Vision and Multi-View AdaBoost itsc-11.pdf*828507*1473350922","Road intersection monitoring from video with large perspective deformation itswc14.pdf*3124099*1518832891","Street Viewer An Autonomous Vision Based Trafﬁc Tracking System sensors16.pdf*7516237*1518832892","Traffic monitoring and accident detection at intersections itst00.pdf*331989*1518832892","ViBe A universal background subtraction algorithm for video sequences tip11.pdf*2035329*1473436842","Vision-based scale-adaptive vehicle detection and tracking for intelligent traffic monitoring robio14.pdf*1166394*1472840492","Vision-based trafﬁc measurement system icpr04.pdf*558404*1473435768",41297696,"318*319*320*321*322"])
D.p(["Z:/UofA/PhD/Literature/traffic_monitoring/commercial*0*1656263345","GridSmart.pdf*1274814*1473270179","THE PROMETHEUS  PROGRAMME  92.pdf*140407*1472928352",1415221,""])
D.p(["Z:/UofA/PhD/Literature/traffic_monitoring/in_vehicle*0*1656263345","A System for Real-time Detection and Tracking of Vehicles from a Single Car-mounted Camera itsc112.pdf*2008910*1473356153","Combining Monocular and Stereo-Vision for Real-Time Vehicle Ranging and Tracking on Multilane Highways itsc11.pdf*403831*1518832892","Vehicle detection and tracking in car video based on motion model itst11.pdf*1305388*1473446834",3718129,""])
D.p(["Z:/UofA/PhD/Literature/traffic_monitoring/semantic*0*1656263346","A real-time computer vision system for measuring traffic parameters cvpr97.pdf*966393*1472947719","Large Scale Automated Analysis of Vehicle Interactions and Collisions.pdf*1814828*1518832892","Real-Time Video-Based Trafﬁc Measurement and Visualization System for EnergyEmissions itst12.pdf*2318964*1472947077","Video processing techniques for traffic information acquisition using uncontrolled video streams itsc09.pdf*932119*1518832893",6032304,""])
D.p(["Z:/UofA/PhD/Literature/traffic_monitoring/survey*0*1656263346","A comprehensive review of background subtraction algorithms evaluated with synthetic and real videos cviu14.pdf*3990831*1518832893","A review of computer vision techniques for the analysis of urban trafﬁc itst11.pdf*659542*1473270466","A survey of video processing techniques for traffic applications ivc03.pdf*318516*1518832893","A Survey of Vision-Based Traffic Monitoring of Road Intersections itst16.pdf*7377529*1518832893","A survey on visual surveillance of object motion and behaviors tsmc04.pdf*314413*1473437492","Background subtraction for automated multisensor surveillance A comprehensive review eurasip jasp10.pdf*5494192*1518832894","Looking at Vehicles on the Road A Survey of Vision-Based Vehicle Detection, Tracking, and Behavior Analysis itst13.pdf*1679394*1473271109","On-Road Vehicle Detection Using Optical Sensors A Review pami06.pdf*2508868*1473271120","Tracking all traffic computer vision algorithms for monitoring vehicles, individuals, and crowds iram05.pdf*1335925*1472948434","Traffic Monitoring and Control Using Machine Vision A Survey  TIE85.pdf*2605049*1472948187","Traffic monitoring with computer vision sami09.pdf*351008*1472921803","Traffic Surveillance A Review of Vision Based Vehicle Detection,  Recognition and Tracking ijaerv11n1_108.pdf*520045*1473270751","Video processing techniques for traffic flow monitoring A survey  itsc11.pdf*943998*1472943317",28099310,""])
D.p(["Z:/UofA/PhD/Literature/traffic_monitoring/uav*0*1656263346","01570387.pdf*381082*1473464002","05279483.pdf*117509*1473464012","07090517.pdf*579592*1473463914","07311600.pdf*2945158*1473463907","07546916.pdf*4850408*1473463994","A pan-tilt camera fuzzy vision controller on an unmanned aerial vehicle iros09.pdf*1136894*1478578523","Computer vision based general object following for gps-denied multirotor unmanned vehicles acc14.pdf*896793*1478577918","Efficient Road Detection and Tracking for Unmanned Aerial Vehicle itst16.pdf*3575586*1473448576","Estimating speed profiles from aerial vision — A comparison of regression based sampling techniques med16.pdf*7083041*1473447852","From images to traffic behavior - A UAV tracking and monitoring application icif07.pdf*1270124*1473447407","Minimum Time UAV Pursuit of a Moving Ground Target Using Partial Information icuas15.pdf*364850*1518832895","Motion-vector clustering for traffic speed detection from UAV video isc216.pdf*683412*1473448383","Surveillance from above A detection-and-prediction based multiple target tracking method on aerial videos icns16.pdf*2662558*1473448095","Vehicle detection methods from an unmanned aerial vehicle platform icves12.pdf*296309*1473456211",26843316,""])
D.p(["Z:/UofA/PhD/Literature/unsorted*0*1656263347","Harmonization_SIG10.pdf*25265866*1520484979","Harmonization_SIG10_supplementary.pdf*54703291*1540237685","Phase-Based_Video.pdf*12946244*1520485453","sun10.pdf*804746*1520483950",93720147,""])
D.p(["Z:/UofA/PhD/Literature/video_captioning*0*1699505839","Accurate and Fast Compressed Video Captioning iccv23.pdf*5284919*1698436635","Delving Deeper into the Decoder for Video Captioning 2001.05614 ecai20.pdf*3251960*1596173459","Describing Videos by Exploiting Temporal Structure 1502.08029 iccv15.pdf*2794484*1595977734","Grounded Video Description 1812.06587 cvpr19.pdf*7865168*1596047845","Learning to Compose Topic-Aware Mixture of Experts for Zero-Shot Video Captioning 1811.02765 aaai19 dummy code.pdf*1467368*1596173183","Learning to Generate Grounded Visual Captions without Localization Supervision 1906.00283 eccv20.pdf*7688953*1596173580","Long-term Recurrent Convolutional Networks for Visual Recognition and Description 1411.4389 cvpr15 tpami1704.pdf*2701270*1596308875","MART Memory-Augmented Recurrent Transformer for Coherent Video Paragraph Captioning 2005.05402 acl20.pdf*2904299*1596112379","Motion Words for Videos eccv14.pdf*4410959*1518832868","Sequence to sequence video to text iccv15.pdf*1526069*1595975033","Spatio-Temporal Dynamics and Semantic Attribute Enriched Visual Encoding for Video Captioning 1902.10322 cvpr19.pdf*2038258*1698171820","SwinBERT End-to-End Transformers with Sparse Attention for Video Captioning cvpr22 microsoft 2111.13196.pdf*3316257*1698516980","Temporal Deformable Convolutional Encoder-Decoder Networks for Video Captioning 1905.01077v1 aaai19.pdf*3452632*1596174007","Temporal Segment Captioning Network proj.pdf*19996813*1596173933","Towards Automatic Learning of Procedures from Web Instructional Videos 1703.09788 aaai18.pdf*2141879*1597628828","Translating Videos to Natural Language Using Deep Recurrent Neural Networks 1412.4729 naacl15.pdf*6903602*1596309078","TVR A Large-Scale Dataset for Video-Subtitle Moment Retrieval 2001.09099.pdf*8999924*1596173339",86744814,"325*326*327"])
D.p(["Z:/UofA/PhD/Literature/video_captioning/DVC*0*1699557949","A Better Use of Audio-Visual Cues Dense Video Captioning with Bi-modal Transformer 2005.08271.pdf*627185*1596067576","Bidirectional Attentive Fusion with Context Gating for Dense Video Captioning 1804.00100 cvpr18.pdf*2071341*1596072188","Dense-Captioning Events in Videos 1705.00754 iccv17.pdf*2358949*1596316722","End-to-End Dense Video Captioning with Masked Transformer 1804.00819 cvpr18.pdf*1387329*1696976624","End-to-End Dense Video Captioning with Parallel Decoding cvpr21.pdf*5552611*1692568315","Multi-modal Dense Video Captioning 2003.07758 cvprw20.pdf*800373*1596066209","Vid2Seq Large-Scale Pretraining of a Visual Language Model for Dense Video Captioning cvpr23.pdf*5847148*1699636441","Vid2Seq supplemental.pdf*3181596*1699505727","Weakly Supervised Dense Video Captioning 1704.01502 cvpr17.pdf*3892581*1596067212",25719113,""])
D.p(["Z:/UofA/PhD/Literature/video_captioning/grounding*0*1656263348","Grounded Video Description cvpr19.pdf*684768*1596308860","Grounding Visual Explanations ECCV18.pdf*2148529*1595971643","Joint Event Detection and Description in Continuous Video Streams 1802.10250v3 wacv19.pdf*1672681*1596047419","Spatio-Temporal Attention Models for Grounded Video Captioning 1610.04997 accv16.pdf*6636915*1595305612","Video Object Grounding using Semantic Roles in Language Description 2003.10606 cvpr20.pdf*10308966*1596138984","Visual Grounding via Accumulated Attention cvpr18.pdf*797130*1595971643","Weakly-Supervised Video Object Grounding from Text by Loss Weighting and Object Interaction bmvc18.pdf*1644165*1595971873",23893154,""])
D.p(["Z:/UofA/PhD/Literature/video_captioning/review*0*1656263348","Video Description A Survey of Methods, Datasets, and Evaluation Metrics 1806.00186 acmcs1910.pdf*3937809*1597294298","Video Description A Survey of Methods, Datasets, and Evaluation Metrics acm2011.pdf*3758023*1650487432",7695832,""])
D.p(["Z:/UofA/PhD/Literature/video_detection*0*1656263352",".gitignore*50*1545182523","Deep Learning-based Multiple Pedestrians Detection-Tracking Framework HCIK16_ACM.pdf*1089041*1540237641","Improving a real-time object detector with compact temporal information iccvw17.pdf*942614*1552961618","MODNet Moving Object Detection Network with Motion and Appearance for Autonomous Driving ax1711.pdf*5967704*1544200274","Moving object detection in videos using principal component pursuit and convolutional neural networks  globalsip1711.pdf*257561*1525991711","Object Detection from Video Sequences Using Deep Learning An Overview AISC1710_SPRINGER.pdf*330398*1540237641","Object recognition and detection with deep learning for autonomous driving applications sage_1706.pdf*1214514*1526067960","Object Tracking in Video with TensorFlow msc_thes1610.pdf*23728636*1525990580","Optimizing Video Object Detection via a Scale-Time Lattice_cvpr18.pdf*4205329*1566844357","Seq-NMS for Video Object Detection ax1608.pdf*13719554*1540237642","Video Object Detection for Tractability with Deep Learning Method  CBD17.pdf*1082825*1526004143",52538226,"329*330*331*332*334*335*336*337"])
D.p(["Z:/UofA/PhD/Literature/video_detection/action*0*1656263349","Does Computer Vision Matter for Action 1905.12887.pdf*7465176*1636862857","Learning Spatiotemporal Attention for Egocentric Action Recognition iccvw19.pdf*2054687*1581973882","LSTA Long Short-Term Attention for Egocentric Action Recognition 1811.10698.pdf*2416388*1581973890","Recurrent Tubelet Proposal and Recognition Networks for Action Detection eccv18.pdf*1963886*1548393210","Tube Convolutional Neural Network (T-CNN) for Action Detection in Videos ax1708.pdf*2003896*1525991634","Two-stream convolutional networks for action recognition in videos nips14.pdf*705462*1552961257",16609495,""])
D.p(["Z:/UofA/PhD/Literature/video_detection/efficient*0*1656263349","NoScope Optimizing Neural Network Queries over Video at Scale ax1708 vldb17.pdf*1171667*1556642262",1171667,""])
D.p(["Z:/UofA/PhD/Literature/video_detection/fgfa*0*1656263350","Deep Feature Flow For Video Recognition cvpr17.pdf*3815551*1494805798","Flow-Guided Feature Aggregation for Video Object Detection ax1708 iccv17.pdf*4566766*1540237641","Towards High Performance Video Object Detection ax171130 cvpr18 microsoft.pdf*1302167*1540237642","Towards High Performance Video Object Detection for Mobiles ax180416 microsoft.pdf*799978*1525990787",10484462,""])
D.p(["Z:/UofA/PhD/Literature/video_detection/motion*0*1656263350","Event-based Moving Object Detection and Tracking ax1803.04523.pdf*4133656*1548813740","MODNet Moving Object Detection Network 1709.04821 itsc18.pdf*5966672*1545093040","Online Illumination Invariant Moving Object Detection by Generative Neural Network ax1808.01066.pdf*9093723*1545427725",19194051,"333"])
D.p(["Z:/UofA/PhD/Literature/video_detection/motion/moving_camera*0*1656263352","An effective motion object detection method using optical flow estimation under a moving camera jvcir1808.pdf*3557823*1550875501","Automatic Object Detection In Video Sequences With Camera In Motion (2004).pdf*320397*1551146521","Dense optical flow in stabilized scenes for moving object detection from a moving camera iccas16.pdf*500660*1550875297","Detection of moving objects with a moving camera using non-panoramic background model mva1307_sl.pdf*1736865*1551135146","Detection of Moving Objects with Non-stationary Cameras in 5.8ms Bringing Motion Detection to Your Mobile Device cvprw13.pdf*1662731*1551120452","Moving Object Detection With a Freely Moving Camera via Background Motion Subtraction tcsvt1702.pdf*4120906*1548813861","Moving-object detection method for moving cameras by merging background subtraction and optical flow methods globalsip17.pdf*856329*1550875837","New trends on moving object detection in video images captured by a moving camera A survey cs_review_1805.pdf*2140444*1548813587","Object-Level Motion Detection From Moving Cameras tcsvt17.pdf*3777178*1551120377","Optical Flow Based Background Subtraction with a Moving Camera Application to Autonomous Driving ax1811.06660.pdf*468046*1550873502","Robust Moving Object Detection at Distance in the Visible Spectrum and Beyond Using A Moving Camera cvprw06.pdf*472386*1551146479",19613765,""])
D.p(["Z:/UofA/PhD/Literature/video_detection/notes*0*1656263352","Context Matters Reﬁning Object Detection in Video with Recurrent Neural Networks bmvc16.pdf*8376*1544495139","Flow-Guided Feature Aggregation for Video Object Detection ax1708 iccv17.pdf*7537*1544494782","Object_Detection_from_Video_Tubelets_with_Convolutional_Neural_Networks_CVPR16.pdf*9653*1544474717","Object_Detection_in_Videos_with_Tubelet_Proposal_Networks_ax1704_cvpr17.pdf*7264*1544474891","Online Video Object Detection using Association LSTM iccv17.pdf*7515*1544495146",40345,""])
D.p(["Z:/UofA/PhD/Literature/video_detection/proposals*0*1656263352","4D Generic Video Object Proposals ax1901.09260.pdf*9616353*1552960744","Adaptive video object proposals by a context-aware model mta18_spr.pdf*8549096*1552960771","Detecting temporally consistent objects in videos through object class label propagation. wacv16.pdf*3662476*1552960883","Spatio- temporal object detection proposals eccv14.pdf*708445*1552960365","Track and Segment An Iterative Unsupervised Approach for Video Object Proposals cvpr2016.pdf*3715908*1552960491","Track and Segment An Iterative Unsupervised Approach for Video Object Proposals cvpr2016_supp.pdf*1126834*1447398619","Video object proposals cvprw12.pdf*2593350*1552960464",29972462,""])
D.p(["Z:/UofA/PhD/Literature/video_detection/rnn*0*1696015313","A One-stage Temporal Detector with Attentional LSTM for Video Object Detection 2021.pdf*1268029*1696015215","Context Matters Reﬁning Object Detection in Video with Recurrent Neural Networks bmvc16.pdf*436828*1540237641","Looking Fast and Slow Memory-Guided Mobile Video Object Detection ax1903.10172.pdf*3517147*1570857065","Mobile Video Object Detection with Temporally-Aware Feature Maps cvpr18.pdf*1131536*1556668638","Online Video Object Detection using Association LSTM iccv17.pdf*2011011*1538327203","Recurrent neural networks for object detection in video sequences msc_thes170321.pdf*2513745*1540237642","Temporally Identity-Aware SSD with Attentional LSTM 1803.00197.pdf*1590469*1696015284",12468765,""])
D.p(["Z:/UofA/PhD/Literature/video_detection/tubelets*0*1656263353","Object_Detection_from_Video_Tubelets_with_Convolutional_Neural_Networks_CVPR16.pdf*4478845*1650417010","Object_Detection_in_Videos_with_Tubelet_Proposal_Networks_ax1704_cvpr17.pdf*5453211*1650420765","T-CNN Tubelets with Convolutional Neural Networks for Object Detection from Videos ax1708 tcsvt.pdf*8017039*1650378958",17949095,""])
D.p(["Z:/UofA/PhD/Literature/video_segmentation*0*1699506666","A Video Representation Using Temporal Superpixels cvpr13.pdf*2482774*1498676418","BoLTVOS Box-Level Tracking for Video Object Segmentation 1904.04552.pdf*4339462*1588448978","CDTS Collaborative Detection, Tracking, and Segmentation for Online Multiple Object Segmentation in Videos_iccv17.pdf*5145906*1538356909","DEEP CONVOLUTIONAL NEURAL NETWORKS FOR SEMANTIC VIDEO OBJECT SEGMENTATION mscthes16.pdf*20280619*1540237663","End-to-end Learning of Driving Models from Large-scale Video Datasets arxiv16_12.pdf*12168651*1485834933","End-to-End Video Instance Segmentation with Transformers cvpr21.pdf*4080578*1652975687","Ensemble Video Object Cut in Highly Dynamic Scenes cvpr13.pdf*1370503*1565966387","Fast and Accurate Online Video Object Segmentation via Tracking Parts  1806.02323 cvpr18.pdf*7554325*1538104554","Improving Semantic Segmentation via Video Prediction and Label Relaxation ax1812.01593 cvpr19.pdf*2520578*1566571354","Instance Segmentation and Tracking with Cosine Embeddings and Recurrent Hourglass Networks  1806.02070 miccai08.pdf*3739970*1540237663","Learning Video Object Segmentation from Static Images cvpr17 masktrack.pdf*2418925*1526071571","Learning What to Learn for Video Object Segmentation ax2003.11540.pdf*9979202*1587408754","Motion trajectory segmentation via minimum cost multicuts iccv15.pdf*2555162*1498935614","Online Adaptation of Convolutional Neural Networks for Video Object Segmentation ax1708 bmvc17.pdf*8655048*1526070434","Online Video Object Segmentation via Convolutional Trident Network cvpr17.pdf*2015893*1526070432","Pixel-Level Matching for Video Object Segmentation using Convolutional Neural Networks ax1708 iccv17.pdf*2919182*1540237664","PReMVOS Proposal-generation, Refinement and Merging for Video Object Segmentation accv18.pdf*2272175*1649696924","Video Instance Segmentation 1905.04804 iccv19.pdf*3781879*1610117335","Video Object Segmentation Without Temporal Information ax1709.06031 tpami18.pdf*9678257*1579967058",107959089,"339*340*341*342*343*344"])
D.p(["Z:/UofA/PhD/Literature/video_segmentation/617*0*1658226535","Efficient Hierarchical Graph Based Video Segmentation cvpr10.pdf*9398980*1524718539","Foreground Segmentation Using a Triplet Convolutional Neural Network for Multiscale Feature Encoding ax1801.pdf*3859337*1540237664","FusionSeg Learning to combine motion and appearance for fully automatic segmentation of generic objects in videos cvpr2017.pdf*8336643*1521930351","MaskRNN Instance Level Video Object Segmentation nips17.pdf*12821148*1521931559","OSVOS One-Shot Video Object Segmentation ax1704 cvpr17.pdf*9813182*1524718540","Unsupervised Learning of Video Representations using LSTMs ax15.pdf*2294111*1521757932","Unsupervised Learning of Visual Representations using Videos ax15.pdf*3737012*1521757911","Unsupervised object segmentation in video by efficient selection of highly probable positive features ax170419.pdf*1370536*1521757594","Unsupervised Video Segmentation via Spatio-Temporally Nonlocal Appearance Learning ax1612.pdf*2950388*1540237665","Video Segmentation by Non-Local Consensus Voting bmvc14.pdf*1537947*1521758008","Video Segmentation via Object Flow cvpr16.pdf*8992124*1550872389",65111408,""])
D.p(["Z:/UofA/PhD/Literature/video_segmentation/davis_2017*0*1656263357","Instance Re-Identification Flow for Video Object Segmentation DAVIS-Challenge-3rd-Team.pdf*1735609*1526071190","Learning to Segment Instances in Videos with Spatial Propagation Network cvprw17DAVIS-Challenge-6th-Team.pdf*343106*1526071365","Lucid Data Dreaming for Object Tracking cvprw17 DAVIS-Challenge-2nd-Team.pdf*2063836*1526071188","Multiple-Instance Video Segmentation with Sequence-Specific Object Proposals cvprw17DAVIS-Challenge-4th-Team.pdf*6196174*1526071364","One-Shot Video Object Segmentation with Iterative Online Fine-Tuning cvprw17DAVIS-Challenge-8th-Team.pdf*1809974*1526071373","Online Adaptation of Convolutional Neural Networks for the 2017 DAVIS Challenge cvprw17 DAVIS-Challenge-5th-Team.pdf*1978929*1526071365","Some Promising Ideas about Multi-instance Video Segmentation cvprw17DAVIS-Challenge-7th-Team.pdf*1671535*1526071368","Video Object Segmentation using Tracked Object Proposals cvprw17 DAVIS-Challenge-9th-Team.pdf*1862158*1526071375","Video Object Segmentation with Re-identification cvprw17 DAVIS-Challenge-1st-Team.pdf*3723412*1526071188",21384733,""])
D.p(["Z:/UofA/PhD/Literature/video_segmentation/instance*0*1686107747","IDOL In Defense of Online Models for Video Instance Segmentation 2207.10661 eccv22.pdf*14865724*1666758228","SeqFormer Sequential Transformer for Video Instance Segmentation 2112.08275 eccv22.pdf*11365059*1686107736","VITA Video Instance Segmentation via Object Token Association 2206.04403.pdf*1617105*1686107673",27847888,""])
D.p(["Z:/UofA/PhD/Literature/video_segmentation/menna*0*1656263358","RTSEG REAL-TIME SEMANTIC SEGMENTATION COMPARATIVE STUDY ax1803.02758 icip18.pdf*1390307*1545096058","ShuffleSeg Real-time Semantic Segmentation Network ax1803.03816.pdf*761547*1545098116","Video Segmentation using Teacher Student Adaptation in HRI ax1810.07733.pdf*4691602*1545096357",6843456,""])
D.p(["Z:/UofA/PhD/Literature/video_segmentation/motion*0*1656263358","Coherent Motion Segmentation in Moving Camera Videos Using Optical Flow Orientations iccv13.pdf*2336646*1587343955","Learning to Segment Moving Objects in Videos ax1505 cvpr15.pdf*3985721*1526051489","Segmentation of Moving Objects by Long Term Video Analysis tpami14.pdf*2634371*1498860314",8956738,""])
D.p(["Z:/UofA/PhD/Literature/video_segmentation/panoptic*0*1699722959","A Generalist Framework for Panoptic Segmentation of Images and Videos iccv23 2210.06366.pdf*13457056*1700149574",13457056,""])
D.p(["Z:/UofA/PhD/Literature/video_synthesis*0*1656263358","Deep multi-scale video prediction beyond mean square error ax1602 iclr16.pdf*3995755*1540237686","list.txt*434*1520358242",3996189,""])
D.p(["Z:/UofA/PhD/Literature/video prediction*0*1656263347","VideoBERT A Joint Model for Video and Language Representation Learning 1904.01766v2 iccv19.pdf*6200997*1596071010",6200997,""])



		delete(Array.prototype.p);	// remove alias added above

		$(document).ready(function(){

			var numberOfFiles = 1743;

			var linkFiles = false;
			var linkProtocol = "";
			var linkRoot = "";
			var sourceRoot = "Z:/UofA/PhD/Literature";
			var sourceParent = sourceRoot.substring( 0, sourceRoot.lastIndexOf("/") +1 );
			var originalHash = location.hash.replace(/#/,"");
			var SelectedFolderID = "-1";
			var currentView;
			var onlyLinkExtensions = [];	// example: ["jpg","png"]

			/* ---  Init --- */

			$("#tot_size").text( bytesToSize( $("#tot_size").text() ) );

			$("#loading").remove();
			$("#content").show();

			// set size of areas
			$("#content").height( $("#wrapper").outerHeight(true) - $("#app_header").outerHeight(true) -1 );
			setTimeout( function() {
				$("#list_files").height( $("#content").height() - $("#list_header").outerHeight(true) - $("#list_footer").outerHeight(true) - 1);
			},1);
			
			$("#content").splitter( { sizeLeft: 200 } );

			// build parent folder lookup
			window.parent_folders = [];
			parent_folders[0] = 0;
			var numDirs = dirs.length;
			for( var id=0; id< numDirs; id++ ) {
				var subdirs = getSubdirs( id );
				if( subdirs != "" ) {
					for( var c=0; c<subdirs.length; c++ ) {
						parent_folders[ subdirs[c] ] = id;
					}
				}
			}


			$.tablesorter.addParser({
				// set a unique id
				id: 'datasort',
				is: function(s, table, cell, $cell) {
					// return false so this parser is not auto detected
					return false;
				},
				format: function(s, table, cell, cellIndex) {
					var $cell = $(cell);
					// returns data-attribute, or cell text (s) if it doesn't exist
					return $cell.attr('data-sort') || s;
				},
				// flag for filter widget (true = ALWAYS search parsed values; false = search cell text)
				parsed: false,
				// set type, either numeric or text
				type: 'numeric'
			});


			


			/* --- Events --- */

			$("#search_form").submit(function(){
				return false;
			});

			var addFolderClickEventHandlers = function() {
				$("#list_files a.folder_link").click(function() {
					expandToFolder( $(this).attr('id') );
					return false; 
				});
			}

			// handle clicks on folders in file list
			$("body").delegate("a.folder_link", "click", function() { 
				expandToFolder( $(this).attr('id') );
				return false; 
			});

			// Handle window resize
			var resizeHandler = debounce(function() {
				// resize is mostly automatic, but we need set the height manually and to tell the splitter to redraw
				$("#content").height( $("#wrapper").outerHeight(true) - $("#app_header").outerHeight(true) -1 );
				$("#content").trigger("resize");
				// for some reason it still did not redraw correctly unless I added a second resize trigger...
				$("#content").height( $("#wrapper").outerHeight(true) - $("#app_header").outerHeight(true) -1 );
				$("#content").trigger("resize");
				// also re-calculate height of file list
				$("#list_files").height( $("#content").height() - $("#list_header").outerHeight(true) - $("#list_footer").outerHeight(true) - 1);				
			}, 250);
			window.addEventListener('resize', resizeHandler);


			/* --- Search for files --- */

			var searchDelay = 250;
			if( numberOfFiles > 1000 ) searchDelay = 1000;

			var searchKeyPressHandler = debounce(function(keyEvent) {
				// cancel debounced event if no keyEvent
				if(!keyEvent) return;

				// skip searching on keys: tab, shift, ctrl, alt, end, home, arrows
				var keysToSkip = [9,16,17,18,35,36,37,38,39,40];
				if(keysToSkip.indexOf(keyEvent.keyCode) !== -1) {
					return;
				}

				// on mobile, skip auto search on keypress
				if (/Mobi/.test(navigator.userAgent)) {
					return;
				}

				doSearch(false);
			}, searchDelay);
			document.getElementById("search_text").addEventListener('input', searchKeyPressHandler);	// for handling pressing the x
			document.getElementById("search_text").addEventListener('keypress', searchKeyPressHandler);
			document.getElementById("search_text").addEventListener('keypress', function(keyEvent) {
				if( keyEvent.keyCode == 13 ) {		// on enter key search immediately
					searchKeyPressHandler(null);		// cancel any current debounced event
					doSearch(true);
				}
			});


			var SearchFilenames = [];
			var SearchLocations = [];
			var SearchLocationsRaw = [];
			var SearchLocationsID = [];
			var SearchIsDir = [];
			var PreviouslySelectedNode = null;
			var PreviousSearchFor = "";
			var PreviousSearchForMode = "all";
			var currentDir = "";
			var currentDirID = -1;

			function doSearch(enterPressed) {

				var SearchFor = $("#search_text").val().toLowerCase();

				if (String.prototype.trim) {	// in case not available in browser
					SearchFor = SearchFor.trim();
				}

				// prevent automatic search for short queries
				if(SearchFor.length > 0 && SearchFor.length <= 2 && !enterPressed) return;

				// search only current folder and optionally subfolders using > and >>
				var SearchForMode = "all";
				var searchThisDirOnly = false;
				var searchThisDirOnlyIncludeSubdirs = false;
				if(SearchFor.indexOf(">") === 0) {
					searchThisDirOnly = true;
					SearchForMode = "dir";
					SearchFor = SearchFor.substr(1);	// removes first character
					if(SearchFor.indexOf(">") === 0) {
						searchThisDirOnlyIncludeSubdirs = true;
						SearchFor = SearchFor.substr(1);
						SearchForMode = "subdirs";
					}
				}

				// prevent searching twice
				if(SearchFor === PreviousSearchFor && PreviousSearchForMode === SearchForMode) return;
				PreviousSearchFor = SearchFor;
				PreviousSearchForMode = SearchForMode;

				if( SearchFor === "" )
				{
					if( PreviouslySelectedNode != null )
					{
						PreviouslySelectedNode.activate();
						PreviouslySelectedNode = null;
					}
					return;
				}

				var showLocationColumn = true;

				if( numberOfFiles > 5000 ) {
					$("#search_indicator").show();
                    //$("#list_header").html( "Searching..." );
					showLocationColumn = false;
				}
				
				location.hash = "";
				
				setTimeout(function(){ // timeout allows redrawing screen before possible time consuming search

					if( SelectedFolderID != -1 )
					{
						PreviouslySelectedNode = $("#treeview").dynatree("getActiveNode");
						SelectedFolderID = "-1";
						$("#treeview").dynatree("getActiveNode").deactivate();
					}

					var hide_root = ( sourceRoot.length > 3 );
					var numDirs = dirs.length;
					var c;

					// if no previous search, do some pre-processing for faster search
					if( SearchFilenames.length === 0 )
					{
						var nFound = 0;
						for( c=1; c<numDirs; c++ ) // dirs first...
						{
							SearchFilenames[nFound] = dirs[c][0].split("*");
							SearchFilenames[nFound][0] = getDirName( c );
							SearchFilenames[nFound][3] = SearchFilenames[nFound][0];		// keep original name (in non-lowercase)
							SearchFilenames[nFound][0] = SearchFilenames[nFound][0].toLowerCase();
							//SearchFilenames[nFound][1] = Number(SearchFilenames[nFound][1]);
							SearchFilenames[nFound][1] = Number(getDirTreeSize( c ));
							SearchLocationsRaw[nFound] = getDirNameAndPath(c);
							if( hide_root )
								SearchLocations[nFound] = SearchLocationsRaw[nFound].substring(sourceParent.length);
							else
								SearchLocations[nFound] = SearchLocationsRaw[nFound];
							SearchLocations[nFound] = SearchLocations[nFound].replace(/\//g,"\\")	// replace forward slash / with windows style \ backslash
							SearchLocationsID[nFound] = c;
							SearchIsDir[nFound] = true;
							nFound++;
						}
						for( c=0; c< numDirs; c++ ) // ...then all files
						{
							var arrLength = dirs[c].length;
							for( var c2=1; c2< arrLength-2; c2++ )
							{
								SearchFilenames[nFound] = dirs[c][c2].split("*");
								SearchFilenames[nFound][3] = SearchFilenames[nFound][0];		// keep original name (in non-lowercase)
								SearchFilenames[nFound][0] = SearchFilenames[nFound][0].toLowerCase();
								SearchFilenames[nFound][1] = Number(SearchFilenames[nFound][1]);
								SearchLocationsRaw[nFound] = getDirNameAndPath(c);
								if( hide_root )
									SearchLocations[nFound] = SearchLocationsRaw[nFound].substring(sourceParent.length);
								else
									SearchLocations[nFound] = SearchLocationsRaw[nFound];
								SearchLocations[nFound] = SearchLocations[nFound].replace(/\//g,"\\")	// replace forward slash / with windows style \ backslash
								SearchLocationsID[nFound] = c;
								SearchIsDir[nFound] = false;
								nFound++;
							}
						}
					}

					var locationHtml = "";

					if(showLocationColumn) locationHtml = "<th>Folder</th>";

					currentView = [];
					var table_html = "";
					table_html += "<table id='files' class='tablesorter'><thead><tr><th>Name</th>" + 
									locationHtml + 
									"<th>Size</th><th>Modified</th></tr></thead><tbody>";

					var countFiles = 0;
					var countDirs = 0;
					var sizeFiles = 0;
					var sizeDirs = 0;

					function foundItem(index) {
						var dir_tmp = getDirNameAndPath(SearchLocationsID[index]);

						if(searchThisDirOnly) {
							var path = getPathToDir(SearchLocationsID[index]);

							if(path.indexOf(currentDirID) === -1) {
								// skip items not in current path
								return;
							}

							if(path[path.length-1] === currentDirID) {
								// file in current dir --> ok for both searchThisDirOnly and searchThisDirOnlyIncludeSubdirs
								if(SearchIsDir[index] && SearchLocationsID[index] == currentDirID) {
									// always skip current dir which appears here
									return;
								}
								console.log("   file in current dir");
							} else if(SearchIsDir[index] && path[path.length-2] === currentDirID) {
								// dir in current dir are also ok
							} else if(path.indexOf(currentDirID) !== -1) {
								// item is in a subdir: ok for searchThisDirOnlyIncludeSubdirs
								if(!searchThisDirOnlyIncludeSubdirs) {
									return;
								}
							}
						}

						dir_tmp = dir_tmp.substring(sourceRoot.length);
						if( dir_tmp != "" ) dir_tmp += "/";

						if( SearchIsDir[index] === true )
						{
							countDirs++;
							sizeDirs += SearchFilenames[index][1];
							var subdir_id = parent_folders[ SearchLocationsID[index] ];
							
							var timestamp = timestampToDate(SearchFilenames[index][2]);

							locationHtml = "";
							if(showLocationColumn) {
								var located_in = SearchLocations[index];
								if( located_in === "" ) located_in = "[.]"
								located_in = located_in.substring( 0, located_in.lastIndexOf("\\") );
								locationHtml = "<td><span class='file_folder'><a href=\"#\" class=\"folder_link\" id=\"" + subdir_id + "\"> " + located_in + "</a></span></td>";
							}

							table_html += 
								"<tr>" + 
									"<td><span class='file_folder'><a href=\"#\" class=\"folder_link\" id=\"" + SearchLocationsID[index] + "\"> " + SearchFilenames[index][3] + "</a></span></td>" + 
									locationHtml + 
									"<td class='size' data-sort='" + SearchFilenames[index][1] + "'>" + bytesToSize( SearchFilenames[index][1] ) + "</td>" + 
									"<td class='date' data-sort='" + SearchFilenames[index][2] + "'>" + timestamp + "</td>" + 
								"</tr>";
							currentView.push( { "name": SearchFilenames[index][3], "path": SearchLocationsRaw[index].replace(/\//g,"\\"), "type": "dir", "size": SearchFilenames[index][1], "date": SearchFilenames[index][2] } );
						}
						else	// files
						{
							sizeFiles += SearchFilenames[index][1];
							countFiles++;

							var file_tmp = SearchFilenames[index][3];

							if( linkFiles )
							{
								var ext = file_tmp.split('.').pop();
								if(onlyLinkExtensions.length === 0 || onlyLinkExtensions.indexOf(ext) !== -1) {

									file_tmp = linkProtocol + linkRoot + dir_tmp.replace("\\","/") + SearchFilenames[index][3] + "\">";
									if( navigator.userAgent.toLowerCase().indexOf("msie") !== -1  &&  linkProtocol.indexOf("file:") !== -1 )
									{
										file_tmp = "javascript:alert('Internet Explorer does not allow linking to local files...')" + "\">";
									}
									if( file_tmp.substr(0,1) === "/" ) file_tmp = file_tmp.substr(1);
									file_tmp = file_tmp.replace(/\\/g,"/");
									file_tmp = file_tmp.replace(/#/g,"%23");
							
									var indx = file_tmp.indexOf("://");
									if( indx !== -1 )
									{
										var protocol_tmp = file_tmp.substr(0,indx+3);
										file_tmp = file_tmp.substr(indx+3);
										file_tmp = file_tmp.replace(/\/\//g,"/");
										file_tmp = protocol_tmp + file_tmp;
									}
									else
									{
										file_tmp = file_tmp.replace(/\/\//g,"/");
									}

									file_tmp = "<a href=\"" + file_tmp + SearchFilenames[index][3] + "</a>";
								}
							}

							locationHtml = "";
							if(showLocationColumn) {
								var located_in = SearchLocations[index];
								if( located_in === "" ) located_in = "[.]"
								locationHtml = "<td><span class='file_folder'><a href=\"#\" class=\"folder_link\" id=\"" + SearchLocationsID[index] + "\"> " + located_in + "</a></span></td>";
							}


							var timestamp = timestampToDate(SearchFilenames[index][2]);
							table_html += 
								"<tr>" + 
									"<td><span class='file'>" + file_tmp + "</span></td>" + 
									locationHtml + 
									"<td class='size' data-sort='" + SearchFilenames[index][1] + "'>" + bytesToSize( SearchFilenames[index][1] ) + "</td>" + 
									"<td class='date' data-sort='" + SearchFilenames[index][2] + "'>" + timestamp + "</td>" + 
								"</tr>";

							currentView.push( { "name": SearchFilenames[index][3], "path": SearchLocationsRaw[index].replace(/\//g,"\\"), "type": "file", "size": SearchFilenames[index][1], "date": SearchFilenames[index][2] } );

						}
					}
					
					// search for matches
					// optimization: use indexOf if no wildcards since it's faster
					if(SearchFor.indexOf("*") !== -1 || SearchFor.indexOf("?") !== -1) {
						var SearchForEscaped = SearchFor.replace(/[\-\[\]\/\{\}\(\)\+\.\\\^\$\|]/g, "\\$&");
						SearchForEscaped = SearchForEscaped.replace(/\*/g, ".*");
						SearchForEscaped = SearchForEscaped.replace(/\?/g, ".");
						var regEx = new RegExp(SearchForEscaped);

						for( c=0; c< SearchFilenames.length; c++ )
						{
							if( regEx.test(SearchFilenames[c][0]) ) {
								foundItem(c);
							}
						}
					} else {
						for( c=0; c< SearchFilenames.length; c++ )
						{
							if( SearchFilenames[c][0].indexOf(SearchFor) !== -1 ) {
								foundItem(c);
							}
						}
					}

					table_html += "</tbody></table>";
					
					$("#list_header").html( "Search Results <span class='path_divider'></span>" );
					document.getElementById("list_files").innerHTML = table_html;
					$("#search_indicator").hide();
					addFolderClickEventHandlers();

					var tablesorterHeaders = { 1 : { sorter: 'datasort' }, 2 : { sorter: 'datasort' } }
					if(showLocationColumn) {
						tablesorterHeaders = { 2 : { sorter: 'datasort' }, 3 : { sorter: 'datasort' } }
					}

					$("#files").tablesorter({
						sortInitialOrder: "desc",
						headers: tablesorterHeaders
					});

					var sFiles = " files"; if(countFiles===1) sFiles = " file";
					var sDirs = " folders"; if(countDirs===1) sDirs = " folder";
					$("#list_footer_info_label").html( countDirs + sDirs + " (" + bytesToSize( sizeDirs , 0 ) + "), " + countFiles + sFiles + " (" + bytesToSize( sizeFiles , 0 ) + ")" );
				
				}, 50); // end setTimeout before search
			}; // end doSearch()


			/* --- Show content of a folder --- */
			
			function ShowFolder( FolderID )
			{
				var c;
			
				if( SelectedFolderID === FolderID ) return false;
				$("#treeview #" + SelectedFolderID ).removeClass("treeview_bold");
				SelectedFolderID = FolderID;

				$("#search_text").val("");
				PreviousSearchFor = "";
			
				var path = 	getPathToDir(FolderID);
				var currentViewPath = getDirNameAndPath(FolderID).replace(/\//g,"\\");
				var breadcrumbs = "";
				for( c=0; c<path.length; c++ )
				{
					var dirName = getDirName(path[c]);
					if(c===0) {
						dirName = dirName.replace(/\:\//g,"");	// remove :\ from volume labels
					}
					breadcrumbs += "<a href=\"#\" class=\"folder_link\" id=\"" + path[c] + "\">" + dirName + "</a>" + "<span class='path_divider'></span>";
				}

				currentDir = getDirNameAndPath(FolderID);
				currentDirID = Number(FolderID);

				location.hash = '#' + currentDir;

				$("#list_header").html( breadcrumbs );

				var table_html = "";
				var showParentFolderClass = "";
				if( FolderID != 0 ) {
					showParentFolderClass = " has-parent-folder"
					table_html += "<span id='parent_folder' class='file_folder'><a href=\"#\" class=\"folder_link\" id=\"" + parent_folders[FolderID] + "\"> [..]</a></span>\n";
					table_html += "<div id='parent_folder_border'></div>";
				}
				table_html += "<table id='files' class='tablesorter" + showParentFolderClass + "'><thead><th>Name</th><th>Size</th><th>Modified</th></tr></thead><tbody>\n";

				currentView = [];
				var countFiles = 0;
				var countDirs = 0;
				var subdirTotSizes = 0;

				// folders
				var subdirs = getSubdirs( SelectedFolderID );
				if( subdirs != "" )
				{
					for( c=0; c< subdirs.length; c++ )
					{
						countDirs++;
						var sTmp = dirs[ subdirs[c] ][0].split("*");
						var name = sTmp[0].substring( sTmp[0].lastIndexOf("/") +1 );
						var dirSize = getDirTreeSize( subdirs[c] );
						subdirTotSizes += dirSize;
						var timestamp = timestampToDate(sTmp[2]);
						table_html += 
							"<tr>" + 
								"<td><span class='file_folder'><a href=\"#\" class=\"folder_link\" id=\"" + subdirs[c] + "\"> " + name + "</a></span></td>" + 
								"<td class='size' data-sort='" + dirSize + "'>" + bytesToSize( dirSize ) + "</td>" + 
								"<td class='date' data-sort='" + sTmp[2] + "'>" + timestamp + "</td>" + 
							"</tr>\n";
						currentView.push( { "name": name, "path": currentViewPath, "type": "dir", "size": dirSize, "date": sTmp[2] } );
					}
				}

				// files
				for( c=1; c< dirs[ SelectedFolderID ].length-2; c++ )
				{
					countFiles++;
					var sTmp = dirs[ SelectedFolderID ][c].split("*");
					var file_tmp = sTmp[0];
					var dir_tmp = getDirNameAndPath(SelectedFolderID).substring(sourceRoot.length);
					if( dir_tmp != "" ) dir_tmp += "/";
					if( linkFiles )
					{

						var ext = file_tmp.split('.').pop();
						if(onlyLinkExtensions.length === 0 || onlyLinkExtensions.indexOf(ext) !== -1) {
							file_tmp = linkProtocol + linkRoot + dir_tmp + sTmp[0] + "\">";
							if( navigator.userAgent.toLowerCase().indexOf("msie") !== -1  &&  linkProtocol.indexOf("file:") !== -1 )
							{
								file_tmp = "javascript:alert('Internet Explorer does not allow linking to local files...')" + "\">";
							}
							if( file_tmp.substr(0,1) === "/" ) file_tmp = file_tmp.substr(1);
							file_tmp = file_tmp.replace(/\\/g,"/");
							file_tmp = file_tmp.replace(/#/g,"%23");

							var indx = file_tmp.indexOf("://");
							if( indx !== -1 )
							{
								var protocol_tmp = file_tmp.substr(0,indx+3);
								file_tmp = file_tmp.substr(indx+3);
								file_tmp = file_tmp.replace(/\/\//g,"/");
								file_tmp = protocol_tmp + file_tmp;
							}
							else
							{
								file_tmp = file_tmp.replace(/\/\//g,"/");
							}

							file_tmp = "<a href=\"" + file_tmp + sTmp[0] + "</a>";
						}
					}
					
					var timestamp = timestampToDate(sTmp[2]);

					table_html += 
						"<tr>" + 
							"<td><span class='file'>" + file_tmp + "</span></td>" + 
							"<td class='size' data-sort='" + sTmp[1] + "'>" + bytesToSize( sTmp[1] ) + "</td>" + 
							"<td class='date' data-sort='" + sTmp[2] + "'>" + timestamp + "</td>" + 
						"</tr>\n";
					currentView.push( { "name": sTmp[0], "path": currentViewPath, "type": "file", "size": sTmp[1], "date": sTmp[2] } );
				}

				table_html += "</tbody></table>\n";

				document.getElementById("list_files").innerHTML = table_html;
				addFolderClickEventHandlers();
				$("#files").tablesorter({
					sortInitialOrder: "desc",
					headers: {
						1 : { sorter: 'datasort' },
						2 : { sorter: 'datasort' }
					}
				});


				var sFiles = " files"; if(countFiles===1) sFiles = " file";
				var sDirs = " folders"; if(countDirs===1) sDirs = " folder";
				$("#list_footer_info_label").html( countDirs + sDirs + " (" + bytesToSize( subdirTotSizes )+ "), " + countFiles + sFiles + " (" + bytesToSize( dirs[ SelectedFolderID ][ dirs[ SelectedFolderID ].length-2 ] )+ ")" );

				$("#treeview #" + SelectedFolderID ).addClass("treeview_bold");

				return false;
			}


			/* --- Treeview --- */

			function PopulateTreeviewNode( node ) {
				var subdirs = getSubdirs( node.data.key );
				if( subdirs != "" )
				{
					var len = subdirs.length;
					for( var c=0; c<len; c++ )
					{
						var newNode = node.addChild({
							title: getDirName( subdirs[c] ),
							key: subdirs[c],
							unselectable: true,
							isFolder: true,
							tooltip: bytesToSize(getDirTreeSize( subdirs[c] )),
						});
						PopulateTreeviewNode( newNode )
					}
				}
			}

			$("#treeview").dynatree({
				clickFolderMode: 1,
				minExpandLevel: 2,
				fx: { height: "toggle", duration: 100 },
				onActivate: function(node) {
					ShowFolder( node.data.key );
				},
				onDblClick: function(node) {
					node.expand( !node.isExpanded() );
				},
			});

			// init treeview items
			var rootNode = $("#treeview").dynatree("getRoot").addChild({
				title: getDirName( 0 ).replace(/\//,"\\"),
				key: "0",
				isFolder: true,
				tooltip: bytesToSize(getDirTreeSize( 0 )),
			});
            rootNode.tree.enableUpdate(false);
            PopulateTreeviewNode( rootNode );
            rootNode.tree.enableUpdate(true);
            rootNode.activate();

			// browse directly to folder at startup
			if(originalHash !== "") {
				var folderId = getFolderIdFromPath( originalHash );
				if(folderId) {
					expandToFolder( folderId )
				} else {
					location.hash = "";
				}
			}

			/* --- Export LightBox --- */

			function populateExport() {
				var output_plain = "";
				var output_json = [];
				var output_csv = "";

				// get the settings
				var showFiles = $("#export_checkbox_files").prop("checked")
				var showDirs = $("#export_checkbox_dirs").prop("checked")
				var fullPath = $("#export_checkbox_path").prop("checked")

				var colPath = $("#export_checkbox_col_path").prop("checked")
				var colType = $("#export_checkbox_col_type").prop("checked")
				var colSize = $("#export_checkbox_col_size").prop("checked")
				var colDate = $("#export_checkbox_col_date").prop("checked")

				var type = $("#export_lightbox input[type='radio']:checked").val();

				// set csv header
				var csv_line = "\"Name\"";
				if(colPath) csv_line += ",\"Path\"";
				if(colType) csv_line += ",\"Type\"";
				if(colSize) csv_line += ",\"Size\"";
				if(colDate) csv_line += ",\"Date\"";
				output_csv = csv_line + "\n";

				// collect and format items
				for(var i=0; i<currentView.length; i++) {
					
					var path = "";
					if(fullPath) path = currentView[i].path + "\\";

					var json_line = { "name": (path + currentView[i].name) }
					if(colPath) json_line.path = currentView[i].path;
					if(colType) json_line.type = currentView[i].type;
					if(colSize) json_line.size = currentView[i].size;
					if(colDate) json_line.date = timestampToIsoString(currentView[i].date);

					var csv_line = "\"" + path + currentView[i].name + "\"";
					if(colPath) csv_line += ",\"" + currentView[i].path + "\"";
					if(colType) csv_line += ",\"" + currentView[i].type + "\"";
					if(colSize) csv_line += ",\"" + currentView[i].size + "\"";
					if(colDate) csv_line += ",\"" + timestampToIsoString(currentView[i].date) + "\"";

					if(showFiles && currentView[i].type == "file") {
						output_plain += path + currentView[i].name + "\n";
						output_json.push(json_line);
						output_csv += csv_line + "\n";
					}
					if(showDirs && currentView[i].type == "dir") {
						output_plain += path + currentView[i].name + "\n";
						output_json.push(json_line);
						output_csv += csv_line + "\n";
					}
				}
		
				// print items
				var output = "";
				if(type == "plain") {
					output = output_plain;
				} else if(type == "json") {
					output = JSON.stringify(output_json).replace(/},/g,"},\n").replace(/^\[/,"[\n").replace(/\]$/,"\n]");
				} else if(type == "csv") {
					output = output_csv;
				}
				$("#export_text").text(output).focus().select();
			}
			
			$("#list_footer_open_export").click(function() {
				var windowHeight = $("body").height();
				$("#export_checkbox_files").prop("checked", true);
				$("input[id^=export_checkbox_col]").attr("disabled", true);
				$("#export_options_columns").css("opacity", "0.5");
				populateExport();
				
				$("#export_content").innerHeight( windowHeight - 80);
				$("#export_content").css("top", 40);
				$("#export_lightbox").fadeIn("fast", function() {
					$("#export_text").focus().select();
				});
			});
			
			$("#export_save").click(function() {
				var type = $("#export_lightbox input[type='radio']:checked").val();
				if(type == "plain") {
					downloadToFile($("#export_text").text(), 'snap2html_export.txt', 'text/plain;encoding:utf-8');
				} else if(type == "json") {
					downloadToFile($("#export_text").text(), 'snap2html_export.json', 'application/json;encoding:utf-8');
				} else if(type == "csv") {
					downloadToFile($("#export_text").text(), 'snap2html_export.csv', 'text/csv;encoding:utf-8');
				}
			});


			$("#export_close").click(function() {
				$("#export_lightbox").fadeOut("fast");
			});

			$("#export_content").click(function(event) {
				event.stopPropagation();
			});
			$("#export_lightbox").click(function() {
				$("#export_lightbox").fadeOut("fast");
			});
			$("#export_lightbox input[type=radio]").click(function() {
				var type = $("#export_lightbox input[type='radio']:checked").val();
				if(type !== "plain") {
					$("input[id^=export_checkbox_col]").removeAttr("disabled");
					$("#export_options_columns").css("opacity", 1);
				} else {
					$("input[id^=export_checkbox_col]").attr("disabled", true)
					$("#export_options_columns").css("opacity", 0.5);
				}
			});
			$("#export_lightbox input[type=checkbox], #export_lightbox input[type=radio]").click(function() {
				populateExport();
			});

			document.addEventListener('keypress', function(keyEvent) {
				if( keyEvent.keyCode == 27 ) {	// esc
					if($("#csv_lightbox").length > 0) {
						$("#csv_lightbox").fadeOut("fast");
					}
				}
			});

			/* --- Helper Functions --- */

			function expandToFolder( id ) {
				var tree = $("#treeview").dynatree("getTree");
				var node = tree.getNodeByKey( id.toString() );
				if(node) {
					node.activate();
				}
			}

			function getFolderIdFromPath( path ) {
				for( var c=0; c<numDirs; c++ ) {
					if(dirs[c][0].split("*")[0] == path) {
						return c;
					};
				}
				return null;
			}

			function getDirName( id ) {
				if( dirs.length <= id ) return "";
				var tmp = dirs[id][0].split("*");
				var tmp2 = tmp[0].substring(tmp[0].lastIndexOf("/")+1);				
				if( tmp2 === "" ) return tmp[0]; else return tmp2;
			}

			function getDirNameAndPath( id ) {
				if( dirs.length <= id ) return "";
				var tmp = dirs[id][0].split("*");
				return tmp[0];
			}

			function getSubdirs( id ) {
				if( dirs.length <= id ) return "";
				return dirs[id][ dirs[id].length-1 ].split("*");
			}

			function getPathToDir( id ) {
				var parentId = parent_folders[id];
				var path = [];
				if(id != 0) {
					path.push(id);
				}
				while(parentId > 0)	 {
					path.push(parentId);
					parentId = parent_folders[parentId];
				}
				path.push(0);
				return path.reverse();
			}

			function getDirSize( id ) {
				if( dirs.length <= id ) return "0";
				return dirs[id][ dirs[id].length-2 ];
			}

			function getDirTreeSize( id ) {
				if( dirs.length <= id ) return "0";
				var totSize = getDirSize(id);
				var subdirs = getSubdirs( id );
				if( subdirs != "" )
				{
					var len = subdirs.length;
					for( var c=0; c<len; c++ )
					{
						totSize += getDirTreeSize( subdirs[c] );
					}
				}
				return totSize;
			}

			function bytesToSize(bytes) {  
				var kilobyte = 1024;
				var megabyte = kilobyte * 1024;
				var gigabyte = megabyte * 1024;
				var terabyte = gigabyte * 1024;
			   
				if ((bytes >= 0) && (bytes < kilobyte)) {
					return bytes + ' bytes';
			 
				} else if ((bytes >= kilobyte) && (bytes < megabyte)) {
					return (bytes / kilobyte).toFixed(0) + ' KB';
			 
				} else if ((bytes >= megabyte) && (bytes < gigabyte)) {
					return (bytes / megabyte).toFixed(1) + ' MB';
			 
				} else if ((bytes >= gigabyte) && (bytes < terabyte)) {
					return (bytes / gigabyte).toFixed(2) + ' GB';
			 
				} else if (bytes >= terabyte) {
					return (bytes / terabyte).toFixed(2) + ' TB';
			 
				} else {
					return bytes + ' bytes';
				}
			}

			function timestampToDate(timestamp){
				// Convert UNIX timestamp to local date
				// If you don't like the date format, try something else, such as toLocaleDateString() manually formatting the date here
				return new Date(timestamp * 1000).toLocaleString();
			}
			function timestampToIsoString(timestamp){
				// Convert UNIX timestamp to ISO string (for use in export view)
				return new Date(timestamp * 1000).toISOString();
			}
			
			
			// debounce() from Underscore.js
			// Returns a function, that, as long as it continues to be invoked, will not
			// be triggered. The function will be called after it stops being called for
			// N milliseconds. If `immediate` is passed, trigger the function on the
			// leading edge, instead of the trailing.
			function debounce(func, wait, immediate) {
				var timeout;
				return function() {
					var context = this, args = arguments;
					var later = function() {
						timeout = null;
						if (!immediate) func.apply(context, args);
					};
					var callNow = immediate && !timeout;
					clearTimeout(timeout);
					timeout = setTimeout(later, wait);
					if (callNow) func.apply(context, args);
				};
			};

			// Save export to local file. Based on https://stackoverflow.com/a/29304414/1087811
			function downloadToFile(content, fileName, mimeType) {
			  var a = document.createElement('a');
			  mimeType = mimeType || 'application/octet-stream';

			  if (navigator.msSaveBlob) { // IE10
				navigator.msSaveBlob(new Blob([content], {
				  type: mimeType
				}), fileName);
			  } else if (URL && 'download' in a) { //html5 A[download]
				a.href = URL.createObjectURL(new Blob([content], {
				  type: mimeType
				}));
				a.setAttribute('download', fileName);
				document.body.appendChild(a);
				a.click();
				document.body.removeChild(a);
			  } else {
				location.href = 'data:application/octet-stream,' + encodeURIComponent(content); // only this mime type is supported
			  }
			}
			
		}); // end $(document).ready
	</script>
	
	</head>

	<body>

	<div id="wrapper" style="height:100%;">
	
		<div id="app_header" class="app_header">
		
			<span class="app_header_icon"></span>
		
			<form class="app_header_search" id="search_form" action="#">
				search: <input type="search" id="search_text" title="Search Box"> <div onclick="javascript:alert('Search Tips:\n\nUse * and ? as wildcards. * matches zero or more characters, ? matches exactly one character.\n\nPrefix your search with &gt; to search only the current folder or &gt;&gt; to search the current folder and sub folders.');" class="app_header_search_help">?</div>
			</form>

			<h1>Literature</h1>
			<div class="app_header_stats">1743 files in 347 folders (<span id="tot_size">6186486135</span>)<br>Generated 2023-11-22 11:58 AM by <a href="http://www.rlvision.com">Snap2HTML</a></div>

		</div>

		<div id="loading" class="loading"><b>Loading...</b><p class="loading_info">(if nothing happens, make sure javascript is enabled and allowed to execute, or try another browser)</p></div>
		
		<div id="content" class="content">
			<div id="treeview" class="treeview"></div>

			<div id="list_container" class="list_container">
				<div id="search_indicator" class="search_indicator">
					Searching...
				</div>
				<div id="list_header" class="list_header"></div>
				<div id="list_files" class="list_files"></div>
				<div id="list_footer" class='list_footer'>
					<div id="list_footer_open_export" class='list_footer_open_export'>Export this View</div>
					<span id="list_footer_info_label"></span>
				</div>
			</div>
		</div>
 
	</div>
 
  	<div id="export_lightbox" class="export_lightbox">
		<div id="export_content" class="export_content">
			<div class="export_options">
				<a href="#" id="export_close" class="export_close"><b>×</b> Close</a>
				<span>Show:</span>
				<input type="checkbox" id="export_checkbox_files"><label for="export_checkbox_files">Files</label>
				<input type="checkbox" id="export_checkbox_dirs"><label for="export_checkbox_dirs">Folders</label>
				<input type="checkbox" id="export_checkbox_path"><label for="export_checkbox_path">Full path</label>
			</div>
			<div class="export_options">
				<input type="radio" name="export_options" value="plain" id="export_checkbox_plain" checked><label for="export_checkbox_plain">Plain</label>
				<input type="radio" name="export_options" value="json" id="export_checkbox_json"><label for="export_checkbox_json">JSON</label>
				<input type="radio" name="export_options" value="csv" id="export_checkbox_csv"><label for="export_checkbox_csv">CSV</label>
				<span id="export_options_columns">
					<span>Columns:</span>
					<input type="checkbox" id="export_checkbox_col_path"><label for="export_checkbox_col_path">Path</label>
					<input type="checkbox" id="export_checkbox_col_type"><label for="export_checkbox_col_type">Type</label>
					<input type="checkbox" id="export_checkbox_col_size"><label for="export_checkbox_col_size">Size</label>
					<input type="checkbox" id="export_checkbox_col_date"><label for="export_checkbox_col_date">Date</label>
				</span>
			</div>
			<textarea id="export_text" class="export_text" wrap="off"></textarea>
			<div class="export_save"><i class="export_chevron"></i>&nbsp;<a href="#" id="export_save">Save</a></div>
		</div>
		<div id="export_tip">Tip: Search for * to export all files and folders</div>
	</div>
 
</body>
</html>
